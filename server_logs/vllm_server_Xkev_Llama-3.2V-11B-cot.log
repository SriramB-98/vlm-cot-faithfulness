INFO 03-28 15:52:14 __init__.py:207] Automatically detected platform cuda.
INFO 03-28 15:52:14 api_server.py:912] vLLM API server version 0.7.3
INFO 03-28 15:52:14 api_server.py:913] args: Namespace(subparser='serve', model_tag='Xkev/Llama-3.2V-11B-cot', config='', host=None, port=27182, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, chat_template_content_format='openai', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, enable_reasoning=False, reasoning_parser=None, tool_call_parser=None, tool_parser_plugin='', model='Xkev/Llama-3.2V-11B-cot', task='auto', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, allowed_local_media_path=None, download_dir=None, load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', max_model_len=8192, guided_decoding_backend='xgrammar', logits_processor_pattern=None, model_impl='auto', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=None, enable_prefix_caching=None, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_partial_prefills=1, max_long_partial_prefills=1, long_prefill_token_threshold=0, max_num_seqs=4, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_overrides=None, enforce_eager=False, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt={'image': 1}, mm_processor_kwargs={}, disable_mm_preprocessor_cache=False, enable_lora=False, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, scheduling_policy='fcfs', scheduler_cls='vllm.core.scheduler.Scheduler', override_neuron_config=None, override_pooler_config=None, compilation_config=None, kv_transfer_config=None, worker_cls='auto', generation_config=None, override_generation_config=None, enable_sleep_mode=False, calculate_kv_scales=False, additional_config=None, disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False, dispatch_function=<function ServeSubcommand.cmd at 0x7fe073f28540>)
INFO 03-28 15:52:14 api_server.py:209] Started engine process with PID 206598
INFO 03-28 15:52:22 __init__.py:207] Automatically detected platform cuda.
INFO 03-28 15:52:33 config.py:549] This model supports multiple tasks: {'score', 'embed', 'generate', 'classify', 'reward'}. Defaulting to 'generate'.
WARNING 03-28 15:52:33 config.py:642] CUDA graph is not supported for mllama yet, fallback to the eager mode.
INFO 03-28 15:52:33 config.py:1382] Defaulting to use mp for distributed inference
WARNING 03-28 15:52:33 cuda.py:95] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
WARNING 03-28 15:52:33 config.py:685] Async output processing is not supported on the current platform type cuda.
INFO 03-28 15:52:33 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='Xkev/Llama-3.2V-11B-cot', speculative_config=None, tokenizer='Xkev/Llama-3.2V-11B-cot', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Xkev/Llama-3.2V-11B-cot, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs={}, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}, use_cached_outputs=True, 
INFO 03-28 15:52:33 config.py:549] This model supports multiple tasks: {'classify', 'reward', 'generate', 'embed', 'score'}. Defaulting to 'generate'.
WARNING 03-28 15:52:33 config.py:642] CUDA graph is not supported for mllama yet, fallback to the eager mode.
INFO 03-28 15:52:33 config.py:1382] Defaulting to use mp for distributed inference
WARNING 03-28 15:52:33 cuda.py:95] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
WARNING 03-28 15:52:33 config.py:685] Async output processing is not supported on the current platform type cuda.
WARNING 03-28 15:52:34 multiproc_worker_utils.py:300] Reducing Torch parallelism from 4 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 03-28 15:52:34 custom_cache_manager.py:19] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
INFO 03-28 15:52:36 cuda.py:229] Using Flash Attention backend.
INFO 03-28 15:52:42 __init__.py:207] Automatically detected platform cuda.
INFO 03-28 15:52:42 __init__.py:207] Automatically detected platform cuda.
INFO 03-28 15:52:42 __init__.py:207] Automatically detected platform cuda.
[1;36m(VllmWorkerProcess pid=206806)[0;0m INFO 03-28 15:52:42 multiproc_worker_utils.py:229] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=206805)[0;0m INFO 03-28 15:52:42 multiproc_worker_utils.py:229] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=206804)[0;0m INFO 03-28 15:52:42 multiproc_worker_utils.py:229] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=206804)[0;0m INFO 03-28 15:52:43 cuda.py:229] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=206806)[0;0m INFO 03-28 15:52:43 cuda.py:229] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=206805)[0;0m INFO 03-28 15:52:43 cuda.py:229] Using Flash Attention backend.
[1;36m(VllmWorkerProcess pid=206804)[0;0m INFO 03-28 15:52:44 utils.py:916] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=206806)[0;0m INFO 03-28 15:52:44 utils.py:916] Found nccl from library libnccl.so.2
INFO 03-28 15:52:44 utils.py:916] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=206805)[0;0m INFO 03-28 15:52:44 utils.py:916] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=206804)[0;0m INFO 03-28 15:52:44 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=206806)[0;0m INFO 03-28 15:52:44 pynccl.py:69] vLLM is using nccl==2.21.5
INFO 03-28 15:52:44 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=206805)[0;0m INFO 03-28 15:52:44 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=206806)[0;0m WARNING 03-28 15:52:45 custom_all_reduce.py:136] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=206804)[0;0m WARNING 03-28 15:52:45 custom_all_reduce.py:136] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 03-28 15:52:45 custom_all_reduce.py:136] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorkerProcess pid=206805)[0;0m WARNING 03-28 15:52:45 custom_all_reduce.py:136] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 03-28 15:52:45 shm_broadcast.py:258] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_2f772996'), local_subscribe_port=58353, remote_subscribe_port=None)
INFO 03-28 15:52:45 model_runner.py:1110] Starting to load model Xkev/Llama-3.2V-11B-cot...
[1;36m(VllmWorkerProcess pid=206805)[0;0m INFO 03-28 15:52:45 model_runner.py:1110] Starting to load model Xkev/Llama-3.2V-11B-cot...
[1;36m(VllmWorkerProcess pid=206804)[0;0m INFO 03-28 15:52:45 model_runner.py:1110] Starting to load model Xkev/Llama-3.2V-11B-cot...
[1;36m(VllmWorkerProcess pid=206806)[0;0m INFO 03-28 15:52:45 model_runner.py:1110] Starting to load model Xkev/Llama-3.2V-11B-cot...
[1;36m(VllmWorkerProcess pid=206805)[0;0m INFO 03-28 15:52:47 weight_utils.py:254] Using model weights format ['*.safetensors']
INFO 03-28 15:52:47 weight_utils.py:254] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=206806)[0;0m INFO 03-28 15:52:47 weight_utils.py:254] Using model weights format ['*.safetensors']
[1;36m(VllmWorkerProcess pid=206804)[0;0m INFO 03-28 15:52:47 weight_utils.py:254] Using model weights format ['*.safetensors']
Loading safetensors checkpoint shards:   0% Completed | 0/9 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  11% Completed | 1/9 [00:07<01:03,  7.90s/it]
Loading safetensors checkpoint shards:  22% Completed | 2/9 [00:15<00:55,  7.95s/it]
Loading safetensors checkpoint shards:  33% Completed | 3/9 [00:23<00:46,  7.70s/it]
Loading safetensors checkpoint shards:  44% Completed | 4/9 [00:29<00:35,  7.09s/it]
Loading safetensors checkpoint shards:  56% Completed | 5/9 [00:37<00:30,  7.51s/it]
Loading safetensors checkpoint shards:  67% Completed | 6/9 [00:44<00:21,  7.31s/it]
Loading safetensors checkpoint shards:  78% Completed | 7/9 [00:53<00:15,  7.76s/it]
Loading safetensors checkpoint shards:  89% Completed | 8/9 [00:58<00:07,  7.10s/it]
Loading safetensors checkpoint shards: 100% Completed | 9/9 [01:05<00:00,  7.03s/it]
Loading safetensors checkpoint shards: 100% Completed | 9/9 [01:05<00:00,  7.32s/it]

INFO 03-28 15:53:53 model_runner.py:1115] Loading model weights took 5.1131 GB
[1;36m(VllmWorkerProcess pid=206805)[0;0m INFO 03-28 15:53:53 model_runner.py:1115] Loading model weights took 5.1131 GB
[1;36m(VllmWorkerProcess pid=206804)[0;0m INFO 03-28 15:53:53 model_runner.py:1115] Loading model weights took 5.1131 GB
[1;36m(VllmWorkerProcess pid=206806)[0;0m INFO 03-28 15:53:53 model_runner.py:1115] Loading model weights took 5.1131 GB
[1;36m(VllmWorkerProcess pid=206805)[0;0m INFO 03-28 15:53:54 enc_dec_model_runner.py:280] Starting profile run for multi-modal models.
[1;36m(VllmWorkerProcess pid=206806)[0;0m INFO 03-28 15:53:54 enc_dec_model_runner.py:280] Starting profile run for multi-modal models.
[1;36m(VllmWorkerProcess pid=206804)[0;0m INFO 03-28 15:53:54 enc_dec_model_runner.py:280] Starting profile run for multi-modal models.
INFO 03-28 15:53:54 enc_dec_model_runner.py:280] Starting profile run for multi-modal models.
[1;36m(VllmWorkerProcess pid=206805)[0;0m INFO 03-28 15:54:33 worker.py:267] Memory profiling takes 39.45 seconds
[1;36m(VllmWorkerProcess pid=206805)[0;0m INFO 03-28 15:54:33 worker.py:267] the current vLLM instance can use total_gpu_memory (15.61GiB) x gpu_memory_utilization (0.90) = 14.05GiB
[1;36m(VllmWorkerProcess pid=206805)[0;0m INFO 03-28 15:54:33 worker.py:267] model weights take 5.11GiB; non_torch_memory takes 0.25GiB; PyTorch activation peak memory takes 1.49GiB; the rest of the memory reserved for KV Cache is 7.19GiB.
[1;36m(VllmWorkerProcess pid=206804)[0;0m INFO 03-28 15:54:33 worker.py:267] Memory profiling takes 39.45 seconds
[1;36m(VllmWorkerProcess pid=206804)[0;0m INFO 03-28 15:54:33 worker.py:267] the current vLLM instance can use total_gpu_memory (15.61GiB) x gpu_memory_utilization (0.90) = 14.05GiB
[1;36m(VllmWorkerProcess pid=206804)[0;0m INFO 03-28 15:54:33 worker.py:267] model weights take 5.11GiB; non_torch_memory takes 0.25GiB; PyTorch activation peak memory takes 1.49GiB; the rest of the memory reserved for KV Cache is 7.19GiB.
[1;36m(VllmWorkerProcess pid=206806)[0;0m INFO 03-28 15:54:33 worker.py:267] Memory profiling takes 39.46 seconds
[1;36m(VllmWorkerProcess pid=206806)[0;0m INFO 03-28 15:54:33 worker.py:267] the current vLLM instance can use total_gpu_memory (15.61GiB) x gpu_memory_utilization (0.90) = 14.05GiB
[1;36m(VllmWorkerProcess pid=206806)[0;0m INFO 03-28 15:54:33 worker.py:267] model weights take 5.11GiB; non_torch_memory takes 0.21GiB; PyTorch activation peak memory takes 1.49GiB; the rest of the memory reserved for KV Cache is 7.23GiB.
INFO 03-28 15:54:33 worker.py:267] Memory profiling takes 39.76 seconds
INFO 03-28 15:54:33 worker.py:267] the current vLLM instance can use total_gpu_memory (15.61GiB) x gpu_memory_utilization (0.90) = 14.05GiB
INFO 03-28 15:54:33 worker.py:267] model weights take 5.11GiB; non_torch_memory takes 0.30GiB; PyTorch activation peak memory takes 1.49GiB; the rest of the memory reserved for KV Cache is 7.14GiB.
INFO 03-28 15:54:34 executor_base.py:111] # cuda blocks: 11705, # CPU blocks: 6553
INFO 03-28 15:54:34 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 22.86x
INFO 03-28 15:54:37 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 43.11 seconds
INFO 03-28 15:54:37 api_server.py:958] Starting vLLM API server on http://0.0.0.0:27182
INFO 03-28 15:54:37 launcher.py:23] Available routes are:
INFO 03-28 15:54:37 launcher.py:31] Route: /openapi.json, Methods: HEAD, GET
INFO 03-28 15:54:37 launcher.py:31] Route: /docs, Methods: HEAD, GET
INFO 03-28 15:54:37 launcher.py:31] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 03-28 15:54:37 launcher.py:31] Route: /redoc, Methods: HEAD, GET
INFO 03-28 15:54:37 launcher.py:31] Route: /health, Methods: GET
INFO 03-28 15:54:37 launcher.py:31] Route: /ping, Methods: POST, GET
INFO 03-28 15:54:37 launcher.py:31] Route: /tokenize, Methods: POST
INFO 03-28 15:54:37 launcher.py:31] Route: /detokenize, Methods: POST
INFO 03-28 15:54:37 launcher.py:31] Route: /v1/models, Methods: GET
INFO 03-28 15:54:37 launcher.py:31] Route: /version, Methods: GET
INFO 03-28 15:54:37 launcher.py:31] Route: /v1/chat/completions, Methods: POST
INFO 03-28 15:54:37 launcher.py:31] Route: /v1/completions, Methods: POST
INFO 03-28 15:54:37 launcher.py:31] Route: /v1/embeddings, Methods: POST
INFO 03-28 15:54:37 launcher.py:31] Route: /pooling, Methods: POST
INFO 03-28 15:54:37 launcher.py:31] Route: /score, Methods: POST
INFO 03-28 15:54:37 launcher.py:31] Route: /v1/score, Methods: POST
INFO 03-28 15:54:37 launcher.py:31] Route: /v1/audio/transcriptions, Methods: POST
INFO 03-28 15:54:37 launcher.py:31] Route: /rerank, Methods: POST
INFO 03-28 15:54:37 launcher.py:31] Route: /v1/rerank, Methods: POST
INFO 03-28 15:54:37 launcher.py:31] Route: /v2/rerank, Methods: POST
INFO 03-28 15:54:37 launcher.py:31] Route: /invocations, Methods: POST
INFO:     Started server process [206268]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     127.0.0.1:39354 - "GET /health HTTP/1.1" 200 OK
INFO 03-28 15:55:33 chat_utils.py:332] Detected the chat template content format to be 'openai'. You can set `--chat-template-content-format` to override this.
INFO 03-28 15:55:33 logger.py:39] Received request chatcmpl-475f5f0f9e524c9d86988fe8f9150fe8: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) desk\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:34 logger.py:39] Received request chatcmpl-7e7c23c27e6f44ddb544ead2cf7ae1f9: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:34 logger.py:39] Received request chatcmpl-990eec5736a545b8a9520f269641c3fd: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:34 logger.py:39] Received request chatcmpl-916a91c6a2084e9e94ca692204dcdcd1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:34 logger.py:39] Received request chatcmpl-8359c61d8fd24ab59134fb4c581f26cb: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:34 logger.py:39] Received request chatcmpl-47c5e490d13a40839854a96ccf4a356b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:34 logger.py:39] Received request chatcmpl-16e4b9da483e4ca6bcf56072d75dbdab: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:34 logger.py:39] Received request chatcmpl-a4e9ddc5474844f3bc2892a041ea18a4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:34 logger.py:39] Received request chatcmpl-8e68a23519ba4d339baf237251366c7b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:34 logger.py:39] Received request chatcmpl-d86e7f73d4404433b698e89f48a662d3: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:34 logger.py:39] Received request chatcmpl-d0d65f08f51d420cbb8edf9268eb8390: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:34 logger.py:39] Received request chatcmpl-95109f1538a3422ba9f128c5a7a6b2b0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:34 logger.py:39] Received request chatcmpl-1be038e2ab084dd3b15ca076c4ab8c88: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sink (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) sink\n(B) pillow\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:34 logger.py:39] Received request chatcmpl-4befb01be9da44e7bf3dd2efc47a74de: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:34 logger.py:39] Received request chatcmpl-1395f924bf154464aa2407cfaab14479: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:34 logger.py:39] Received request chatcmpl-3f251b3ddfae4a7ea12bf9b2477db0ae: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) door\n(B) pillow\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-28 15:55:36 preprocess.py:87] Falling back on <BOS> for decoder start token id because decoder start token id is not available.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-475f5f0f9e524c9d86988fe8f9150fe8.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-7e7c23c27e6f44ddb544ead2cf7ae1f9.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-990eec5736a545b8a9520f269641c3fd.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-916a91c6a2084e9e94ca692204dcdcd1.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-8359c61d8fd24ab59134fb4c581f26cb.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-47c5e490d13a40839854a96ccf4a356b.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-16e4b9da483e4ca6bcf56072d75dbdab.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-a4e9ddc5474844f3bc2892a041ea18a4.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-8e68a23519ba4d339baf237251366c7b.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-d86e7f73d4404433b698e89f48a662d3.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-d0d65f08f51d420cbb8edf9268eb8390.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-95109f1538a3422ba9f128c5a7a6b2b0.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-1be038e2ab084dd3b15ca076c4ab8c88.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-4befb01be9da44e7bf3dd2efc47a74de.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-1395f924bf154464aa2407cfaab14479.
INFO 03-28 15:55:36 engine.py:280] Added request chatcmpl-3f251b3ddfae4a7ea12bf9b2477db0ae.
INFO 03-28 15:55:38 metrics.py:455] Avg prompt throughput: 28.1 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 13.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:55:43 logger.py:39] Received request chatcmpl-c5d551514afb4f69856ae25dae715772: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) books\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:43 metrics.py:455] Avg prompt throughput: 15.3 tokens/s, Avg generation throughput: 136.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.2%, CPU KV cache usage: 0.0%.
INFO 03-28 15:55:43 engine.py:280] Added request chatcmpl-c5d551514afb4f69856ae25dae715772.
INFO:     127.0.0.1:37710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:55:44 logger.py:39] Received request chatcmpl-2dabb5176e93402ba16740fddae208c9: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:44 engine.py:280] Added request chatcmpl-2dabb5176e93402ba16740fddae208c9.
INFO:     127.0.0.1:37694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:55:45 logger.py:39] Received request chatcmpl-5a2daaf624344755b381632f311af657: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:45 engine.py:280] Added request chatcmpl-5a2daaf624344755b381632f311af657.
INFO 03-28 15:55:48 metrics.py:455] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 120.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:55:51 logger.py:39] Received request chatcmpl-73dd29b64b3744f1bdd4f329a29613e5: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:51 engine.py:280] Added request chatcmpl-73dd29b64b3744f1bdd4f329a29613e5.
INFO:     127.0.0.1:37810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:55:51 logger.py:39] Received request chatcmpl-f96bd331934546e4996edbc0bf705882: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) shelves\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:51 engine.py:280] Added request chatcmpl-f96bd331934546e4996edbc0bf705882.
INFO 03-28 15:55:53 metrics.py:455] Avg prompt throughput: 31.0 tokens/s, Avg generation throughput: 123.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:55:56 logger.py:39] Received request chatcmpl-617f142160ff4c1cb4a14213e06d73d3: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:55:57 engine.py:280] Added request chatcmpl-617f142160ff4c1cb4a14213e06d73d3.
INFO 03-28 15:55:58 metrics.py:455] Avg prompt throughput: 15.9 tokens/s, Avg generation throughput: 137.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:02 logger.py:39] Received request chatcmpl-748fa05301f3415ea08d8fd890727b5b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:02 engine.py:280] Added request chatcmpl-748fa05301f3415ea08d8fd890727b5b.
INFO 03-28 15:56:03 metrics.py:455] Avg prompt throughput: 15.9 tokens/s, Avg generation throughput: 138.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:07 logger.py:39] Received request chatcmpl-ebe736a3a9b54af4a785d4763855c6ac: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:08 engine.py:280] Added request chatcmpl-ebe736a3a9b54af4a785d4763855c6ac.
INFO 03-28 15:56:08 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 137.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:09 logger.py:39] Received request chatcmpl-05499624a4ce4e478a19c5296437f901: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:10 engine.py:280] Added request chatcmpl-05499624a4ce4e478a19c5296437f901.
INFO 03-28 15:56:13 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 137.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:14 logger.py:39] Received request chatcmpl-5a5bc3aa7705456c926ff932ee927c2d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:15 engine.py:280] Added request chatcmpl-5a5bc3aa7705456c926ff932ee927c2d.
INFO:     127.0.0.1:37790 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:16 logger.py:39] Received request chatcmpl-3e0b37f97aef4eb09b4ede70e0315dc3: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:16 engine.py:280] Added request chatcmpl-3e0b37f97aef4eb09b4ede70e0315dc3.
INFO 03-28 15:56:19 metrics.py:455] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 121.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:19 logger.py:39] Received request chatcmpl-d1c5a2e7233443a2819dadc6fec40a23: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:19 engine.py:280] Added request chatcmpl-d1c5a2e7233443a2819dadc6fec40a23.
INFO:     127.0.0.1:37778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:21 logger.py:39] Received request chatcmpl-618225af1e0a4228b495b3377b15bbeb: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:21 engine.py:280] Added request chatcmpl-618225af1e0a4228b495b3377b15bbeb.
INFO:     127.0.0.1:37812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:22 logger.py:39] Received request chatcmpl-11f9a899107f47bbbc62d47eb2a25eb7: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:23 engine.py:280] Added request chatcmpl-11f9a899107f47bbbc62d47eb2a25eb7.
INFO 03-28 15:56:24 metrics.py:455] Avg prompt throughput: 46.6 tokens/s, Avg generation throughput: 105.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:25 logger.py:39] Received request chatcmpl-d962100166af4975a9ba2c8c7b04bc4e: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:25 engine.py:280] Added request chatcmpl-d962100166af4975a9ba2c8c7b04bc4e.
INFO:     127.0.0.1:37710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:28 logger.py:39] Received request chatcmpl-4461ea6122ec499789e8684a29dcd95a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:28 engine.py:280] Added request chatcmpl-4461ea6122ec499789e8684a29dcd95a.
INFO:     127.0.0.1:37772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:28 logger.py:39] Received request chatcmpl-94739cab8bea475fbe15edc3d205c1ec: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) sofa\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:28 engine.py:280] Added request chatcmpl-94739cab8bea475fbe15edc3d205c1ec.
INFO 03-28 15:56:29 metrics.py:455] Avg prompt throughput: 46.8 tokens/s, Avg generation throughput: 107.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:33 logger.py:39] Received request chatcmpl-820c52cea75f4885b321c12e5a809a96: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) chair\n(B) shelves\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:34 metrics.py:455] Avg prompt throughput: 15.7 tokens/s, Avg generation throughput: 138.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO 03-28 15:56:34 engine.py:280] Added request chatcmpl-820c52cea75f4885b321c12e5a809a96.
INFO:     127.0.0.1:37810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:34 logger.py:39] Received request chatcmpl-6e16d4c0c80d41798e373c31cd973a81: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:34 engine.py:280] Added request chatcmpl-6e16d4c0c80d41798e373c31cd973a81.
INFO 03-28 15:56:39 metrics.py:455] Avg prompt throughput: 16.0 tokens/s, Avg generation throughput: 133.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:40 logger.py:39] Received request chatcmpl-c7a7face0d5a4b3a80cb3aaf282d4278: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) shelves\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:40 engine.py:280] Added request chatcmpl-c7a7face0d5a4b3a80cb3aaf282d4278.
INFO:     127.0.0.1:37792 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:41 logger.py:39] Received request chatcmpl-8b33178f1d27465f994243c04c8ee0f1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:41 engine.py:280] Added request chatcmpl-8b33178f1d27465f994243c04c8ee0f1.
INFO 03-28 15:56:44 metrics.py:455] Avg prompt throughput: 31.9 tokens/s, Avg generation throughput: 122.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:46 logger.py:39] Received request chatcmpl-31a9968b58f44c75851ab7ed738fedee: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the floor mat (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) floor mat\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:46 engine.py:280] Added request chatcmpl-31a9968b58f44c75851ab7ed738fedee.
INFO:     127.0.0.1:37714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:47 logger.py:39] Received request chatcmpl-326e8acff14045a3a6b6bf09f233368c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:47 engine.py:280] Added request chatcmpl-326e8acff14045a3a6b6bf09f233368c.
INFO 03-28 15:56:49 metrics.py:455] Avg prompt throughput: 31.0 tokens/s, Avg generation throughput: 123.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37790 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:52 logger.py:39] Received request chatcmpl-2ea509069eeb4150bfa97b318a78b3f9: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:53 engine.py:280] Added request chatcmpl-2ea509069eeb4150bfa97b318a78b3f9.
INFO 03-28 15:56:54 metrics.py:455] Avg prompt throughput: 15.9 tokens/s, Avg generation throughput: 137.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:57 logger.py:39] Received request chatcmpl-f628dfdb7ffa4c84bfa2491d81b8c4ee: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the counter (highlighted by a blue box)?\n(A) lamp\n(B) counter\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:57 engine.py:280] Added request chatcmpl-f628dfdb7ffa4c84bfa2491d81b8c4ee.
INFO:     127.0.0.1:37814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:56:58 logger.py:39] Received request chatcmpl-2ff845656c994a9e84f4b45a7ec71759: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:56:58 engine.py:280] Added request chatcmpl-2ff845656c994a9e84f4b45a7ec71759.
INFO 03-28 15:56:59 metrics.py:455] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 121.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:04 logger.py:39] Received request chatcmpl-72cd2dc0c9a748688cbcb6be2d8343f2: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:04 metrics.py:455] Avg prompt throughput: 16.0 tokens/s, Avg generation throughput: 139.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO 03-28 15:57:04 engine.py:280] Added request chatcmpl-72cd2dc0c9a748688cbcb6be2d8343f2.
INFO:     127.0.0.1:37742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:05 logger.py:39] Received request chatcmpl-f3372f3c262e404abfa224880d1ad6c9: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:06 engine.py:280] Added request chatcmpl-f3372f3c262e404abfa224880d1ad6c9.
INFO 03-28 15:57:09 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 135.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:10 logger.py:39] Received request chatcmpl-9a13d382e290451da26de57a088d00c6: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:10 engine.py:280] Added request chatcmpl-9a13d382e290451da26de57a088d00c6.
INFO:     127.0.0.1:37710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:11 logger.py:39] Received request chatcmpl-64cf1292e26d4db1bffdc157de26ee21: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) sofa\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:11 engine.py:280] Added request chatcmpl-64cf1292e26d4db1bffdc157de26ee21.
INFO 03-28 15:57:14 metrics.py:455] Avg prompt throughput: 31.2 tokens/s, Avg generation throughput: 114.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:15 logger.py:39] Received request chatcmpl-4b767daa6b5346afae3fce3121c2a356: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:15 engine.py:280] Added request chatcmpl-4b767daa6b5346afae3fce3121c2a356.
INFO:     127.0.0.1:37788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:17 logger.py:39] Received request chatcmpl-48965e759bb14eebae3e574ced11cd9f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) shelves\n(B) mirror\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:17 engine.py:280] Added request chatcmpl-48965e759bb14eebae3e574ced11cd9f.
INFO:     127.0.0.1:37756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:19 logger.py:39] Received request chatcmpl-6b7d1d4a3e2e49f8bce9ff9f491317a1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:19 metrics.py:455] Avg prompt throughput: 46.5 tokens/s, Avg generation throughput: 108.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.
INFO 03-28 15:57:19 engine.py:280] Added request chatcmpl-6b7d1d4a3e2e49f8bce9ff9f491317a1.
INFO:     127.0.0.1:37810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:22 logger.py:39] Received request chatcmpl-b42270eb9d4c48ce8f62ab9df22fa9d1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:22 engine.py:280] Added request chatcmpl-b42270eb9d4c48ce8f62ab9df22fa9d1.
INFO:     127.0.0.1:37730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:23 logger.py:39] Received request chatcmpl-0628ce4d95a1491982bac0ebdc562c1b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:23 engine.py:280] Added request chatcmpl-0628ce4d95a1491982bac0ebdc562c1b.
INFO 03-28 15:57:24 metrics.py:455] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 119.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.
INFO 03-28 15:57:29 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:30 logger.py:39] Received request chatcmpl-e5bf4302158f403d9e36a80fe605ffae: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:30 engine.py:280] Added request chatcmpl-e5bf4302158f403d9e36a80fe605ffae.
INFO 03-28 15:57:34 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 136.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37790 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:35 logger.py:39] Received request chatcmpl-0350ff5f8dc44d0fbdb5bdee3e5b06f7: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:35 engine.py:280] Added request chatcmpl-0350ff5f8dc44d0fbdb5bdee3e5b06f7.
INFO 03-28 15:57:39 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 136.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:40 logger.py:39] Received request chatcmpl-c0da89dda2364b2abb8aaa51c916d0d2: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:41 engine.py:280] Added request chatcmpl-c0da89dda2364b2abb8aaa51c916d0d2.
INFO 03-28 15:57:44 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 137.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37792 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:49 logger.py:39] Received request chatcmpl-593a1dcf42bc41fc92f983756d154906: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:49 engine.py:280] Added request chatcmpl-593a1dcf42bc41fc92f983756d154906.
INFO 03-28 15:57:49 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 135.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:52 logger.py:39] Received request chatcmpl-b9494ee96d9543c58232b6e1e39decc1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) bookcase\n(B) pillow\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:52 engine.py:280] Added request chatcmpl-b9494ee96d9543c58232b6e1e39decc1.
INFO:     127.0.0.1:37714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:53 logger.py:39] Received request chatcmpl-e1f2a2973902400683766ab18e87bb2c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) shelves\n(B) pillow\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:53 engine.py:280] Added request chatcmpl-e1f2a2973902400683766ab18e87bb2c.
INFO 03-28 15:57:54 metrics.py:455] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 122.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:57:55 logger.py:39] Received request chatcmpl-2299986879ad46b3818f5e84fe0672c6: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:57:55 engine.py:280] Added request chatcmpl-2299986879ad46b3818f5e84fe0672c6.
INFO 03-28 15:57:59 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 136.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:58:00 logger.py:39] Received request chatcmpl-27dc1359eb9148b9a1c3f4f29b94dc01: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:58:00 engine.py:280] Added request chatcmpl-27dc1359eb9148b9a1c3f4f29b94dc01.
INFO 03-28 15:58:04 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 138.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:58:05 logger.py:39] Received request chatcmpl-f29746a8d32c4143a08b82187c92cc78: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:58:05 engine.py:280] Added request chatcmpl-f29746a8d32c4143a08b82187c92cc78.
INFO 03-28 15:58:09 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 137.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:58:11 logger.py:39] Received request chatcmpl-b41b2d07f43e4c8c884de2ca42daab2a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:58:11 engine.py:280] Added request chatcmpl-b41b2d07f43e4c8c884de2ca42daab2a.
INFO 03-28 15:58:14 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 138.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO 03-28 15:58:19 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:58:21 logger.py:39] Received request chatcmpl-d00dde853e6e4b5182c7f1350f496ae0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:58:22 engine.py:280] Added request chatcmpl-d00dde853e6e4b5182c7f1350f496ae0.
INFO:     127.0.0.1:37804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:58:23 logger.py:39] Received request chatcmpl-a21d6a28bdbe4d15be36893dd59f901a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:58:23 engine.py:280] Added request chatcmpl-a21d6a28bdbe4d15be36893dd59f901a.
INFO 03-28 15:58:24 metrics.py:455] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 120.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO 03-28 15:58:29 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 153.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:58:34 logger.py:39] Received request chatcmpl-bda9cf4b18114434bb7a36e222ea8f73: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:58:34 metrics.py:455] Avg prompt throughput: 15.1 tokens/s, Avg generation throughput: 140.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO 03-28 15:58:34 engine.py:280] Added request chatcmpl-bda9cf4b18114434bb7a36e222ea8f73.
INFO:     127.0.0.1:37778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:58:39 logger.py:39] Received request chatcmpl-a47056bf54ee4c5fae5eb0ba0adf5207: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) table\n(B) blinds\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:58:39 metrics.py:455] Avg prompt throughput: 14.8 tokens/s, Avg generation throughput: 137.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
INFO 03-28 15:58:39 engine.py:280] Added request chatcmpl-a47056bf54ee4c5fae5eb0ba0adf5207.
INFO:     127.0.0.1:37756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:58:40 logger.py:39] Received request chatcmpl-958c1f40e5884586910e5009954a5ac5: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:58:40 engine.py:280] Added request chatcmpl-958c1f40e5884586910e5009954a5ac5.
INFO 03-28 15:58:44 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 135.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37790 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:58:45 logger.py:39] Received request chatcmpl-5a252ae5d0404340add0cfa6f77cc364: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:58:45 engine.py:280] Added request chatcmpl-5a252ae5d0404340add0cfa6f77cc364.
INFO 03-28 15:58:49 metrics.py:455] Avg prompt throughput: 16.0 tokens/s, Avg generation throughput: 135.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:58:51 logger.py:39] Received request chatcmpl-0a0a2d6e0ce44c1d991331b3adc2b095: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:58:52 engine.py:280] Added request chatcmpl-0a0a2d6e0ce44c1d991331b3adc2b095.
INFO:     127.0.0.1:37730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:58:53 logger.py:39] Received request chatcmpl-593d15500ee64dc7ac15127a2e2ed052: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:58:53 engine.py:280] Added request chatcmpl-593d15500ee64dc7ac15127a2e2ed052.
INFO 03-28 15:58:54 metrics.py:455] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 123.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:58:57 logger.py:39] Received request chatcmpl-4e5ff5d4cc97472c8278ee865560c1be: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:58:57 engine.py:280] Added request chatcmpl-4e5ff5d4cc97472c8278ee865560c1be.
INFO:     127.0.0.1:37714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:58:59 logger.py:39] Received request chatcmpl-83f2d7692e934322aeec1f0b8bdfde45: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:58:59 engine.py:280] Added request chatcmpl-83f2d7692e934322aeec1f0b8bdfde45.
INFO 03-28 15:58:59 metrics.py:455] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 122.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:59:03 logger.py:39] Received request chatcmpl-a764c2e66ae146cb8bfb3a726cf69990: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:59:04 engine.py:280] Added request chatcmpl-a764c2e66ae146cb8bfb3a726cf69990.
INFO:     127.0.0.1:37710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:59:04 logger.py:39] Received request chatcmpl-6c2a45f6ca654244a26969a669633231: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:59:04 engine.py:280] Added request chatcmpl-6c2a45f6ca654244a26969a669633231.
INFO 03-28 15:59:05 metrics.py:455] Avg prompt throughput: 31.2 tokens/s, Avg generation throughput: 122.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:59:09 logger.py:39] Received request chatcmpl-288d280699404396be2af5f570679a27: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:59:10 engine.py:280] Added request chatcmpl-288d280699404396be2af5f570679a27.
INFO 03-28 15:59:10 metrics.py:455] Avg prompt throughput: 15.4 tokens/s, Avg generation throughput: 137.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:59:10 logger.py:39] Received request chatcmpl-dca6ebc39c694a048b6942a04744bbcf: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:59:10 engine.py:280] Added request chatcmpl-dca6ebc39c694a048b6942a04744bbcf.
INFO:     127.0.0.1:37694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:59:12 logger.py:39] Received request chatcmpl-a4e188e1296343d1b0bedd62e0f92078: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:59:12 engine.py:280] Added request chatcmpl-a4e188e1296343d1b0bedd62e0f92078.
INFO 03-28 15:59:15 metrics.py:455] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 122.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:59:17 logger.py:39] Received request chatcmpl-6981950f010d443c95f81cca22e6e899: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) box\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:59:17 engine.py:280] Added request chatcmpl-6981950f010d443c95f81cca22e6e899.
INFO:     127.0.0.1:37792 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:59:18 logger.py:39] Received request chatcmpl-7f24190cca6e4d1eb741733446ba1281: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:59:18 engine.py:280] Added request chatcmpl-7f24190cca6e4d1eb741733446ba1281.
INFO 03-28 15:59:20 metrics.py:455] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 122.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:59:23 logger.py:39] Received request chatcmpl-9fa255d749b24b9dabf8b0eda5c5e0ba: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:59:23 engine.py:280] Added request chatcmpl-9fa255d749b24b9dabf8b0eda5c5e0ba.
INFO 03-28 15:59:25 metrics.py:455] Avg prompt throughput: 16.0 tokens/s, Avg generation throughput: 137.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37790 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:59:28 logger.py:39] Received request chatcmpl-68452e9a56914a78a0fa8cf002e38c9c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:59:29 engine.py:280] Added request chatcmpl-68452e9a56914a78a0fa8cf002e38c9c.
INFO 03-28 15:59:30 metrics.py:455] Avg prompt throughput: 16.0 tokens/s, Avg generation throughput: 136.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO 03-28 15:59:35 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 153.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:59:40 logger.py:39] Received request chatcmpl-315026da514743aea1cbb792326d8833: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) table\n(B) shelves\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:59:40 metrics.py:455] Avg prompt throughput: 14.8 tokens/s, Avg generation throughput: 138.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
INFO 03-28 15:59:40 engine.py:280] Added request chatcmpl-315026da514743aea1cbb792326d8833.
INFO:     127.0.0.1:37804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:59:40 logger.py:39] Received request chatcmpl-f131a3c26ad74d92a1d99e31a0b9c0ac: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:59:41 engine.py:280] Added request chatcmpl-f131a3c26ad74d92a1d99e31a0b9c0ac.
INFO 03-28 15:59:45 metrics.py:455] Avg prompt throughput: 16.0 tokens/s, Avg generation throughput: 134.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:59:46 logger.py:39] Received request chatcmpl-19e52eff5a6b436c97a0a61976e99a41: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) lamp\n(B) door\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:59:47 engine.py:280] Added request chatcmpl-19e52eff5a6b436c97a0a61976e99a41.
INFO:     127.0.0.1:37778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:59:47 logger.py:39] Received request chatcmpl-867043057a5d4e219f79138c46294016: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:59:47 engine.py:280] Added request chatcmpl-867043057a5d4e219f79138c46294016.
INFO 03-28 15:59:50 metrics.py:455] Avg prompt throughput: 31.6 tokens/s, Avg generation throughput: 121.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO 03-28 15:59:55 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 15:59:58 logger.py:39] Received request chatcmpl-955316dd4b2d40a4b17253b5d99302a5: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) lamp\n(B) shelves\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 15:59:58 engine.py:280] Added request chatcmpl-955316dd4b2d40a4b17253b5d99302a5.
INFO 03-28 16:00:00 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 137.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO 03-28 16:00:05 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:00:09 logger.py:39] Received request chatcmpl-abcbf03047444508a0928614ba2e6f25: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:00:09 engine.py:280] Added request chatcmpl-abcbf03047444508a0928614ba2e6f25.
INFO 03-28 16:00:10 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 137.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:00:15 logger.py:39] Received request chatcmpl-881757b2cd7e41cd87bd4438b6da3b7c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) books\n(B) mirror\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:00:15 metrics.py:455] Avg prompt throughput: 14.5 tokens/s, Avg generation throughput: 137.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO 03-28 16:00:15 engine.py:280] Added request chatcmpl-881757b2cd7e41cd87bd4438b6da3b7c.
INFO:     127.0.0.1:37812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:00:16 logger.py:39] Received request chatcmpl-83b82a04e6c9416591cf8fd21d7eba42: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:00:16 engine.py:280] Added request chatcmpl-83b82a04e6c9416591cf8fd21d7eba42.
INFO 03-28 16:00:20 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 135.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.
INFO 03-28 16:00:25 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 150.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:00:27 logger.py:39] Received request chatcmpl-03344331a5524d9292aa5a90cc0fa792: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) pillow\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:00:27 engine.py:280] Added request chatcmpl-03344331a5524d9292aa5a90cc0fa792.
INFO 03-28 16:00:30 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 136.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO 03-28 16:00:35 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:00:38 logger.py:39] Received request chatcmpl-48331ffee9614d6a84de27078d4d3518: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:00:38 engine.py:280] Added request chatcmpl-48331ffee9614d6a84de27078d4d3518.
INFO 03-28 16:00:40 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 134.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:00:44 logger.py:39] Received request chatcmpl-755227fa6d2c4323b85bf7fcd3f9ce99: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:00:44 engine.py:280] Added request chatcmpl-755227fa6d2c4323b85bf7fcd3f9ce99.
INFO:     127.0.0.1:37694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:00:45 logger.py:39] Received request chatcmpl-30d700806cbc4088825e825f70ea84c4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:00:45 engine.py:280] Added request chatcmpl-30d700806cbc4088825e825f70ea84c4.
INFO 03-28 16:00:45 metrics.py:455] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 121.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:00:50 logger.py:39] Received request chatcmpl-52664e76b1ef4d68bdc3f10e05bbe243: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:00:50 engine.py:280] Added request chatcmpl-52664e76b1ef4d68bdc3f10e05bbe243.
INFO 03-28 16:00:50 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 137.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO 03-28 16:00:55 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:00:56 logger.py:39] Received request chatcmpl-89f1c5d2796c49e9a8fb1ad8d35464d0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:00:56 engine.py:280] Added request chatcmpl-89f1c5d2796c49e9a8fb1ad8d35464d0.
INFO 03-28 16:01:00 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 136.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO 03-28 16:01:05 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37792 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:01:08 logger.py:39] Received request chatcmpl-278311ce9b314c019522c65c8b796793: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) door\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:01:08 engine.py:280] Added request chatcmpl-278311ce9b314c019522c65c8b796793.
INFO 03-28 16:01:10 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 136.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:01:13 logger.py:39] Received request chatcmpl-e272eb073f89475d9ff62db688eac80b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:01:13 engine.py:280] Added request chatcmpl-e272eb073f89475d9ff62db688eac80b.
INFO:     127.0.0.1:37790 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:01:15 logger.py:39] Received request chatcmpl-6e860021591a4426bfbb09199c0480b1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:01:15 engine.py:280] Added request chatcmpl-6e860021591a4426bfbb09199c0480b1.
INFO 03-28 16:01:15 metrics.py:455] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 120.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:01:19 logger.py:39] Received request chatcmpl-abf8f86a360546a2815763012c2311da: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:01:19 engine.py:280] Added request chatcmpl-abf8f86a360546a2815763012c2311da.
INFO:     127.0.0.1:37810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:01:21 logger.py:39] Received request chatcmpl-d28170389aaa4beb9286eaaf2a51a7ee: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:01:21 metrics.py:455] Avg prompt throughput: 28.9 tokens/s, Avg generation throughput: 125.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO 03-28 16:01:21 engine.py:280] Added request chatcmpl-d28170389aaa4beb9286eaaf2a51a7ee.
INFO 03-28 16:01:26 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 150.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:01:26 logger.py:39] Received request chatcmpl-14d47c4ee8614634991364b450377e61: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:01:26 engine.py:280] Added request chatcmpl-14d47c4ee8614634991364b450377e61.
INFO 03-28 16:01:31 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 137.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:01:32 logger.py:39] Received request chatcmpl-c24ec5d9476140bea3ea64e7822f100e: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:01:32 engine.py:280] Added request chatcmpl-c24ec5d9476140bea3ea64e7822f100e.
INFO 03-28 16:01:36 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 138.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:01:37 logger.py:39] Received request chatcmpl-740b0ae215c0434899055bf25babf7a6: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) desk\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:01:38 engine.py:280] Added request chatcmpl-740b0ae215c0434899055bf25babf7a6.
INFO 03-28 16:01:41 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 135.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:01:43 logger.py:39] Received request chatcmpl-02c4c8dd48384c63a22b0995a9551ff1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:01:44 engine.py:280] Added request chatcmpl-02c4c8dd48384c63a22b0995a9551ff1.
INFO 03-28 16:01:46 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 137.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:01:49 logger.py:39] Received request chatcmpl-cc569897c4f440798862e7241b1aa7ac: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:01:49 engine.py:280] Added request chatcmpl-cc569897c4f440798862e7241b1aa7ac.
INFO:     127.0.0.1:37730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:01:50 logger.py:39] Received request chatcmpl-4b89550662fb40209d43acc22d53d3de: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:01:50 engine.py:280] Added request chatcmpl-4b89550662fb40209d43acc22d53d3de.
INFO:     127.0.0.1:37714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:01:51 logger.py:39] Received request chatcmpl-83689092dee84636abb6579f96ad94e2: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:01:51 metrics.py:455] Avg prompt throughput: 45.0 tokens/s, Avg generation throughput: 112.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.2%, CPU KV cache usage: 0.0%.
INFO 03-28 16:01:51 engine.py:280] Added request chatcmpl-83689092dee84636abb6579f96ad94e2.
INFO 03-28 16:01:56 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 151.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO 03-28 16:02:01 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO 03-28 16:02:06 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:02:07 logger.py:39] Received request chatcmpl-3374b75faf3c4281b460750a1b81bcf3: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:02:07 engine.py:280] Added request chatcmpl-3374b75faf3c4281b460750a1b81bcf3.
INFO 03-28 16:02:11 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 136.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37792 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:02:12 logger.py:39] Received request chatcmpl-3ff1f37ed7f04061a2928b53d27ada21: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:02:12 engine.py:280] Added request chatcmpl-3ff1f37ed7f04061a2928b53d27ada21.
INFO 03-28 16:02:16 metrics.py:455] Avg prompt throughput: 16.0 tokens/s, Avg generation throughput: 138.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:02:18 logger.py:39] Received request chatcmpl-f21d18f5a378476cbef4cabfbbd8d9e4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:02:18 engine.py:280] Added request chatcmpl-f21d18f5a378476cbef4cabfbbd8d9e4.
INFO:     127.0.0.1:37756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:02:19 logger.py:39] Received request chatcmpl-b3c6f9c4c80a42b49c7d6e4e2ba4e04a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sink (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) sink\n(B) pillow\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:02:19 engine.py:280] Added request chatcmpl-b3c6f9c4c80a42b49c7d6e4e2ba4e04a.
INFO:     127.0.0.1:37788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:02:20 logger.py:39] Received request chatcmpl-8abe65d012074895ac4b94e16069c87c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:02:21 engine.py:280] Added request chatcmpl-8abe65d012074895ac4b94e16069c87c.
INFO 03-28 16:02:21 metrics.py:455] Avg prompt throughput: 46.6 tokens/s, Avg generation throughput: 109.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37790 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:02:24 logger.py:39] Received request chatcmpl-48648fbaaef341d09bd42fb8d125a676: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) door\n(B) pillow\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:02:24 engine.py:280] Added request chatcmpl-48648fbaaef341d09bd42fb8d125a676.
INFO:     127.0.0.1:37810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:02:26 logger.py:39] Received request chatcmpl-7431258694974b56be66b00645060878: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:02:26 engine.py:280] Added request chatcmpl-7431258694974b56be66b00645060878.
INFO:     127.0.0.1:37742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:02:26 logger.py:39] Received request chatcmpl-9ee98092d5704d918ba8e72f2ab801cf: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:02:27 metrics.py:455] Avg prompt throughput: 43.6 tokens/s, Avg generation throughput: 111.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.2%, CPU KV cache usage: 0.0%.
INFO 03-28 16:02:27 engine.py:280] Added request chatcmpl-9ee98092d5704d918ba8e72f2ab801cf.
INFO:     127.0.0.1:37812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:02:32 logger.py:39] Received request chatcmpl-6778be2b194a43408fd9a69db9687ed8: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:02:32 metrics.py:455] Avg prompt throughput: 15.0 tokens/s, Avg generation throughput: 139.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO 03-28 16:02:32 engine.py:280] Added request chatcmpl-6778be2b194a43408fd9a69db9687ed8.
INFO 03-28 16:02:37 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 151.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO 03-28 16:02:42 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:02:43 logger.py:39] Received request chatcmpl-5828a8c3e7ad45d997f7e074e027e050: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:02:43 engine.py:280] Added request chatcmpl-5828a8c3e7ad45d997f7e074e027e050.
INFO 03-28 16:02:47 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 138.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:02:49 logger.py:39] Received request chatcmpl-6f2d4a7341534e3090f11293fdd15a98: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) books\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:02:49 engine.py:280] Added request chatcmpl-6f2d4a7341534e3090f11293fdd15a98.
INFO 03-28 16:02:52 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 136.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:02:53 logger.py:39] Received request chatcmpl-5d8992d3034f4ae8a75f9c6bb8561edd: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:02:54 engine.py:280] Added request chatcmpl-5d8992d3034f4ae8a75f9c6bb8561edd.
INFO:     127.0.0.1:37710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:02:56 logger.py:39] Received request chatcmpl-2bd87df38d8a4a90a9d32df9ae6a500f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:02:56 engine.py:280] Added request chatcmpl-2bd87df38d8a4a90a9d32df9ae6a500f.
INFO 03-28 16:02:57 metrics.py:455] Avg prompt throughput: 31.2 tokens/s, Avg generation throughput: 124.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:03:01 logger.py:39] Received request chatcmpl-e67cdce234064a508073936419c69c85: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:03:02 engine.py:280] Added request chatcmpl-e67cdce234064a508073936419c69c85.
INFO:     127.0.0.1:37772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:03:02 logger.py:39] Received request chatcmpl-8cdce6b1f08b48858d10f560cbecd4c8: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) shelves\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:03:02 metrics.py:455] Avg prompt throughput: 30.9 tokens/s, Avg generation throughput: 120.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.
INFO 03-28 16:03:02 engine.py:280] Added request chatcmpl-8cdce6b1f08b48858d10f560cbecd4c8.
INFO:     127.0.0.1:37694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:03:07 logger.py:39] Received request chatcmpl-ee5509b7a43a47218fa561c2ab3ef885: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:03:07 metrics.py:455] Avg prompt throughput: 15.4 tokens/s, Avg generation throughput: 138.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO 03-28 16:03:07 engine.py:280] Added request chatcmpl-ee5509b7a43a47218fa561c2ab3ef885.
INFO:     127.0.0.1:37756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:03:12 logger.py:39] Received request chatcmpl-41f918794774418daa122a32549266f9: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:03:12 metrics.py:455] Avg prompt throughput: 15.4 tokens/s, Avg generation throughput: 137.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO 03-28 16:03:12 engine.py:280] Added request chatcmpl-41f918794774418daa122a32549266f9.
INFO:     127.0.0.1:37788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:03:18 logger.py:39] Received request chatcmpl-2d9bac28ea084eef8eb96e67c225b169: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:03:18 metrics.py:455] Avg prompt throughput: 14.9 tokens/s, Avg generation throughput: 138.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
INFO 03-28 16:03:18 engine.py:280] Added request chatcmpl-2d9bac28ea084eef8eb96e67c225b169.
INFO:     127.0.0.1:37730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:03:19 logger.py:39] Received request chatcmpl-271a52cd19344ddd9ce9511e7b266a52: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:03:20 engine.py:280] Added request chatcmpl-271a52cd19344ddd9ce9511e7b266a52.
INFO 03-28 16:03:23 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 137.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:03:24 logger.py:39] Received request chatcmpl-1664934c22f04eb5bdb4c7522ab7789e: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:03:25 engine.py:280] Added request chatcmpl-1664934c22f04eb5bdb4c7522ab7789e.
INFO 03-28 16:03:28 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 136.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:03:30 logger.py:39] Received request chatcmpl-b7037e1147c848c2a1b5d41e1a207240: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:03:30 engine.py:280] Added request chatcmpl-b7037e1147c848c2a1b5d41e1a207240.
INFO:     127.0.0.1:37792 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:03:32 logger.py:39] Received request chatcmpl-2c419d109d3b4832b8fb1793a013e1ac: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:03:32 engine.py:280] Added request chatcmpl-2c419d109d3b4832b8fb1793a013e1ac.
INFO 03-28 16:03:33 metrics.py:455] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 124.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:03:37 logger.py:39] Received request chatcmpl-b02115244dc345eaae9263a685088304: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:03:37 engine.py:280] Added request chatcmpl-b02115244dc345eaae9263a685088304.
INFO 03-28 16:03:38 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 137.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:03:43 logger.py:39] Received request chatcmpl-25197cd09b5a4688badbdabf72d1be64: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:03:43 metrics.py:455] Avg prompt throughput: 15.4 tokens/s, Avg generation throughput: 139.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO 03-28 16:03:43 engine.py:280] Added request chatcmpl-25197cd09b5a4688badbdabf72d1be64.
INFO:     127.0.0.1:37790 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:03:48 logger.py:39] Received request chatcmpl-625f01599ae241a4840719028353d804: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:03:48 metrics.py:455] Avg prompt throughput: 15.2 tokens/s, Avg generation throughput: 138.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO 03-28 16:03:48 engine.py:280] Added request chatcmpl-625f01599ae241a4840719028353d804.
INFO:     127.0.0.1:37810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:03:50 logger.py:39] Received request chatcmpl-89485c91d5bc4090b1decb19b18fdb8c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:03:50 engine.py:280] Added request chatcmpl-89485c91d5bc4090b1decb19b18fdb8c.
INFO 03-28 16:03:53 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 136.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:03:54 logger.py:39] Received request chatcmpl-09e1f4eed5a94755bb4d18c918734e61: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) sofa\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:03:54 engine.py:280] Added request chatcmpl-09e1f4eed5a94755bb4d18c918734e61.
INFO:     127.0.0.1:37778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:03:56 logger.py:39] Received request chatcmpl-72ab54dc445d40899426cb95cd10c1a8: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) chair\n(B) shelves\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:03:56 engine.py:280] Added request chatcmpl-72ab54dc445d40899426cb95cd10c1a8.
INFO 03-28 16:03:58 metrics.py:455] Avg prompt throughput: 31.6 tokens/s, Avg generation throughput: 122.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:01 logger.py:39] Received request chatcmpl-ce237f87d08b4597b241a0c10c88260a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:01 engine.py:280] Added request chatcmpl-ce237f87d08b4597b241a0c10c88260a.
INFO:     127.0.0.1:37812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:01 logger.py:39] Received request chatcmpl-d52b48b006b746f593eb913e2cbf1ed0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) shelves\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:01 engine.py:280] Added request chatcmpl-d52b48b006b746f593eb913e2cbf1ed0.
INFO:     127.0.0.1:37694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:02 logger.py:39] Received request chatcmpl-fa6be503ea214db49d09cacebb18e07e: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:02 engine.py:280] Added request chatcmpl-fa6be503ea214db49d09cacebb18e07e.
INFO 03-28 16:04:03 metrics.py:455] Avg prompt throughput: 47.9 tokens/s, Avg generation throughput: 109.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:06 logger.py:39] Received request chatcmpl-f0eda3456d774fbead46600fdb492de5: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the floor mat (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) floor mat\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:07 engine.py:280] Added request chatcmpl-f0eda3456d774fbead46600fdb492de5.
INFO:     127.0.0.1:37788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:07 logger.py:39] Received request chatcmpl-ea4330d62449479f926f80c530a78d07: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:08 engine.py:280] Added request chatcmpl-ea4330d62449479f926f80c530a78d07.
INFO 03-28 16:04:08 metrics.py:455] Avg prompt throughput: 31.2 tokens/s, Avg generation throughput: 124.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:09 logger.py:39] Received request chatcmpl-53cdd4e3aafc42b2b17d496567258860: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:09 engine.py:280] Added request chatcmpl-53cdd4e3aafc42b2b17d496567258860.
INFO:     127.0.0.1:37714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:12 logger.py:39] Received request chatcmpl-56fde22a08234e9b9f1e585fd2d63db4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the counter (highlighted by a blue box)?\n(A) lamp\n(B) counter\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:13 engine.py:280] Added request chatcmpl-56fde22a08234e9b9f1e585fd2d63db4.
INFO 03-28 16:04:13 metrics.py:455] Avg prompt throughput: 32.0 tokens/s, Avg generation throughput: 122.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:14 logger.py:39] Received request chatcmpl-2c5588ec1e3e44bf829d492a4af3006f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:14 engine.py:280] Added request chatcmpl-2c5588ec1e3e44bf829d492a4af3006f.
INFO:     127.0.0.1:37792 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:15 logger.py:39] Received request chatcmpl-2fc3aafb4c1442589e1312a2cd58fc06: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:15 engine.py:280] Added request chatcmpl-2fc3aafb4c1442589e1312a2cd58fc06.
INFO:     127.0.0.1:37804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:16 logger.py:39] Received request chatcmpl-e52139fca8f047ec87abb310c93bff31: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:16 engine.py:280] Added request chatcmpl-e52139fca8f047ec87abb310c93bff31.
INFO 03-28 16:04:18 metrics.py:455] Avg prompt throughput: 47.2 tokens/s, Avg generation throughput: 107.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:21 logger.py:39] Received request chatcmpl-9171b1355800430fbaa35d1c47cfa613: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:21 engine.py:280] Added request chatcmpl-9171b1355800430fbaa35d1c47cfa613.
INFO:     127.0.0.1:37790 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:22 logger.py:39] Received request chatcmpl-1d2cb466c5094d1399871d340692d1d2: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) sofa\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:22 engine.py:280] Added request chatcmpl-1d2cb466c5094d1399871d340692d1d2.
INFO 03-28 16:04:23 metrics.py:455] Avg prompt throughput: 31.2 tokens/s, Avg generation throughput: 122.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:26 logger.py:39] Received request chatcmpl-e9c3bc617e944a25811967fa878ace99: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:26 engine.py:280] Added request chatcmpl-e9c3bc617e944a25811967fa878ace99.
INFO 03-28 16:04:28 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 139.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:29 logger.py:39] Received request chatcmpl-6666a8b3f6fd44a281ff1cf5bc61b138: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) shelves\n(B) mirror\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:29 engine.py:280] Added request chatcmpl-6666a8b3f6fd44a281ff1cf5bc61b138.
INFO:     127.0.0.1:37772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:33 logger.py:39] Received request chatcmpl-e32b4699b3de4dd5b9a56dbdbc1e1dc0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:33 metrics.py:455] Avg prompt throughput: 30.9 tokens/s, Avg generation throughput: 123.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO 03-28 16:04:33 engine.py:280] Added request chatcmpl-e32b4699b3de4dd5b9a56dbdbc1e1dc0.
INFO 03-28 16:04:38 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 150.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO 03-28 16:04:43 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:44 logger.py:39] Received request chatcmpl-df878830aaf643b18df94056fa47cf82: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:44 engine.py:280] Added request chatcmpl-df878830aaf643b18df94056fa47cf82.
INFO:     127.0.0.1:37810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:47 logger.py:39] Received request chatcmpl-5b8eeef529714b7294a654b41795e83c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:47 engine.py:280] Added request chatcmpl-5b8eeef529714b7294a654b41795e83c.
INFO 03-28 16:04:48 metrics.py:455] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 123.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO 03-28 16:04:53 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 153.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:04:57 logger.py:39] Received request chatcmpl-d8149273b7c3418bb1ace2393ff2bb3b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:04:58 engine.py:280] Added request chatcmpl-d8149273b7c3418bb1ace2393ff2bb3b.
INFO 03-28 16:04:58 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 136.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:05:02 logger.py:39] Received request chatcmpl-b203a22f3af24642a6e8836051821dd0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:05:02 engine.py:280] Added request chatcmpl-b203a22f3af24642a6e8836051821dd0.
INFO 03-28 16:05:03 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 137.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.
INFO 03-28 16:05:08 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 151.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:05:12 logger.py:39] Received request chatcmpl-706d080b02654993ad6b9eeff2cea4eb: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:05:13 engine.py:280] Added request chatcmpl-706d080b02654993ad6b9eeff2cea4eb.
INFO 03-28 16:05:13 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 138.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:05:15 logger.py:39] Received request chatcmpl-f66ed44da7c646b4a543586c64db348f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:05:16 engine.py:280] Added request chatcmpl-f66ed44da7c646b4a543586c64db348f.
INFO 03-28 16:05:18 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 137.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.
INFO 03-28 16:05:23 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:05:26 logger.py:39] Received request chatcmpl-49dbc07e28fc4453b5358d4e89217c44: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) bookcase\n(B) pillow\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:05:26 engine.py:280] Added request chatcmpl-49dbc07e28fc4453b5358d4e89217c44.
INFO 03-28 16:05:28 metrics.py:455] Avg prompt throughput: 16.0 tokens/s, Avg generation throughput: 138.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:05:31 logger.py:39] Received request chatcmpl-874ae151c3b4480981db5767c8d46392: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) shelves\n(B) pillow\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:05:31 engine.py:280] Added request chatcmpl-874ae151c3b4480981db5767c8d46392.
INFO 03-28 16:05:33 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 138.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO 03-28 16:05:38 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 150.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:05:41 logger.py:39] Received request chatcmpl-13a8abfb21b4418d83eab237ef71ea12: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:05:41 engine.py:280] Added request chatcmpl-13a8abfb21b4418d83eab237ef71ea12.
INFO 03-28 16:05:43 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 137.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37792 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:05:44 logger.py:39] Received request chatcmpl-e81e5697935f4f2ca39f820512a80553: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:05:44 engine.py:280] Added request chatcmpl-e81e5697935f4f2ca39f820512a80553.
INFO:     127.0.0.1:37790 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:05:47 logger.py:39] Received request chatcmpl-dc5a067435d449baa8e520dc42ffc994: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:05:47 engine.py:280] Added request chatcmpl-dc5a067435d449baa8e520dc42ffc994.
INFO 03-28 16:05:48 metrics.py:455] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 124.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:05:50 logger.py:39] Received request chatcmpl-32cd6626463a4e32a2b4f5493c1d2be5: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:05:50 engine.py:280] Added request chatcmpl-32cd6626463a4e32a2b4f5493c1d2be5.
INFO 03-28 16:05:53 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 138.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:05:56 logger.py:39] Received request chatcmpl-467fb3445fcd4f6cbbd550c2262449a0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:05:56 engine.py:280] Added request chatcmpl-467fb3445fcd4f6cbbd550c2262449a0.
INFO 03-28 16:05:58 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 137.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:00 logger.py:39] Received request chatcmpl-f8518f4a77924931a989bc114b35e0e4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:00 engine.py:280] Added request chatcmpl-f8518f4a77924931a989bc114b35e0e4.
INFO 03-28 16:06:03 metrics.py:455] Avg prompt throughput: 16.0 tokens/s, Avg generation throughput: 137.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:06 logger.py:39] Received request chatcmpl-ac449a9c14e44eb38d43c81ff559605c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:06 engine.py:280] Added request chatcmpl-ac449a9c14e44eb38d43c81ff559605c.
INFO 03-28 16:06:08 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 137.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO 03-28 16:06:13 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:16 logger.py:39] Received request chatcmpl-0a2b9b5c9f50491a874977d346f7ce7b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) table\n(B) blinds\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:17 engine.py:280] Added request chatcmpl-0a2b9b5c9f50491a874977d346f7ce7b.
INFO 03-28 16:06:18 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 137.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:19 logger.py:39] Received request chatcmpl-d9bb9cf792744e23aaa6e2c8eb8b4b4c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:19 engine.py:280] Added request chatcmpl-d9bb9cf792744e23aaa6e2c8eb8b4b4c.
INFO:     127.0.0.1:37694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:23 logger.py:39] Received request chatcmpl-260b0547e24543ce97a8e53cfc0283df: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:23 engine.py:280] Added request chatcmpl-260b0547e24543ce97a8e53cfc0283df.
INFO 03-28 16:06:23 metrics.py:455] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 123.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:26 logger.py:39] Received request chatcmpl-8978afbe349a4e8999fbc7364a6aa892: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:26 engine.py:280] Added request chatcmpl-8978afbe349a4e8999fbc7364a6aa892.
INFO 03-28 16:06:28 metrics.py:455] Avg prompt throughput: 15.9 tokens/s, Avg generation throughput: 138.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:32 logger.py:39] Received request chatcmpl-52f8a27210f34e7e9e5bfcd15f007a99: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:32 engine.py:280] Added request chatcmpl-52f8a27210f34e7e9e5bfcd15f007a99.
INFO 03-28 16:06:33 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 138.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:36 logger.py:39] Received request chatcmpl-fdddaad5c3f748b0954b2f4684a8d513: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:36 engine.py:280] Added request chatcmpl-fdddaad5c3f748b0954b2f4684a8d513.
INFO:     127.0.0.1:37714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:38 logger.py:39] Received request chatcmpl-88299615d4e640519df88481c6cf88d4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:38 engine.py:280] Added request chatcmpl-88299615d4e640519df88481c6cf88d4.
INFO 03-28 16:06:38 metrics.py:455] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 123.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:42 logger.py:39] Received request chatcmpl-c6b0d2545a3a4bcc91ffad59ba461ca2: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:42 engine.py:280] Added request chatcmpl-c6b0d2545a3a4bcc91ffad59ba461ca2.
INFO:     127.0.0.1:37792 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:43 logger.py:39] Received request chatcmpl-bf7d8eeb75284d46acd03485e8bea3d4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:43 metrics.py:455] Avg prompt throughput: 30.6 tokens/s, Avg generation throughput: 126.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.
INFO 03-28 16:06:44 engine.py:280] Added request chatcmpl-bf7d8eeb75284d46acd03485e8bea3d4.
INFO:     127.0.0.1:37790 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:47 logger.py:39] Received request chatcmpl-9349e3059b3d473fb7f85fbe2110eb0f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:48 engine.py:280] Added request chatcmpl-9349e3059b3d473fb7f85fbe2110eb0f.
INFO 03-28 16:06:48 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 137.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:49 logger.py:39] Received request chatcmpl-bd8f2ffae71542d0815920531b73ca9b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:49 engine.py:280] Added request chatcmpl-bd8f2ffae71542d0815920531b73ca9b.
INFO:     127.0.0.1:37756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:51 logger.py:39] Received request chatcmpl-177607ce681f4ca2899afd7db622f77c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:51 engine.py:280] Added request chatcmpl-177607ce681f4ca2899afd7db622f77c.
INFO 03-28 16:06:54 metrics.py:455] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 124.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:54 logger.py:39] Received request chatcmpl-207e64a6fe5c4feab1f262980fdb4d76: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) box\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:54 engine.py:280] Added request chatcmpl-207e64a6fe5c4feab1f262980fdb4d76.
INFO:     127.0.0.1:37810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:06:56 logger.py:39] Received request chatcmpl-56a6de259bf04a23893b93c95309eada: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:06:56 engine.py:280] Added request chatcmpl-56a6de259bf04a23893b93c95309eada.
INFO 03-28 16:06:59 metrics.py:455] Avg prompt throughput: 31.2 tokens/s, Avg generation throughput: 122.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:07:02 logger.py:39] Received request chatcmpl-8aa72d78fe24456eb3d6b14f3a8e462b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:07:02 engine.py:280] Added request chatcmpl-8aa72d78fe24456eb3d6b14f3a8e462b.
INFO 03-28 16:07:04 metrics.py:455] Avg prompt throughput: 16.0 tokens/s, Avg generation throughput: 138.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:07:08 logger.py:39] Received request chatcmpl-ceddf6b8782a48a1a842ce6301b3a8d5: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:07:08 engine.py:280] Added request chatcmpl-ceddf6b8782a48a1a842ce6301b3a8d5.
INFO 03-28 16:07:09 metrics.py:455] Avg prompt throughput: 16.0 tokens/s, Avg generation throughput: 138.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO 03-28 16:07:14 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:07:18 logger.py:39] Received request chatcmpl-941abec8c8e44907a45dc548bbe9460f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) table\n(B) shelves\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:07:18 engine.py:280] Added request chatcmpl-941abec8c8e44907a45dc548bbe9460f.
INFO 03-28 16:07:19 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 136.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:07:19 logger.py:39] Received request chatcmpl-8bd81cab8b974ee3a77411c0cee1e4bc: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:07:19 engine.py:280] Added request chatcmpl-8bd81cab8b974ee3a77411c0cee1e4bc.
INFO 03-28 16:07:24 metrics.py:455] Avg prompt throughput: 16.0 tokens/s, Avg generation throughput: 138.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:07:24 logger.py:39] Received request chatcmpl-ba864193ac914a2b85b08d279a68e242: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) lamp\n(B) door\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:07:24 engine.py:280] Added request chatcmpl-ba864193ac914a2b85b08d279a68e242.
INFO:     127.0.0.1:37812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:07:25 logger.py:39] Received request chatcmpl-904820f1f5724ebdb0cab5ac9d75e411: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:07:25 engine.py:280] Added request chatcmpl-904820f1f5724ebdb0cab5ac9d75e411.
INFO 03-28 16:07:29 metrics.py:455] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 123.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:07:30 logger.py:39] Received request chatcmpl-1996f67ee2f9408e83d470b0996ff08d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) lamp\n(B) shelves\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:07:30 engine.py:280] Added request chatcmpl-1996f67ee2f9408e83d470b0996ff08d.
INFO 03-28 16:07:34 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 138.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:07:37 logger.py:39] Received request chatcmpl-5515f06b935d4f65a44b7e629cffc6dd: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:07:38 engine.py:280] Added request chatcmpl-5515f06b935d4f65a44b7e629cffc6dd.
INFO 03-28 16:07:39 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 138.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.
INFO 03-28 16:07:44 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:07:47 logger.py:39] Received request chatcmpl-2b0411511c1e43e8b6016e879707beb6: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) books\n(B) mirror\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:07:47 engine.py:280] Added request chatcmpl-2b0411511c1e43e8b6016e879707beb6.
INFO 03-28 16:07:49 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 138.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:07:54 logger.py:39] Received request chatcmpl-560ab6d1b9f1464eb24b465d83b5b373: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:07:54 metrics.py:455] Avg prompt throughput: 14.4 tokens/s, Avg generation throughput: 140.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 11 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO 03-28 16:07:54 engine.py:280] Added request chatcmpl-560ab6d1b9f1464eb24b465d83b5b373.
INFO:     127.0.0.1:37792 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:07:59 logger.py:39] Received request chatcmpl-dc7bd3a08e5b4b9794402c63325f534c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) pillow\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:07:59 engine.py:280] Added request chatcmpl-dc7bd3a08e5b4b9794402c63325f534c.
INFO 03-28 16:07:59 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 136.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.6%, CPU KV cache usage: 0.0%.
INFO 03-28 16:08:04 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37790 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:08:06 logger.py:39] Received request chatcmpl-a537241853de4975b3ff9631f7934a67: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:08:06 engine.py:280] Added request chatcmpl-a537241853de4975b3ff9631f7934a67.
INFO 03-28 16:08:09 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 138.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO 03-28 16:08:14 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:08:16 logger.py:39] Received request chatcmpl-56302b84ee7241a7b0d7de6379e205dc: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:08:16 engine.py:280] Added request chatcmpl-56302b84ee7241a7b0d7de6379e205dc.
INFO 03-28 16:08:19 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 138.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:08:21 logger.py:39] Received request chatcmpl-386a643a8b974cc6b62372b4b66f344e: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:08:21 engine.py:280] Added request chatcmpl-386a643a8b974cc6b62372b4b66f344e.
INFO:     127.0.0.1:37756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:08:23 logger.py:39] Received request chatcmpl-2aa83d59e0464804b57513f418959612: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:08:23 engine.py:280] Added request chatcmpl-2aa83d59e0464804b57513f418959612.
INFO 03-28 16:08:24 metrics.py:455] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 122.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:08:28 logger.py:39] Received request chatcmpl-095b226ed42b4bbfb6bb67e32dd3d72b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:08:28 engine.py:280] Added request chatcmpl-095b226ed42b4bbfb6bb67e32dd3d72b.
INFO:     127.0.0.1:37804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:08:29 logger.py:39] Received request chatcmpl-c0ab68c2dcf343799b40fcf0bf6fdc2f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) door\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:08:29 engine.py:280] Added request chatcmpl-c0ab68c2dcf343799b40fcf0bf6fdc2f.
INFO 03-28 16:08:29 metrics.py:455] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 124.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.4%, CPU KV cache usage: 0.0%.
INFO 03-28 16:08:34 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 153.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:08:35 logger.py:39] Received request chatcmpl-de4cdb4e25e942dd8cad063f74a196f0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:08:35 engine.py:280] Added request chatcmpl-de4cdb4e25e942dd8cad063f74a196f0.
INFO:     127.0.0.1:37810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:08:37 logger.py:39] Received request chatcmpl-be8d1fae3c5641b886f319db040eec22: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:08:37 engine.py:280] Added request chatcmpl-be8d1fae3c5641b886f319db040eec22.
INFO 03-28 16:08:39 metrics.py:455] Avg prompt throughput: 31.2 tokens/s, Avg generation throughput: 121.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:08:42 logger.py:39] Received request chatcmpl-36eed2c2a9e9479fb75e4570792b0025: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:08:42 engine.py:280] Added request chatcmpl-36eed2c2a9e9479fb75e4570792b0025.
INFO 03-28 16:08:44 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 138.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO 03-28 16:08:49 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:08:52 logger.py:39] Received request chatcmpl-0b85ebf840914690805dec2882791f44: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:08:52 engine.py:280] Added request chatcmpl-0b85ebf840914690805dec2882791f44.
INFO 03-28 16:08:54 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 138.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:08:58 logger.py:39] Received request chatcmpl-8b7cd3d4e581443eb653a54e79dff5ab: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<|image|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:08:58 engine.py:280] Added request chatcmpl-8b7cd3d4e581443eb653a54e79dff5ab.
INFO 03-28 16:08:59 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 139.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 12 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:09:04 metrics.py:455] Avg prompt throughput: 30.4 tokens/s, Avg generation throughput: 128.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 10 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37792 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:09:09 metrics.py:455] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 140.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 9 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:09:15 metrics.py:455] Avg prompt throughput: 30.2 tokens/s, Avg generation throughput: 127.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO 03-28 16:09:20 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37730 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:09:25 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 140.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 6 reqs, GPU KV cache usage: 14.8%, CPU KV cache usage: 0.0%.
INFO 03-28 16:09:30 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 6 reqs, GPU KV cache usage: 15.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37790 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:09:35 metrics.py:455] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 139.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 5 reqs, GPU KV cache usage: 15.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:09:40 metrics.py:455] Avg prompt throughput: 16.0 tokens/s, Avg generation throughput: 139.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 4 reqs, GPU KV cache usage: 15.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:09:45 metrics.py:455] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 126.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 2 reqs, GPU KV cache usage: 14.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:09:50 metrics.py:455] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 127.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 14.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37788 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:09:55 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 90.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.3%, CPU KV cache usage: 0.0%.
INFO 03-28 16:10:00 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 76.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%.
INFO 03-28 16:10:05 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 76.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37810 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:10:10 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 61.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%.
INFO 03-28 16:10:15 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
