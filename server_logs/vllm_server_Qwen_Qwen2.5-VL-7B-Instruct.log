INFO 03-28 16:54:59 [__init__.py:239] Automatically detected platform cuda.
INFO 03-28 16:55:03 [api_server.py:981] vLLM API server version 0.8.2
INFO 03-28 16:55:03 [api_server.py:982] args: Namespace(subparser='serve', model_tag='Qwen/Qwen2.5-VL-7B-Instruct', config='', host=None, port=27182, uvicorn_log_level='info', disable_uvicorn_access_log=False, allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, chat_template_content_format='auto', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, enable_ssl_refresh=False, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='Qwen/Qwen2.5-VL-7B-Instruct', task='auto', tokenizer=None, hf_config_path=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, allowed_local_media_path=None, download_dir=None, load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', max_model_len=16384, guided_decoding_backend='xgrammar', logits_processor_pattern=None, model_impl='auto', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=2, enable_expert_parallel=False, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=None, enable_prefix_caching=None, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=None, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.95, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_partial_prefills=1, max_long_partial_prefills=1, long_prefill_token_threshold=0, max_num_seqs=None, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_overrides=None, enforce_eager=False, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt={'image': 5}, mm_processor_kwargs={'images_kwargs.do_resize': True, 'images_kwargs.size.shortest_edge': 3136, 'images_kwargs.size.longest_edge': 250880}, disable_mm_preprocessor_cache=False, enable_lora=False, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, use_tqdm_on_load=True, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_config=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, scheduling_policy='fcfs', scheduler_cls='vllm.core.scheduler.Scheduler', override_neuron_config=None, override_pooler_config=None, compilation_config=None, kv_transfer_config=None, worker_cls='auto', worker_extension_cls='', generation_config='auto', override_generation_config=None, enable_sleep_mode=False, calculate_kv_scales=False, additional_config=None, enable_reasoning=False, reasoning_parser=None, disable_cascade_attn=False, disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False, enable_server_load_tracking=False, dispatch_function=<function ServeSubcommand.cmd at 0x7f38679f0cc0>)
INFO 03-28 16:55:13 [config.py:585] This model supports multiple tasks: {'reward', 'classify', 'embed', 'generate', 'score'}. Defaulting to 'generate'.
INFO 03-28 16:55:13 [config.py:1519] Defaulting to use mp for distributed inference
INFO 03-28 16:55:13 [config.py:1697] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 03-28 16:55:20 [__init__.py:239] Automatically detected platform cuda.
INFO 03-28 16:55:22 [core.py:54] Initializing a V1 LLM engine (v0.8.2) with config: model='Qwen/Qwen2.5-VL-7B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-VL-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=16384, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=Qwen/Qwen2.5-VL-7B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs={'images_kwargs.do_resize': True, 'images_kwargs.size.shortest_edge': 3136, 'images_kwargs.size.longest_edge': 250880}, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 03-28 16:55:22 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 4 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 03-28 16:55:22 [shm_broadcast.py:259] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1], buffer_handle=(2, 10485760, 10, 'psm_cdeb3b65'), local_subscribe_addr='ipc:///tmp/dff3f929-c2b4-47d3-9f07-94a5a050a816', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-28 16:55:28 [__init__.py:239] Automatically detected platform cuda.
WARNING 03-28 16:55:34 [utils.py:2321] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7efc247300e0>
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:55:34 [shm_broadcast.py:259] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_edc4e788'), local_subscribe_addr='ipc:///tmp/2dfbfa90-cea6-44ef-b8b7-ad65fbf705b4', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-28 16:55:40 [__init__.py:239] Automatically detected platform cuda.
WARNING 03-28 16:55:43 [utils.py:2321] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fd2873f0e00>
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:55:43 [shm_broadcast.py:259] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_45eaef9f'), local_subscribe_addr='ipc:///tmp/dbee3d03-454f-4e1c-ac0e-1d83cb4d3d9a', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:55:44 [utils.py:931] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:55:44 [utils.py:931] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:55:44 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:55:44 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:55:44 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /nfshomes/sriramb/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:55:44 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /nfshomes/sriramb/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:55:44 [shm_broadcast.py:259] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_3fe8bf19'), local_subscribe_addr='ipc:///tmp/852e073b-569d-4fd5-ab45-bf23abdd5933', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:55:44 [parallel_state.py:954] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:55:44 [parallel_state.py:954] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:55:44 [cuda.py:220] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:55:44 [cuda.py:220] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=331582)[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
[1;36m(VllmWorker rank=1 pid=331631)[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:55:45 [gpu_model_runner.py:1174] Starting to load model Qwen/Qwen2.5-VL-7B-Instruct...
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:55:45 [gpu_model_runner.py:1174] Starting to load model Qwen/Qwen2.5-VL-7B-Instruct...
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:55:45 [config.py:3243] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:55:45 [config.py:3243] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
[1;36m(VllmWorker rank=1 pid=331631)[0;0m WARNING 03-28 16:55:45 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=0 pid=331582)[0;0m WARNING 03-28 16:55:45 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:55:45 [weight_utils.py:265] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:55:45 [weight_utils.py:265] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=0 pid=331582)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/5 [00:00<?, ?it/s]
[1;36m(VllmWorker rank=0 pid=331582)[0;0m Loading safetensors checkpoint shards:  20% Completed | 1/5 [00:00<00:01,  2.73it/s]
[1;36m(VllmWorker rank=0 pid=331582)[0;0m Loading safetensors checkpoint shards:  40% Completed | 2/5 [00:00<00:00,  4.74it/s]
[1;36m(VllmWorker rank=0 pid=331582)[0;0m Loading safetensors checkpoint shards:  60% Completed | 3/5 [00:00<00:00,  3.43it/s]
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:55:47 [loader.py:447] Loading weights took 1.67 seconds
[1;36m(VllmWorker rank=0 pid=331582)[0;0m Loading safetensors checkpoint shards:  80% Completed | 4/5 [00:01<00:00,  2.93it/s]
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:55:47 [gpu_model_runner.py:1186] Model loading took 7.8685 GB and 2.175871 seconds
[1;36m(VllmWorker rank=0 pid=331582)[0;0m Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:01<00:00,  2.91it/s]
[1;36m(VllmWorker rank=0 pid=331582)[0;0m Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:01<00:00,  3.08it/s]
[1;36m(VllmWorker rank=0 pid=331582)[0;0m 
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:55:47 [loader.py:447] Loading weights took 1.66 seconds
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:55:47 [gpu_model_runner.py:1186] Model loading took 7.8685 GB and 2.647184 seconds
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:55:47 [gpu_model_runner.py:1456] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:55:47 [gpu_model_runner.py:1456] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.
[1;36m(VllmWorker rank=0 pid=331582)[0;0m Keyword argument `images_kwargs.do_resize` is not a valid argument for this processor and will be ignored.
[1;36m(VllmWorker rank=0 pid=331582)[0;0m Keyword argument `images_kwargs.size.shortest_edge` is not a valid argument for this processor and will be ignored.
[1;36m(VllmWorker rank=0 pid=331582)[0;0m Keyword argument `images_kwargs.size.longest_edge` is not a valid argument for this processor and will be ignored.
[1;36m(VllmWorker rank=1 pid=331631)[0;0m Keyword argument `images_kwargs.do_resize` is not a valid argument for this processor and will be ignored.
[1;36m(VllmWorker rank=1 pid=331631)[0;0m Keyword argument `images_kwargs.size.shortest_edge` is not a valid argument for this processor and will be ignored.
[1;36m(VllmWorker rank=1 pid=331631)[0;0m Keyword argument `images_kwargs.size.longest_edge` is not a valid argument for this processor and will be ignored.
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:56:08 [backends.py:415] Using cache directory: /nfshomes/sriramb/.cache/vllm/torch_compile_cache/e0fe43e33b/rank_0_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:56:08 [backends.py:415] Using cache directory: /nfshomes/sriramb/.cache/vllm/torch_compile_cache/e0fe43e33b/rank_1_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:56:08 [backends.py:425] Dynamo bytecode transform time: 8.04 s
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:56:08 [backends.py:425] Dynamo bytecode transform time: 8.04 s
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:56:08 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:56:08 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:56:15 [monitor.py:33] torch.compile takes 8.04 s in total
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:56:15 [monitor.py:33] torch.compile takes 8.04 s in total
INFO 03-28 16:56:16 [kv_cache_utils.py:566] GPU KV cache size: 17,360 tokens
INFO 03-28 16:56:16 [kv_cache_utils.py:569] Maximum concurrency for 16,384 tokens per request: 1.06x
INFO 03-28 16:56:16 [kv_cache_utils.py:566] GPU KV cache size: 17,360 tokens
INFO 03-28 16:56:16 [kv_cache_utils.py:569] Maximum concurrency for 16,384 tokens per request: 1.06x
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:56:39 [custom_all_reduce.py:229] Registering 3752 cuda graph addresses
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:56:39 [custom_all_reduce.py:229] Registering 3752 cuda graph addresses
[1;36m(VllmWorker rank=1 pid=331631)[0;0m INFO 03-28 16:56:39 [gpu_model_runner.py:1534] Graph capturing finished in 23 secs, took 0.49 GiB
[1;36m(VllmWorker rank=0 pid=331582)[0;0m INFO 03-28 16:56:39 [gpu_model_runner.py:1534] Graph capturing finished in 23 secs, took 0.49 GiB
INFO 03-28 16:56:39 [core.py:151] init engine (profile, create kv cache, warmup model) took 51.48 seconds
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
WARNING 03-28 16:56:40 [config.py:1028] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
INFO 03-28 16:56:40 [serving_chat.py:115] Using default chat sampling params from model: {'repetition_penalty': 1.05, 'temperature': 1e-06}
INFO 03-28 16:56:40 [serving_completion.py:61] Using default completion sampling params from model: {'repetition_penalty': 1.05, 'temperature': 1e-06}
INFO 03-28 16:56:40 [api_server.py:1028] Starting vLLM API server on http://0.0.0.0:27182
INFO 03-28 16:56:40 [launcher.py:26] Available routes are:
INFO 03-28 16:56:40 [launcher.py:34] Route: /openapi.json, Methods: HEAD, GET
INFO 03-28 16:56:40 [launcher.py:34] Route: /docs, Methods: HEAD, GET
INFO 03-28 16:56:40 [launcher.py:34] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 03-28 16:56:40 [launcher.py:34] Route: /redoc, Methods: HEAD, GET
INFO 03-28 16:56:40 [launcher.py:34] Route: /health, Methods: GET
INFO 03-28 16:56:40 [launcher.py:34] Route: /load, Methods: GET
INFO 03-28 16:56:40 [launcher.py:34] Route: /ping, Methods: POST, GET
INFO 03-28 16:56:40 [launcher.py:34] Route: /tokenize, Methods: POST
INFO 03-28 16:56:40 [launcher.py:34] Route: /detokenize, Methods: POST
INFO 03-28 16:56:40 [launcher.py:34] Route: /v1/models, Methods: GET
INFO 03-28 16:56:40 [launcher.py:34] Route: /version, Methods: GET
INFO 03-28 16:56:40 [launcher.py:34] Route: /v1/chat/completions, Methods: POST
INFO 03-28 16:56:40 [launcher.py:34] Route: /v1/completions, Methods: POST
INFO 03-28 16:56:40 [launcher.py:34] Route: /v1/embeddings, Methods: POST
INFO 03-28 16:56:40 [launcher.py:34] Route: /pooling, Methods: POST
INFO 03-28 16:56:40 [launcher.py:34] Route: /score, Methods: POST
INFO 03-28 16:56:40 [launcher.py:34] Route: /v1/score, Methods: POST
INFO 03-28 16:56:40 [launcher.py:34] Route: /v1/audio/transcriptions, Methods: POST
INFO 03-28 16:56:40 [launcher.py:34] Route: /rerank, Methods: POST
INFO 03-28 16:56:40 [launcher.py:34] Route: /v1/rerank, Methods: POST
INFO 03-28 16:56:40 [launcher.py:34] Route: /v2/rerank, Methods: POST
INFO 03-28 16:56:40 [launcher.py:34] Route: /invocations, Methods: POST
INFO:     Started server process [330932]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     127.0.0.1:58682 - "GET /health HTTP/1.1" 200 OK
INFO 03-28 16:56:51 [loggers.py:80] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-28 16:57:01 [loggers.py:80] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-28 16:57:11 [loggers.py:80] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
INFO 03-28 16:57:17 [chat_utils.py:379] Detected the chat template content format to be 'openai'. You can set `--chat-template-content-format` to override this.
INFO 03-28 16:57:17 [logger.py:39] Received request chatcmpl-53088c72500f494c821ba9c4a96e9fa9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) desk\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
Keyword argument `images_kwargs.do_resize` is not a valid argument for this processor and will be ignored.
Keyword argument `images_kwargs.size.shortest_edge` is not a valid argument for this processor and will be ignored.
Keyword argument `images_kwargs.size.longest_edge` is not a valid argument for this processor and will be ignored.
INFO 03-28 16:57:19 [async_llm.py:221] Added request chatcmpl-53088c72500f494c821ba9c4a96e9fa9.
INFO 03-28 16:57:19 [logger.py:39] Received request chatcmpl-ba893487e3974fb6bfcf3a49f56c00e7: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:19 [async_llm.py:221] Added request chatcmpl-ba893487e3974fb6bfcf3a49f56c00e7.
INFO 03-28 16:57:19 [logger.py:39] Received request chatcmpl-b16e50c9ecb545ceb58be0e8163f4da9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:19 [async_llm.py:221] Added request chatcmpl-b16e50c9ecb545ceb58be0e8163f4da9.
INFO 03-28 16:57:19 [logger.py:39] Received request chatcmpl-8f2f0e6fa3c1436793c40afe1ddc6a1c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:19 [async_llm.py:221] Added request chatcmpl-8f2f0e6fa3c1436793c40afe1ddc6a1c.
INFO 03-28 16:57:19 [logger.py:39] Received request chatcmpl-26db4d34613c4215a509db889de15667: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:19 [async_llm.py:221] Added request chatcmpl-26db4d34613c4215a509db889de15667.
INFO 03-28 16:57:19 [logger.py:39] Received request chatcmpl-021141fce1614023be9e32f021dac8b7: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:20 [async_llm.py:221] Added request chatcmpl-021141fce1614023be9e32f021dac8b7.
INFO 03-28 16:57:20 [logger.py:39] Received request chatcmpl-08359e8c475542c8875a3ec0630222eb: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:20 [async_llm.py:221] Added request chatcmpl-08359e8c475542c8875a3ec0630222eb.
INFO 03-28 16:57:20 [logger.py:39] Received request chatcmpl-b655bf7920694cac8fa2c30275fe51d8: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:20 [async_llm.py:221] Added request chatcmpl-b655bf7920694cac8fa2c30275fe51d8.
INFO 03-28 16:57:20 [logger.py:39] Received request chatcmpl-4ce12488d31e4da9b5aa3f55d51459ea: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:20 [async_llm.py:221] Added request chatcmpl-4ce12488d31e4da9b5aa3f55d51459ea.
INFO 03-28 16:57:20 [logger.py:39] Received request chatcmpl-0462f2732380479d876123c1e86b48b5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:20 [async_llm.py:221] Added request chatcmpl-0462f2732380479d876123c1e86b48b5.
INFO 03-28 16:57:20 [logger.py:39] Received request chatcmpl-4557bd6451514b1b8a25082b62fbac3b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:20 [async_llm.py:221] Added request chatcmpl-4557bd6451514b1b8a25082b62fbac3b.
INFO 03-28 16:57:20 [logger.py:39] Received request chatcmpl-423836a62c5442509aa3ed85a673776e: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:20 [async_llm.py:221] Added request chatcmpl-423836a62c5442509aa3ed85a673776e.
INFO 03-28 16:57:20 [logger.py:39] Received request chatcmpl-4c0c24268a794277862099dd87de6d66: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sink (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) sink\n(B) pillow\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:20 [async_llm.py:221] Added request chatcmpl-4c0c24268a794277862099dd87de6d66.
INFO 03-28 16:57:20 [logger.py:39] Received request chatcmpl-baaca122963b4a0caef841a1e6f40dc0: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:20 [async_llm.py:221] Added request chatcmpl-baaca122963b4a0caef841a1e6f40dc0.
INFO 03-28 16:57:20 [logger.py:39] Received request chatcmpl-71b8306235654f5798e9a38a156bc4ce: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:21 [async_llm.py:221] Added request chatcmpl-71b8306235654f5798e9a38a156bc4ce.
INFO 03-28 16:57:21 [logger.py:39] Received request chatcmpl-67b0cb0bb0a341cd9aab282e9b7b29df: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) door\n(B) pillow\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:21 [async_llm.py:221] Added request chatcmpl-67b0cb0bb0a341cd9aab282e9b7b29df.
INFO 03-28 16:57:21 [loggers.py:80] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:30 [logger.py:39] Received request chatcmpl-c9cae4c37f8e493fb5f6b83f0d547e4c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) books\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:30 [async_llm.py:221] Added request chatcmpl-c9cae4c37f8e493fb5f6b83f0d547e4c.
INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:31 [logger.py:39] Received request chatcmpl-2590041af49340b38e31376210e5b08d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:31 [async_llm.py:221] Added request chatcmpl-2590041af49340b38e31376210e5b08d.
INFO:     127.0.0.1:59318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:31 [loggers.py:80] Avg prompt throughput: 1762.9 tokens/s, Avg generation throughput: 190.9 tokens/s, Running: 13 reqs, Waiting: 2 reqs, GPU KV cache usage: 92.4%, Prefix cache hit rate: 42.6%
INFO 03-28 16:57:31 [logger.py:39] Received request chatcmpl-df8d5b8cae6b4417be86101008c564a1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:31 [async_llm.py:221] Added request chatcmpl-df8d5b8cae6b4417be86101008c564a1.
INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:32 [logger.py:39] Received request chatcmpl-34dd474e25b04c648492a4f732a980bf: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:32 [async_llm.py:221] Added request chatcmpl-34dd474e25b04c648492a4f732a980bf.
INFO:     127.0.0.1:59294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:32 [logger.py:39] Received request chatcmpl-c9b76e90126f42c7ab6e6d537e153720: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) shelves\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:33 [async_llm.py:221] Added request chatcmpl-c9b76e90126f42c7ab6e6d537e153720.
INFO:     127.0.0.1:59190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:33 [logger.py:39] Received request chatcmpl-528e2e43331949138af391044a2d8bb3: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:33 [async_llm.py:221] Added request chatcmpl-528e2e43331949138af391044a2d8bb3.
INFO:     127.0.0.1:59196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:34 [logger.py:39] Received request chatcmpl-a18cd6930b654b72a9fc4149f5f48eba: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:34 [async_llm.py:221] Added request chatcmpl-a18cd6930b654b72a9fc4149f5f48eba.
INFO:     127.0.0.1:59274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:34 [logger.py:39] Received request chatcmpl-f0dda66add824a178fa4ebb4a5d541c6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:34 [async_llm.py:221] Added request chatcmpl-f0dda66add824a178fa4ebb4a5d541c6.
INFO:     127.0.0.1:59264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:35 [logger.py:39] Received request chatcmpl-08b1b634756543fe9a21491dc0c0418c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:35 [async_llm.py:221] Added request chatcmpl-08b1b634756543fe9a21491dc0c0418c.
INFO:     127.0.0.1:59256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:35 [logger.py:39] Received request chatcmpl-5d880bc345cc4c37acb6d9bd541d1df0: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:35 [async_llm.py:221] Added request chatcmpl-5d880bc345cc4c37acb6d9bd541d1df0.
INFO 03-28 16:57:35 [logger.py:39] Received request chatcmpl-ec36a5432d794dc689d7290219319ac6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:36 [async_llm.py:221] Added request chatcmpl-ec36a5432d794dc689d7290219319ac6.
INFO:     127.0.0.1:59310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:36 [logger.py:39] Received request chatcmpl-5c0818230b244e789919ac6fed362993: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:36 [async_llm.py:221] Added request chatcmpl-5c0818230b244e789919ac6fed362993.
INFO:     127.0.0.1:59248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:38 [logger.py:39] Received request chatcmpl-2da938b2fd314e6287fad19f4fdc8ea1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:38 [async_llm.py:221] Added request chatcmpl-2da938b2fd314e6287fad19f4fdc8ea1.
INFO:     127.0.0.1:59322 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:38 [logger.py:39] Received request chatcmpl-1711589676534f439df5bba7c4d1c6f1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:38 [async_llm.py:221] Added request chatcmpl-1711589676534f439df5bba7c4d1c6f1.
INFO:     127.0.0.1:59234 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:39 [logger.py:39] Received request chatcmpl-966fd35c8fa94549aad4251295c4fab8: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:39 [async_llm.py:221] Added request chatcmpl-966fd35c8fa94549aad4251295c4fab8.
INFO:     127.0.0.1:59284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:40 [logger.py:39] Received request chatcmpl-4d39e56717d5486fba961c3d6411afe8: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:40 [async_llm.py:221] Added request chatcmpl-4d39e56717d5486fba961c3d6411afe8.
INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:40 [logger.py:39] Received request chatcmpl-b536d8d4a4954adb90e668c4b841bda4: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) sofa\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:40 [async_llm.py:221] Added request chatcmpl-b536d8d4a4954adb90e668c4b841bda4.
INFO:     127.0.0.1:59264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:41 [loggers.py:80] Avg prompt throughput: 1649.4 tokens/s, Avg generation throughput: 239.5 tokens/s, Running: 13 reqs, Waiting: 2 reqs, GPU KV cache usage: 92.4%, Prefix cache hit rate: 22.6%
INFO 03-28 16:57:41 [logger.py:39] Received request chatcmpl-d381192bc6584a18ada302577fe57940: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) chair\n(B) shelves\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:41 [async_llm.py:221] Added request chatcmpl-d381192bc6584a18ada302577fe57940.
INFO:     127.0.0.1:59318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:42 [logger.py:39] Received request chatcmpl-d8eca94f9bef419a8d56a571ea9cefa6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:42 [async_llm.py:221] Added request chatcmpl-d8eca94f9bef419a8d56a571ea9cefa6.
INFO:     127.0.0.1:59256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:42 [logger.py:39] Received request chatcmpl-2a529a9afee34d5facd774d0f14ade76: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) shelves\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:42 [async_llm.py:221] Added request chatcmpl-2a529a9afee34d5facd774d0f14ade76.
INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:43 [logger.py:39] Received request chatcmpl-40e00e0c0c434e72b650830e0ef2674a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:43 [async_llm.py:221] Added request chatcmpl-40e00e0c0c434e72b650830e0ef2674a.
INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:44 [logger.py:39] Received request chatcmpl-984210258e374e299bf5e0d84ca4b7b5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the floor mat (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) floor mat\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:44 [async_llm.py:221] Added request chatcmpl-984210258e374e299bf5e0d84ca4b7b5.
INFO:     127.0.0.1:59274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:45 [logger.py:39] Received request chatcmpl-cbd3ccac3ec74a0b8790aa4856b4fed5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:45 [async_llm.py:221] Added request chatcmpl-cbd3ccac3ec74a0b8790aa4856b4fed5.
INFO:     127.0.0.1:59294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:45 [logger.py:39] Received request chatcmpl-65c0c4b30d814635829ad80f4ac640ff: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:45 [async_llm.py:221] Added request chatcmpl-65c0c4b30d814635829ad80f4ac640ff.
INFO:     127.0.0.1:59190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:46 [logger.py:39] Received request chatcmpl-9ac635130c4f41fa8004aa34ffd66dff: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the counter (highlighted by a blue box)?\n(A) lamp\n(B) counter\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:46 [async_llm.py:221] Added request chatcmpl-9ac635130c4f41fa8004aa34ffd66dff.
INFO:     127.0.0.1:59248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:46 [logger.py:39] Received request chatcmpl-d3a99d0f60a348dd9361facc98944876: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:46 [async_llm.py:221] Added request chatcmpl-d3a99d0f60a348dd9361facc98944876.
INFO:     127.0.0.1:59196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:47 [logger.py:39] Received request chatcmpl-f9795734c21c4b97a3ff427c072ed021: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:47 [async_llm.py:221] Added request chatcmpl-f9795734c21c4b97a3ff427c072ed021.
INFO:     127.0.0.1:59310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:47 [logger.py:39] Received request chatcmpl-c4c1fa8c39b34324bf0a0e866a6587af: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:48 [async_llm.py:221] Added request chatcmpl-c4c1fa8c39b34324bf0a0e866a6587af.
INFO:     127.0.0.1:59234 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:48 [logger.py:39] Received request chatcmpl-a7486bdadda64826be0701260656fbae: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:48 [async_llm.py:221] Added request chatcmpl-a7486bdadda64826be0701260656fbae.
INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:49 [logger.py:39] Received request chatcmpl-7a3136db18954807a515fbaa33044eab: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) sofa\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:49 [async_llm.py:221] Added request chatcmpl-7a3136db18954807a515fbaa33044eab.
INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:50 [logger.py:39] Received request chatcmpl-4102da2d08a0456eaa51a5cd1105891a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:50 [async_llm.py:221] Added request chatcmpl-4102da2d08a0456eaa51a5cd1105891a.
INFO:     127.0.0.1:59284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:51 [logger.py:39] Received request chatcmpl-607801fd816b4dcabb76a8706e0ad31a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) shelves\n(B) mirror\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:51 [async_llm.py:221] Added request chatcmpl-607801fd816b4dcabb76a8706e0ad31a.
INFO:     127.0.0.1:59322 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:51 [logger.py:39] Received request chatcmpl-67188bbd5d1646fc962dfd5712c0d0f9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:51 [async_llm.py:221] Added request chatcmpl-67188bbd5d1646fc962dfd5712c0d0f9.
INFO 03-28 16:57:51 [loggers.py:80] Avg prompt throughput: 1639.5 tokens/s, Avg generation throughput: 223.6 tokens/s, Running: 13 reqs, Waiting: 2 reqs, GPU KV cache usage: 91.5%, Prefix cache hit rate: 17.3%
INFO:     127.0.0.1:59256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:52 [logger.py:39] Received request chatcmpl-317f24139c3940b5b8931e55ef25813e: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:52 [async_llm.py:221] Added request chatcmpl-317f24139c3940b5b8931e55ef25813e.
INFO:     127.0.0.1:59264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:52 [logger.py:39] Received request chatcmpl-12f205e0eb384286879db7652ef61e3f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:52 [async_llm.py:221] Added request chatcmpl-12f205e0eb384286879db7652ef61e3f.
INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:53 [logger.py:39] Received request chatcmpl-1f9daa2ff1e14f68a8e273a4e720eb01: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:53 [async_llm.py:221] Added request chatcmpl-1f9daa2ff1e14f68a8e273a4e720eb01.
INFO:     127.0.0.1:59294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:54 [logger.py:39] Received request chatcmpl-6489e08c2dfd4e89a2d10863a13edf7b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:54 [async_llm.py:221] Added request chatcmpl-6489e08c2dfd4e89a2d10863a13edf7b.
INFO:     127.0.0.1:59318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:54 [logger.py:39] Received request chatcmpl-fbd8848583e14444bd81d22941905ba7: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:55 [async_llm.py:221] Added request chatcmpl-fbd8848583e14444bd81d22941905ba7.
INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:55 [logger.py:39] Received request chatcmpl-980183504bf942d88a1d2f389519306d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:55 [async_llm.py:221] Added request chatcmpl-980183504bf942d88a1d2f389519306d.
INFO:     127.0.0.1:59196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:56 [logger.py:39] Received request chatcmpl-054e54453bab48c592e532296bcf3187: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) bookcase\n(B) pillow\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:56 [async_llm.py:221] Added request chatcmpl-054e54453bab48c592e532296bcf3187.
INFO:     127.0.0.1:59234 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:56 [logger.py:39] Received request chatcmpl-458466aabb154bc181d41493344243f6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) shelves\n(B) pillow\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:57 [async_llm.py:221] Added request chatcmpl-458466aabb154bc181d41493344243f6.
INFO:     127.0.0.1:59274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:57 [logger.py:39] Received request chatcmpl-affe7aab338c4a40a00428623184d8a9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:57 [async_llm.py:221] Added request chatcmpl-affe7aab338c4a40a00428623184d8a9.
INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:58 [logger.py:39] Received request chatcmpl-9794b317966c4d868a90e37226614b62: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:58 [async_llm.py:221] Added request chatcmpl-9794b317966c4d868a90e37226614b62.
INFO:     127.0.0.1:59248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:58 [logger.py:39] Received request chatcmpl-c949edb91cdc4e8c8f5163e7099e4edb: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:58 [async_llm.py:221] Added request chatcmpl-c949edb91cdc4e8c8f5163e7099e4edb.
INFO:     127.0.0.1:59190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:57:59 [logger.py:39] Received request chatcmpl-6cb21dbfd03640a2ab1e9b69ed62bd34: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:59 [async_llm.py:221] Added request chatcmpl-6cb21dbfd03640a2ab1e9b69ed62bd34.
INFO 03-28 16:57:59 [logger.py:39] Received request chatcmpl-2f40f2f217bf48ffbb36d396e706eb7d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:57:59 [async_llm.py:221] Added request chatcmpl-2f40f2f217bf48ffbb36d396e706eb7d.
INFO:     127.0.0.1:59284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:00 [logger.py:39] Received request chatcmpl-a0566d379183475791b3b935fa5e068d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:00 [async_llm.py:221] Added request chatcmpl-a0566d379183475791b3b935fa5e068d.
INFO:     127.0.0.1:59310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:00 [logger.py:39] Received request chatcmpl-aa71de62f48a4e53b9657f06965ffd73: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:00 [async_llm.py:221] Added request chatcmpl-aa71de62f48a4e53b9657f06965ffd73.
INFO:     127.0.0.1:59322 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:01 [logger.py:39] Received request chatcmpl-532e9a9886c54d48b51f57847076d2de: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) table\n(B) blinds\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:01 [async_llm.py:221] Added request chatcmpl-532e9a9886c54d48b51f57847076d2de.
INFO 03-28 16:58:01 [loggers.py:80] Avg prompt throughput: 1874.1 tokens/s, Avg generation throughput: 234.0 tokens/s, Running: 14 reqs, Waiting: 2 reqs, GPU KV cache usage: 97.1%, Prefix cache hit rate: 14.4%
INFO:     127.0.0.1:59256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:02 [logger.py:39] Received request chatcmpl-0051d3cda61e470d9fafddee7b754ff6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:02 [async_llm.py:221] Added request chatcmpl-0051d3cda61e470d9fafddee7b754ff6.
INFO:     127.0.0.1:59264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:02 [logger.py:39] Received request chatcmpl-9951c3d3ee584164ae97174ec6f21613: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:03 [async_llm.py:221] Added request chatcmpl-9951c3d3ee584164ae97174ec6f21613.
INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:03 [logger.py:39] Received request chatcmpl-62f61d6ab99b49bb881b8ec08f9df921: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:03 [async_llm.py:221] Added request chatcmpl-62f61d6ab99b49bb881b8ec08f9df921.
INFO:     127.0.0.1:59294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:04 [logger.py:39] Received request chatcmpl-ca9d558a1372417e98725a9b7aecbe36: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:04 [async_llm.py:221] Added request chatcmpl-ca9d558a1372417e98725a9b7aecbe36.
INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:04 [logger.py:39] Received request chatcmpl-c14224265deb4e77bc514022c426ac62: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:04 [async_llm.py:221] Added request chatcmpl-c14224265deb4e77bc514022c426ac62.
INFO:     127.0.0.1:59318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:05 [logger.py:39] Received request chatcmpl-bc6af7379126441699d77a2ec62e1ec6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:05 [async_llm.py:221] Added request chatcmpl-bc6af7379126441699d77a2ec62e1ec6.
INFO:     127.0.0.1:59196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:06 [logger.py:39] Received request chatcmpl-a68c83464c6b4db78e3b1d5bea4dea6b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:06 [async_llm.py:221] Added request chatcmpl-a68c83464c6b4db78e3b1d5bea4dea6b.
INFO:     127.0.0.1:59190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:06 [logger.py:39] Received request chatcmpl-4e5b34b15dd94168867691e9d857e7c6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:07 [async_llm.py:221] Added request chatcmpl-4e5b34b15dd94168867691e9d857e7c6.
INFO:     127.0.0.1:59234 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:07 [logger.py:39] Received request chatcmpl-5619ef7a47ca4f5fa12f26d08f8471e0: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:07 [async_llm.py:221] Added request chatcmpl-5619ef7a47ca4f5fa12f26d08f8471e0.
INFO:     127.0.0.1:59248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:08 [logger.py:39] Received request chatcmpl-78359face6ec454785cd620355723fdc: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:08 [async_llm.py:221] Added request chatcmpl-78359face6ec454785cd620355723fdc.
INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:09 [logger.py:39] Received request chatcmpl-442142f815cb48b0a8683d9f7ce0b166: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:09 [async_llm.py:221] Added request chatcmpl-442142f815cb48b0a8683d9f7ce0b166.
INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:10 [logger.py:39] Received request chatcmpl-ce233497f8ea4e8693b1de92bcf1b6f0: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) box\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:10 [async_llm.py:221] Added request chatcmpl-ce233497f8ea4e8693b1de92bcf1b6f0.
INFO:     127.0.0.1:59274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:11 [logger.py:39] Received request chatcmpl-c56366e316914ca0a0c06bd7a38dbad4: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:11 [async_llm.py:221] Added request chatcmpl-c56366e316914ca0a0c06bd7a38dbad4.
INFO 03-28 16:58:11 [loggers.py:80] Avg prompt throughput: 1433.4 tokens/s, Avg generation throughput: 252.5 tokens/s, Running: 13 reqs, Waiting: 3 reqs, GPU KV cache usage: 93.7%, Prefix cache hit rate: 15.0%
INFO:     127.0.0.1:59310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:11 [logger.py:39] Received request chatcmpl-53bafbbe3947405f9ac8a4325034b93a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:12 [async_llm.py:221] Added request chatcmpl-53bafbbe3947405f9ac8a4325034b93a.
INFO:     127.0.0.1:59284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:12 [logger.py:39] Received request chatcmpl-24c83609b8754222b8ff47c06c212571: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:12 [async_llm.py:221] Added request chatcmpl-24c83609b8754222b8ff47c06c212571.
INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:12 [logger.py:39] Received request chatcmpl-ecbd5b37729e4e28835c170b7d9e8598: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) table\n(B) shelves\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:12 [async_llm.py:221] Added request chatcmpl-ecbd5b37729e4e28835c170b7d9e8598.
INFO:     127.0.0.1:59256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:13 [logger.py:39] Received request chatcmpl-c7ab63dfd1474969b749fe6bf730069b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:13 [async_llm.py:221] Added request chatcmpl-c7ab63dfd1474969b749fe6bf730069b.
INFO:     127.0.0.1:59264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:14 [logger.py:39] Received request chatcmpl-f45b1d26b941402684b4b3a724eb0304: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) lamp\n(B) door\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:14 [async_llm.py:221] Added request chatcmpl-f45b1d26b941402684b4b3a724eb0304.
INFO:     127.0.0.1:59322 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:15 [logger.py:39] Received request chatcmpl-05c5fd3aa5c546ca8a3c316bd4989c81: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:15 [async_llm.py:221] Added request chatcmpl-05c5fd3aa5c546ca8a3c316bd4989c81.
INFO:     127.0.0.1:59196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:15 [logger.py:39] Received request chatcmpl-85f3dd8bd1fa496d88c889b4a42acdc9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) lamp\n(B) shelves\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:16 [async_llm.py:221] Added request chatcmpl-85f3dd8bd1fa496d88c889b4a42acdc9.
INFO:     127.0.0.1:59318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:16 [logger.py:39] Received request chatcmpl-498828520f2f40b2adb04b43ebc350e9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:17 [async_llm.py:221] Added request chatcmpl-498828520f2f40b2adb04b43ebc350e9.
INFO:     127.0.0.1:59234 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:17 [logger.py:39] Received request chatcmpl-b45036c6c29b4511a9324b2041df29c1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) books\n(B) mirror\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:17 [async_llm.py:221] Added request chatcmpl-b45036c6c29b4511a9324b2041df29c1.
INFO:     127.0.0.1:59190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:18 [logger.py:39] Received request chatcmpl-f8a05e4b4bff41f4a0ce8cdd01c87b0f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:18 [async_llm.py:221] Added request chatcmpl-f8a05e4b4bff41f4a0ce8cdd01c87b0f.
INFO:     127.0.0.1:59294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:18 [logger.py:39] Received request chatcmpl-942d4620f4624a81b9514080333f4631: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) pillow\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:18 [async_llm.py:221] Added request chatcmpl-942d4620f4624a81b9514080333f4631.
INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:18 [logger.py:39] Received request chatcmpl-46e6d73587af455b83a7cdc36631e4a8: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:19 [async_llm.py:221] Added request chatcmpl-46e6d73587af455b83a7cdc36631e4a8.
INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:19 [logger.py:39] Received request chatcmpl-8c954cf386034eea91e6c1bf17cea7bb: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:20 [async_llm.py:221] Added request chatcmpl-8c954cf386034eea91e6c1bf17cea7bb.
INFO:     127.0.0.1:59248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:20 [logger.py:39] Received request chatcmpl-2849899100164ec1aea8f4f31b01c539: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:20 [async_llm.py:221] Added request chatcmpl-2849899100164ec1aea8f4f31b01c539.
INFO:     127.0.0.1:59274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:20 [logger.py:39] Received request chatcmpl-9bf49fc73c864a9b985ec0eecf7a08b4: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:20 [async_llm.py:221] Added request chatcmpl-9bf49fc73c864a9b985ec0eecf7a08b4.
INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:21 [logger.py:39] Received request chatcmpl-67ee9258187c46a799fbe22f68ec97d1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:21 [async_llm.py:221] Added request chatcmpl-67ee9258187c46a799fbe22f68ec97d1.
INFO 03-28 16:58:21 [loggers.py:80] Avg prompt throughput: 1763.4 tokens/s, Avg generation throughput: 214.9 tokens/s, Running: 14 reqs, Waiting: 2 reqs, GPU KV cache usage: 97.0%, Prefix cache hit rate: 15.5%
INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:22 [logger.py:39] Received request chatcmpl-5031bafcda6440eb83f0526cf453cafd: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) door\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:22 [async_llm.py:221] Added request chatcmpl-5031bafcda6440eb83f0526cf453cafd.
INFO:     127.0.0.1:59284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:23 [logger.py:39] Received request chatcmpl-7caa434a961b4ed197127cb601454fcd: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:23 [async_llm.py:221] Added request chatcmpl-7caa434a961b4ed197127cb601454fcd.
INFO:     127.0.0.1:59310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:23 [logger.py:39] Received request chatcmpl-70d4ba3c185748d6a8a88d482a4100e1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:23 [async_llm.py:221] Added request chatcmpl-70d4ba3c185748d6a8a88d482a4100e1.
INFO:     127.0.0.1:59256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:24 [logger.py:39] Received request chatcmpl-2a62bd3d2e7943b48c1c5d4c667aeb98: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:24 [async_llm.py:221] Added request chatcmpl-2a62bd3d2e7943b48c1c5d4c667aeb98.
INFO:     127.0.0.1:59322 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:24 [logger.py:39] Received request chatcmpl-ccb5d75d2637449b874b8a4afe8c8ed9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:25 [async_llm.py:221] Added request chatcmpl-ccb5d75d2637449b874b8a4afe8c8ed9.
INFO:     127.0.0.1:59318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:25 [logger.py:39] Received request chatcmpl-464591d2e597425c9e0c747478269207: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:25 [async_llm.py:221] Added request chatcmpl-464591d2e597425c9e0c747478269207.
INFO:     127.0.0.1:59190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:26 [logger.py:39] Received request chatcmpl-4bf320d1eed34c1dba61702354c0613f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:26 [async_llm.py:221] Added request chatcmpl-4bf320d1eed34c1dba61702354c0613f.
INFO:     127.0.0.1:59248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:27 [logger.py:39] Received request chatcmpl-2960b00e2a7948f2a8e592f256f60d82: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) desk\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:27 [async_llm.py:221] Added request chatcmpl-2960b00e2a7948f2a8e592f256f60d82.
INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:28 [logger.py:39] Received request chatcmpl-80640b0ea0ab4b8d896da6fdef8b350f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:28 [async_llm.py:221] Added request chatcmpl-80640b0ea0ab4b8d896da6fdef8b350f.
INFO:     127.0.0.1:59264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:28 [logger.py:39] Received request chatcmpl-acd214415b2a42b9832fdcc78df3178a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:28 [async_llm.py:221] Added request chatcmpl-acd214415b2a42b9832fdcc78df3178a.
INFO:     127.0.0.1:59196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:29 [logger.py:39] Received request chatcmpl-4e358d55a84844a0afb97d350f768efb: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:29 [async_llm.py:221] Added request chatcmpl-4e358d55a84844a0afb97d350f768efb.
INFO:     127.0.0.1:59234 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:30 [logger.py:39] Received request chatcmpl-00b05d2dc859454b85abb6b5a6731add: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:30 [async_llm.py:221] Added request chatcmpl-00b05d2dc859454b85abb6b5a6731add.
INFO 03-28 16:58:30 [logger.py:39] Received request chatcmpl-e0714f76ede34a6fa0f02b9cb923870b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:30 [async_llm.py:221] Added request chatcmpl-e0714f76ede34a6fa0f02b9cb923870b.
INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:31 [logger.py:39] Received request chatcmpl-54da807107124d92905a904bb261a9b4: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:31 [async_llm.py:221] Added request chatcmpl-54da807107124d92905a904bb261a9b4.
INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:31 [loggers.py:80] Avg prompt throughput: 1542.2 tokens/s, Avg generation throughput: 235.2 tokens/s, Running: 13 reqs, Waiting: 2 reqs, GPU KV cache usage: 90.8%, Prefix cache hit rate: 10.8%
INFO 03-28 16:58:31 [logger.py:39] Received request chatcmpl-1c865df48ea3497da9f72767c2654e5a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:31 [async_llm.py:221] Added request chatcmpl-1c865df48ea3497da9f72767c2654e5a.
INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:33 [logger.py:39] Received request chatcmpl-cea6e3836cb041fd9de4ae9c725e7930: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sink (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) sink\n(B) pillow\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:33 [async_llm.py:221] Added request chatcmpl-cea6e3836cb041fd9de4ae9c725e7930.
INFO:     127.0.0.1:59310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:33 [logger.py:39] Received request chatcmpl-42ff0b71a4bd47349a6e89d1c2d05b16: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:33 [async_llm.py:221] Added request chatcmpl-42ff0b71a4bd47349a6e89d1c2d05b16.
INFO:     127.0.0.1:59274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:34 [logger.py:39] Received request chatcmpl-591921167498465ca4b74cc6ebed80eb: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) door\n(B) pillow\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:34 [async_llm.py:221] Added request chatcmpl-591921167498465ca4b74cc6ebed80eb.
INFO:     127.0.0.1:59190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:35 [logger.py:39] Received request chatcmpl-9e0bf0d48d804c8d960af2fed8e0b4ca: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:35 [async_llm.py:221] Added request chatcmpl-9e0bf0d48d804c8d960af2fed8e0b4ca.
INFO:     127.0.0.1:59322 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:36 [logger.py:39] Received request chatcmpl-ea07ab614527471096fbe9b08e7d4896: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:36 [async_llm.py:221] Added request chatcmpl-ea07ab614527471096fbe9b08e7d4896.
INFO:     127.0.0.1:59256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:36 [logger.py:39] Received request chatcmpl-43a48f732e8d4419a9fea95671180e31: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:36 [async_llm.py:221] Added request chatcmpl-43a48f732e8d4419a9fea95671180e31.
INFO:     127.0.0.1:59318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:37 [logger.py:39] Received request chatcmpl-75640020411745058fb4ebc7e494a6db: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:37 [async_llm.py:221] Added request chatcmpl-75640020411745058fb4ebc7e494a6db.
INFO:     127.0.0.1:59284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:38 [logger.py:39] Received request chatcmpl-6a7af5e76dd84ddba77dd40478eceef7: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) books\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:38 [async_llm.py:221] Added request chatcmpl-6a7af5e76dd84ddba77dd40478eceef7.
INFO:     127.0.0.1:59248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:38 [logger.py:39] Received request chatcmpl-d3333d6f0fc54b76a400fa8c6f4f8ad2: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:38 [async_llm.py:221] Added request chatcmpl-d3333d6f0fc54b76a400fa8c6f4f8ad2.
INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:38 [logger.py:39] Received request chatcmpl-c3867c8b3d16404fa15372355ff5f925: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:38 [async_llm.py:221] Added request chatcmpl-c3867c8b3d16404fa15372355ff5f925.
INFO:     127.0.0.1:59196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:39 [logger.py:39] Received request chatcmpl-c23e8f6aff9642169dc231797300348b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:39 [async_llm.py:221] Added request chatcmpl-c23e8f6aff9642169dc231797300348b.
INFO:     127.0.0.1:59264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:40 [logger.py:39] Received request chatcmpl-fa0978ff83084119b288e19914a102c2: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:40 [async_llm.py:221] Added request chatcmpl-fa0978ff83084119b288e19914a102c2.
INFO 03-28 16:58:40 [logger.py:39] Received request chatcmpl-77298a35358e4c158d55b46ada43ec61: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) shelves\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:40 [async_llm.py:221] Added request chatcmpl-77298a35358e4c158d55b46ada43ec61.
INFO:     127.0.0.1:59294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:41 [logger.py:39] Received request chatcmpl-f3716eda5afb4bf2b4f4516246ed607a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:41 [async_llm.py:221] Added request chatcmpl-f3716eda5afb4bf2b4f4516246ed607a.
INFO 03-28 16:58:41 [loggers.py:80] Avg prompt throughput: 1653.3 tokens/s, Avg generation throughput: 238.3 tokens/s, Running: 14 reqs, Waiting: 2 reqs, GPU KV cache usage: 97.9%, Prefix cache hit rate: 10.5%
INFO:     127.0.0.1:59234 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:42 [logger.py:39] Received request chatcmpl-c430aeb932b0440693d03aecbdc63e15: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:42 [async_llm.py:221] Added request chatcmpl-c430aeb932b0440693d03aecbdc63e15.
INFO:     127.0.0.1:59274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:43 [logger.py:39] Received request chatcmpl-e9b4f87b0ac640f4a5399de24da24891: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:43 [async_llm.py:221] Added request chatcmpl-e9b4f87b0ac640f4a5399de24da24891.
INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:44 [logger.py:39] Received request chatcmpl-a13380fdd1544b71aaa7210dfb11ec1d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:44 [async_llm.py:221] Added request chatcmpl-a13380fdd1544b71aaa7210dfb11ec1d.
INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:45 [logger.py:39] Received request chatcmpl-318eeb67c43b4c55845cc65e0bbc2d6c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:45 [async_llm.py:221] Added request chatcmpl-318eeb67c43b4c55845cc65e0bbc2d6c.
INFO:     127.0.0.1:59284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:45 [logger.py:39] Received request chatcmpl-d9327d6320b84c2d83b6c1d424389dc0: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:45 [async_llm.py:221] Added request chatcmpl-d9327d6320b84c2d83b6c1d424389dc0.
INFO:     127.0.0.1:59256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:46 [logger.py:39] Received request chatcmpl-198f476d73c644878d86e6764683eb73: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:46 [async_llm.py:221] Added request chatcmpl-198f476d73c644878d86e6764683eb73.
INFO:     127.0.0.1:59310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:46 [logger.py:39] Received request chatcmpl-93897ebf21d84804b726da4ba6d1d62f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:46 [async_llm.py:221] Added request chatcmpl-93897ebf21d84804b726da4ba6d1d62f.
INFO:     127.0.0.1:59190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:47 [logger.py:39] Received request chatcmpl-d14aa56d9ff5426ab8256076f7c675b5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:47 [async_llm.py:221] Added request chatcmpl-d14aa56d9ff5426ab8256076f7c675b5.
INFO:     127.0.0.1:59196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:47 [logger.py:39] Received request chatcmpl-db512d7668494963b1757819c05889f9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:47 [async_llm.py:221] Added request chatcmpl-db512d7668494963b1757819c05889f9.
INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:48 [logger.py:39] Received request chatcmpl-dfb6b7f34a5549cba3c58f8c47d1cbf8: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) sofa\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:48 [async_llm.py:221] Added request chatcmpl-dfb6b7f34a5549cba3c58f8c47d1cbf8.
INFO:     127.0.0.1:59322 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:48 [logger.py:39] Received request chatcmpl-fe47c03528254bdea334feaf8814421b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) chair\n(B) shelves\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:48 [async_llm.py:221] Added request chatcmpl-fe47c03528254bdea334feaf8814421b.
INFO:     127.0.0.1:59318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:49 [logger.py:39] Received request chatcmpl-0f049d366cb54896ac20a35a107fa3ca: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:49 [async_llm.py:221] Added request chatcmpl-0f049d366cb54896ac20a35a107fa3ca.
INFO:     127.0.0.1:59248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:50 [logger.py:39] Received request chatcmpl-102fa86ea12944b49c3c225714b43658: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) shelves\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:50 [async_llm.py:221] Added request chatcmpl-102fa86ea12944b49c3c225714b43658.
INFO:     127.0.0.1:59264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:50 [logger.py:39] Received request chatcmpl-04e7cc51970b4b318ebedc146a7493c1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:50 [async_llm.py:221] Added request chatcmpl-04e7cc51970b4b318ebedc146a7493c1.
INFO 03-28 16:58:51 [loggers.py:80] Avg prompt throughput: 1543.9 tokens/s, Avg generation throughput: 254.0 tokens/s, Running: 14 reqs, Waiting: 2 reqs, GPU KV cache usage: 99.4%, Prefix cache hit rate: 10.1%
INFO:     127.0.0.1:59274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:53 [logger.py:39] Received request chatcmpl-d69904c65da142029e3a90120321839e: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the floor mat (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) floor mat\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:53 [async_llm.py:221] Added request chatcmpl-d69904c65da142029e3a90120321839e.
INFO:     127.0.0.1:59256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:53 [logger.py:39] Received request chatcmpl-5168657482204315b03fe8bf379ac9c6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:53 [async_llm.py:221] Added request chatcmpl-5168657482204315b03fe8bf379ac9c6.
INFO:     127.0.0.1:59310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:54 [logger.py:39] Received request chatcmpl-78b0fbadcbcf46bd80c80879189c3cbf: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:54 [async_llm.py:221] Added request chatcmpl-78b0fbadcbcf46bd80c80879189c3cbf.
INFO:     127.0.0.1:59294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:54 [logger.py:39] Received request chatcmpl-51bbc32758224dbfad8bbb6fd3594e3c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the counter (highlighted by a blue box)?\n(A) lamp\n(B) counter\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:54 [async_llm.py:221] Added request chatcmpl-51bbc32758224dbfad8bbb6fd3594e3c.
INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:54 [logger.py:39] Received request chatcmpl-bc8603ffa7e048ac95a54ede09df29f0: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:54 [async_llm.py:221] Added request chatcmpl-bc8603ffa7e048ac95a54ede09df29f0.
INFO:     127.0.0.1:59234 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:55 [logger.py:39] Received request chatcmpl-63ab1e6ed8604b748a7c59e149537465: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:55 [async_llm.py:221] Added request chatcmpl-63ab1e6ed8604b748a7c59e149537465.
INFO:     127.0.0.1:59284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:56 [logger.py:39] Received request chatcmpl-28e89e48b1f448248f78592ac2cb0a54: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:56 [async_llm.py:221] Added request chatcmpl-28e89e48b1f448248f78592ac2cb0a54.
INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:56 [logger.py:39] Received request chatcmpl-3f7cb2262a054f95a7d321150b9730bc: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:56 [async_llm.py:221] Added request chatcmpl-3f7cb2262a054f95a7d321150b9730bc.
INFO:     127.0.0.1:59190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:57 [logger.py:39] Received request chatcmpl-0a5a23a229eb4217958880391ecbaaca: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) sofa\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:57 [async_llm.py:221] Added request chatcmpl-0a5a23a229eb4217958880391ecbaaca.
INFO:     127.0.0.1:59322 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:58 [logger.py:39] Received request chatcmpl-39af676d6ab540a6907c87d298581266: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:58 [async_llm.py:221] Added request chatcmpl-39af676d6ab540a6907c87d298581266.
INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:58 [logger.py:39] Received request chatcmpl-ed9d6e65545947fab0c202d72497387c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:58 [async_llm.py:221] Added request chatcmpl-ed9d6e65545947fab0c202d72497387c.
INFO 03-28 16:58:58 [logger.py:39] Received request chatcmpl-b001e0363e874bc9856895e76e54342f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) shelves\n(B) mirror\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:58 [async_llm.py:221] Added request chatcmpl-b001e0363e874bc9856895e76e54342f.
INFO:     127.0.0.1:59318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:58:59 [logger.py:39] Received request chatcmpl-dc0d22b8aab64522b12395c27cb61903: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:58:59 [async_llm.py:221] Added request chatcmpl-dc0d22b8aab64522b12395c27cb61903.
INFO:     127.0.0.1:59196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:00 [logger.py:39] Received request chatcmpl-2dc169f4313f4ea68c98117e3cfd8ede: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:00 [async_llm.py:221] Added request chatcmpl-2dc169f4313f4ea68c98117e3cfd8ede.
INFO:     127.0.0.1:59248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:01 [loggers.py:80] Avg prompt throughput: 1543.2 tokens/s, Avg generation throughput: 238.8 tokens/s, Running: 13 reqs, Waiting: 2 reqs, GPU KV cache usage: 92.6%, Prefix cache hit rate: 12.5%
INFO 03-28 16:59:01 [logger.py:39] Received request chatcmpl-9eba1df30ad54146aa2e394ccabf10a0: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:01 [async_llm.py:221] Added request chatcmpl-9eba1df30ad54146aa2e394ccabf10a0.
INFO:     127.0.0.1:59264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:02 [logger.py:39] Received request chatcmpl-dfdb693014624492bd5396573974d64a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:02 [async_llm.py:221] Added request chatcmpl-dfdb693014624492bd5396573974d64a.
INFO:     127.0.0.1:59310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:03 [logger.py:39] Received request chatcmpl-1ac9f8fb988d4a8fbb8727be70af2cd9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:03 [async_llm.py:221] Added request chatcmpl-1ac9f8fb988d4a8fbb8727be70af2cd9.
INFO:     127.0.0.1:59322 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:03 [logger.py:39] Received request chatcmpl-7b8c11645de7479ea6470963e89ead30: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:03 [async_llm.py:221] Added request chatcmpl-7b8c11645de7479ea6470963e89ead30.
INFO:     127.0.0.1:59274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:04 [logger.py:39] Received request chatcmpl-01fba53bbbbf4cdbb1efbc40c86bc1fa: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) bookcase\n(B) pillow\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:04 [async_llm.py:221] Added request chatcmpl-01fba53bbbbf4cdbb1efbc40c86bc1fa.
INFO:     127.0.0.1:59190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:05 [logger.py:39] Received request chatcmpl-06c45e3f5f9a4e06bb9b07833d3dc2af: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) shelves\n(B) pillow\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:05 [async_llm.py:221] Added request chatcmpl-06c45e3f5f9a4e06bb9b07833d3dc2af.
INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:05 [logger.py:39] Received request chatcmpl-e64d97b92ef64ddd896008f2ea5b17fd: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:05 [async_llm.py:221] Added request chatcmpl-e64d97b92ef64ddd896008f2ea5b17fd.
INFO:     127.0.0.1:59234 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:06 [logger.py:39] Received request chatcmpl-f3d6fbe609204f8daee5c6ab6e4a05bc: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:06 [async_llm.py:221] Added request chatcmpl-f3d6fbe609204f8daee5c6ab6e4a05bc.
INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:06 [logger.py:39] Received request chatcmpl-4636871b757549c0883e309314e7ff98: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:06 [async_llm.py:221] Added request chatcmpl-4636871b757549c0883e309314e7ff98.
INFO:     127.0.0.1:59284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:07 [logger.py:39] Received request chatcmpl-9f5e9adef928421d82bba9a332a28396: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:07 [async_llm.py:221] Added request chatcmpl-9f5e9adef928421d82bba9a332a28396.
INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:07 [logger.py:39] Received request chatcmpl-21d42cb178c042a09621fdbccd76b435: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:07 [async_llm.py:221] Added request chatcmpl-21d42cb178c042a09621fdbccd76b435.
INFO:     127.0.0.1:59294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:08 [logger.py:39] Received request chatcmpl-8baf0bbd8d174b6aaf6cc0522e2e8d84: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:08 [async_llm.py:221] Added request chatcmpl-8baf0bbd8d174b6aaf6cc0522e2e8d84.
INFO:     127.0.0.1:59256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:09 [logger.py:39] Received request chatcmpl-5d43d7fb62d54e3e84d4a42db4fdee30: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:09 [async_llm.py:221] Added request chatcmpl-5d43d7fb62d54e3e84d4a42db4fdee30.
INFO:     127.0.0.1:59318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:09 [logger.py:39] Received request chatcmpl-4ce69300bd144d99803732c2b23bafa6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) table\n(B) blinds\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:09 [async_llm.py:221] Added request chatcmpl-4ce69300bd144d99803732c2b23bafa6.
INFO:     127.0.0.1:59322 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:10 [logger.py:39] Received request chatcmpl-bf88c87743614436a1fff7db027eb13a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:10 [async_llm.py:221] Added request chatcmpl-bf88c87743614436a1fff7db027eb13a.
INFO:     127.0.0.1:59196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:11 [logger.py:39] Received request chatcmpl-df0f855c78d74e4bb38b7a4d7c4edc0a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:11 [async_llm.py:221] Added request chatcmpl-df0f855c78d74e4bb38b7a4d7c4edc0a.
INFO 03-28 16:59:11 [loggers.py:80] Avg prompt throughput: 1764.0 tokens/s, Avg generation throughput: 233.8 tokens/s, Running: 13 reqs, Waiting: 2 reqs, GPU KV cache usage: 91.2%, Prefix cache hit rate: 8.1%
INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:11 [logger.py:39] Received request chatcmpl-015cf0a74d4d414d9b6d12d9d25ccbe5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:11 [async_llm.py:221] Added request chatcmpl-015cf0a74d4d414d9b6d12d9d25ccbe5.
INFO:     127.0.0.1:59310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:12 [logger.py:39] Received request chatcmpl-7f4c7dbf7fcc42d7b12d2759736e2c8a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:12 [async_llm.py:221] Added request chatcmpl-7f4c7dbf7fcc42d7b12d2759736e2c8a.
INFO:     127.0.0.1:59248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:13 [logger.py:39] Received request chatcmpl-d579f09cc26b4d94a5446d351ea0f9cf: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:13 [async_llm.py:221] Added request chatcmpl-d579f09cc26b4d94a5446d351ea0f9cf.
INFO:     127.0.0.1:59264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:14 [logger.py:39] Received request chatcmpl-05059f0dc9a34db2b7412eaba32f705d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:14 [async_llm.py:221] Added request chatcmpl-05059f0dc9a34db2b7412eaba32f705d.
INFO:     127.0.0.1:59190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:14 [logger.py:39] Received request chatcmpl-f701f69a29564ea882aca8cd22f8f985: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:14 [async_llm.py:221] Added request chatcmpl-f701f69a29564ea882aca8cd22f8f985.
INFO:     127.0.0.1:59274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:15 [logger.py:39] Received request chatcmpl-80a35709f17a4030a9a6c668df30f096: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:15 [async_llm.py:221] Added request chatcmpl-80a35709f17a4030a9a6c668df30f096.
INFO:     127.0.0.1:59284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:16 [logger.py:39] Received request chatcmpl-be6523100c264d47b208aee8bcc9ae7a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:16 [async_llm.py:221] Added request chatcmpl-be6523100c264d47b208aee8bcc9ae7a.
INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:16 [logger.py:39] Received request chatcmpl-40a7c4f9331f4c6485088fa44349e55e: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:16 [async_llm.py:221] Added request chatcmpl-40a7c4f9331f4c6485088fa44349e55e.
INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:17 [logger.py:39] Received request chatcmpl-8d2b806e9f714b93bd92441d7823889f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:17 [async_llm.py:221] Added request chatcmpl-8d2b806e9f714b93bd92441d7823889f.
INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:18 [logger.py:39] Received request chatcmpl-36262b0d84564598b2366b35c820cd78: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) box\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:18 [async_llm.py:221] Added request chatcmpl-36262b0d84564598b2366b35c820cd78.
INFO:     127.0.0.1:59256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:18 [logger.py:39] Received request chatcmpl-c9e65d7d47104614ab45682e34806b61: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:18 [async_llm.py:221] Added request chatcmpl-c9e65d7d47104614ab45682e34806b61.
INFO:     127.0.0.1:59294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:18 [logger.py:39] Received request chatcmpl-44a4f6f986d24496b63898fc8e019336: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:18 [async_llm.py:221] Added request chatcmpl-44a4f6f986d24496b63898fc8e019336.
INFO:     127.0.0.1:59234 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:19 [logger.py:39] Received request chatcmpl-d317a1418fde47e6b82d3e6086076e9e: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:19 [async_llm.py:221] Added request chatcmpl-d317a1418fde47e6b82d3e6086076e9e.
INFO:     127.0.0.1:59318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:20 [logger.py:39] Received request chatcmpl-147f5065796a468f8e01ccf6d528e6ef: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) table\n(B) shelves\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:20 [async_llm.py:221] Added request chatcmpl-147f5065796a468f8e01ccf6d528e6ef.
INFO:     127.0.0.1:59196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:21 [logger.py:39] Received request chatcmpl-e0768f43d1a745b38a81244f2c15ae1f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:21 [async_llm.py:221] Added request chatcmpl-e0768f43d1a745b38a81244f2c15ae1f.
INFO 03-28 16:59:21 [loggers.py:80] Avg prompt throughput: 1653.9 tokens/s, Avg generation throughput: 246.4 tokens/s, Running: 14 reqs, Waiting: 2 reqs, GPU KV cache usage: 98.8%, Prefix cache hit rate: 7.0%
INFO:     127.0.0.1:59322 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:22 [logger.py:39] Received request chatcmpl-22953c254ff3409f83af09ced0636070: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) lamp\n(B) door\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:22 [async_llm.py:221] Added request chatcmpl-22953c254ff3409f83af09ced0636070.
INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:22 [logger.py:39] Received request chatcmpl-1fa99418cf8647219f4845bde39a26a1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:23 [async_llm.py:221] Added request chatcmpl-1fa99418cf8647219f4845bde39a26a1.
INFO 03-28 16:59:23 [logger.py:39] Received request chatcmpl-6601ffa8acdc421ba8b1fef45579cef8: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) lamp\n(B) shelves\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:23 [async_llm.py:221] Added request chatcmpl-6601ffa8acdc421ba8b1fef45579cef8.
INFO:     127.0.0.1:59274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:24 [logger.py:39] Received request chatcmpl-f144b23f45fc45958ddd955542a7e9b2: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:24 [async_llm.py:221] Added request chatcmpl-f144b23f45fc45958ddd955542a7e9b2.
INFO:     127.0.0.1:59284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:24 [logger.py:39] Received request chatcmpl-96115aed61b64afb87413f8e56227bea: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) books\n(B) mirror\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:24 [async_llm.py:221] Added request chatcmpl-96115aed61b64afb87413f8e56227bea.
INFO:     127.0.0.1:59310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:25 [logger.py:39] Received request chatcmpl-4842d2f2a6c9405bb8238fc6eaddfb5e: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:25 [async_llm.py:221] Added request chatcmpl-4842d2f2a6c9405bb8238fc6eaddfb5e.
INFO 03-28 16:59:25 [logger.py:39] Received request chatcmpl-04c7d40df064477fad3d46ad4abfdd6a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) pillow\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:25 [async_llm.py:221] Added request chatcmpl-04c7d40df064477fad3d46ad4abfdd6a.
INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:26 [logger.py:39] Received request chatcmpl-6c91ac5bc2c14cefa45f7e699826ec91: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:26 [async_llm.py:221] Added request chatcmpl-6c91ac5bc2c14cefa45f7e699826ec91.
INFO:     127.0.0.1:59248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:26 [logger.py:39] Received request chatcmpl-cac1397f069146e0b2d4401970423c69: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:26 [async_llm.py:221] Added request chatcmpl-cac1397f069146e0b2d4401970423c69.
INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:27 [logger.py:39] Received request chatcmpl-5ca9e6d4d716421ba0947585d2e1204b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:27 [async_llm.py:221] Added request chatcmpl-5ca9e6d4d716421ba0947585d2e1204b.
INFO:     127.0.0.1:59256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:27 [logger.py:39] Received request chatcmpl-e49c5f524ad04fca96743d03a02aa504: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:27 [async_llm.py:221] Added request chatcmpl-e49c5f524ad04fca96743d03a02aa504.
INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:28 [logger.py:39] Received request chatcmpl-c19b988f8fed463f93b1edff2a2669ef: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:28 [async_llm.py:221] Added request chatcmpl-c19b988f8fed463f93b1edff2a2669ef.
INFO:     127.0.0.1:59234 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:29 [logger.py:39] Received request chatcmpl-a884792ff34a438594d1aa15278afb32: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) door\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:29 [async_llm.py:221] Added request chatcmpl-a884792ff34a438594d1aa15278afb32.
INFO:     127.0.0.1:59318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:30 [logger.py:39] Received request chatcmpl-6c8e123d045d4b60b72eaf0c996ffdae: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:30 [async_llm.py:221] Added request chatcmpl-6c8e123d045d4b60b72eaf0c996ffdae.
INFO:     127.0.0.1:59196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:31 [logger.py:39] Received request chatcmpl-c7963cfd84fd46fca689505b65879aaf: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:31 [async_llm.py:221] Added request chatcmpl-c7963cfd84fd46fca689505b65879aaf.
INFO 03-28 16:59:31 [loggers.py:80] Avg prompt throughput: 1653.1 tokens/s, Avg generation throughput: 234.8 tokens/s, Running: 14 reqs, Waiting: 1 reqs, GPU KV cache usage: 100.0%, Prefix cache hit rate: 3.3%
INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:32 [logger.py:39] Received request chatcmpl-7b0c9ffb334f4bc69e916119b307ec82: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:32 [async_llm.py:221] Added request chatcmpl-7b0c9ffb334f4bc69e916119b307ec82.
INFO:     127.0.0.1:59274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:32 [logger.py:39] Received request chatcmpl-6484fae067984a77a391c2b6a9ba5974: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:32 [async_llm.py:221] Added request chatcmpl-6484fae067984a77a391c2b6a9ba5974.
INFO:     127.0.0.1:59294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:33 [logger.py:39] Received request chatcmpl-53482eb354cf4bd1b5df6d336166c7a6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-28 16:59:33 [async_llm.py:221] Added request chatcmpl-53482eb354cf4bd1b5df6d336166c7a6.
INFO:     127.0.0.1:59190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59322 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59284 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59234 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:41 [loggers.py:80] Avg prompt throughput: 551.4 tokens/s, Avg generation throughput: 189.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 7.6%, Prefix cache hit rate: 3.3%
INFO:     127.0.0.1:59318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-28 16:59:51 [loggers.py:80] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.4 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 3.3%
