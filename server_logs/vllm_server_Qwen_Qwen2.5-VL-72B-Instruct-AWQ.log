INFO 03-29 14:41:26 [__init__.py:239] Automatically detected platform cuda.
INFO 03-29 14:41:33 [api_server.py:981] vLLM API server version 0.8.2
INFO 03-29 14:41:33 [api_server.py:982] args: Namespace(subparser='serve', model_tag='Qwen/Qwen2.5-VL-72B-Instruct-AWQ', config='', host=None, port=27182, uvicorn_log_level='info', disable_uvicorn_access_log=False, allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, chat_template_content_format='auto', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, enable_ssl_refresh=False, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='Qwen/Qwen2.5-VL-72B-Instruct-AWQ', task='auto', tokenizer=None, hf_config_path=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, allowed_local_media_path=None, download_dir=None, load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', max_model_len=16384, guided_decoding_backend='xgrammar', logits_processor_pattern=None, model_impl='auto', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=2, enable_expert_parallel=False, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=None, enable_prefix_caching=None, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=None, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.95, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_partial_prefills=1, max_long_partial_prefills=1, long_prefill_token_threshold=0, max_num_seqs=None, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_overrides=None, enforce_eager=False, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt={'image': 5}, mm_processor_kwargs={'images_kwargs.do_resize': True, 'images_kwargs.size.shortest_edge': 3136, 'images_kwargs.size.longest_edge': 250880}, disable_mm_preprocessor_cache=False, enable_lora=False, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, use_tqdm_on_load=True, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_config=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, scheduling_policy='fcfs', scheduler_cls='vllm.core.scheduler.Scheduler', override_neuron_config=None, override_pooler_config=None, compilation_config=None, kv_transfer_config=None, worker_cls='auto', worker_extension_cls='', generation_config='auto', override_generation_config=None, enable_sleep_mode=False, calculate_kv_scales=False, additional_config=None, enable_reasoning=False, reasoning_parser=None, disable_cascade_attn=False, disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False, enable_server_load_tracking=False, dispatch_function=<function ServeSubcommand.cmd at 0x7fe0933dccc0>)
INFO 03-29 14:41:44 [config.py:585] This model supports multiple tasks: {'classify', 'reward', 'generate', 'embed', 'score'}. Defaulting to 'generate'.
INFO 03-29 14:41:46 [awq_marlin.py:114] The model is convertible to awq_marlin during runtime. Using awq_marlin kernel.
INFO 03-29 14:41:46 [config.py:1519] Defaulting to use mp for distributed inference
INFO 03-29 14:41:46 [config.py:1697] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 03-29 14:41:52 [__init__.py:239] Automatically detected platform cuda.
INFO 03-29 14:41:55 [core.py:54] Initializing a V1 LLM engine (v0.8.2) with config: model='Qwen/Qwen2.5-VL-72B-Instruct-AWQ', speculative_config=None, tokenizer='Qwen/Qwen2.5-VL-72B-Instruct-AWQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=16384, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq_marlin, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=Qwen/Qwen2.5-VL-72B-Instruct-AWQ, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs={'images_kwargs.do_resize': True, 'images_kwargs.size.shortest_edge': 3136, 'images_kwargs.size.longest_edge': 250880}, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 03-29 14:41:55 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 4 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 03-29 14:41:55 [shm_broadcast.py:259] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1], buffer_handle=(2, 10485760, 10, 'psm_d79071a6'), local_subscribe_addr='ipc:///tmp/730398dd-6e7c-4502-bc8f-8e8159925c2f', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-29 14:42:00 [__init__.py:239] Automatically detected platform cuda.
WARNING 03-29 14:42:10 [utils.py:2321] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ff6aad280b0>
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:42:10 [shm_broadcast.py:259] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_69d8c3ec'), local_subscribe_addr='ipc:///tmp/0a0135c4-03b0-450a-8b84-6d3158163d9d', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-29 14:42:16 [__init__.py:239] Automatically detected platform cuda.
WARNING 03-29 14:42:20 [utils.py:2321] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fc2c9b14110>
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:42:20 [shm_broadcast.py:259] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_eaa80405'), local_subscribe_addr='ipc:///tmp/29d3d50a-a877-4049-88e0-5875651e7230', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:42:21 [utils.py:931] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:42:21 [utils.py:931] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:42:21 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:42:21 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:42:21 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /nfshomes/sriramb/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:42:21 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /nfshomes/sriramb/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:42:21 [shm_broadcast.py:259] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_e82b8bbb'), local_subscribe_addr='ipc:///tmp/4356ff9b-65e4-4a8a-84da-dc3c61e7a109', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:42:21 [parallel_state.py:954] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:42:21 [parallel_state.py:954] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:42:21 [cuda.py:220] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:42:21 [cuda.py:220] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:42:21 [gpu_model_runner.py:1174] Starting to load model Qwen/Qwen2.5-VL-72B-Instruct-AWQ...
[1;36m(VllmWorker rank=1 pid=8540)[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:42:22 [gpu_model_runner.py:1174] Starting to load model Qwen/Qwen2.5-VL-72B-Instruct-AWQ...
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:42:22 [config.py:3243] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:42:22 [config.py:3243] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
[1;36m(VllmWorker rank=1 pid=8540)[0;0m WARNING 03-29 14:42:22 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=0 pid=8519)[0;0m WARNING 03-29 14:42:22 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:42:23 [weight_utils.py:265] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:42:23 [weight_utils.py:265] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/11 [00:00<?, ?it/s]
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Loading safetensors checkpoint shards:   9% Completed | 1/11 [00:03<00:38,  3.83s/it]
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Loading safetensors checkpoint shards:  18% Completed | 2/11 [00:10<00:48,  5.38s/it]
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Loading safetensors checkpoint shards:  27% Completed | 3/11 [00:16<00:47,  5.88s/it]
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Loading safetensors checkpoint shards:  36% Completed | 4/11 [00:23<00:42,  6.13s/it]
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Loading safetensors checkpoint shards:  45% Completed | 5/11 [00:29<00:37,  6.25s/it]
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Loading safetensors checkpoint shards:  55% Completed | 6/11 [00:36<00:32,  6.45s/it]
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Loading safetensors checkpoint shards:  64% Completed | 7/11 [00:43<00:26,  6.51s/it]
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Loading safetensors checkpoint shards:  73% Completed | 8/11 [00:50<00:20,  6.70s/it]
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Loading safetensors checkpoint shards:  82% Completed | 9/11 [00:54<00:11,  5.85s/it]
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Loading safetensors checkpoint shards:  91% Completed | 10/11 [01:01<00:06,  6.26s/it]
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Loading safetensors checkpoint shards: 100% Completed | 11/11 [01:08<00:00,  6.39s/it]
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Loading safetensors checkpoint shards: 100% Completed | 11/11 [01:08<00:00,  6.20s/it]
[1;36m(VllmWorker rank=0 pid=8519)[0;0m 
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:43:31 [loader.py:447] Loading weights took 68.31 seconds
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:43:31 [loader.py:447] Loading weights took 68.35 seconds
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:43:32 [gpu_model_runner.py:1186] Model loading took 20.1702 GB and 70.644662 seconds
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:43:33 [gpu_model_runner.py:1186] Model loading took 20.1702 GB and 70.797815 seconds
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:43:33 [gpu_model_runner.py:1456] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:43:33 [gpu_model_runner.py:1456] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Keyword argument `images_kwargs.do_resize` is not a valid argument for this processor and will be ignored.
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Keyword argument `images_kwargs.size.shortest_edge` is not a valid argument for this processor and will be ignored.
[1;36m(VllmWorker rank=0 pid=8519)[0;0m Keyword argument `images_kwargs.size.longest_edge` is not a valid argument for this processor and will be ignored.
[1;36m(VllmWorker rank=1 pid=8540)[0;0m Keyword argument `images_kwargs.do_resize` is not a valid argument for this processor and will be ignored.
[1;36m(VllmWorker rank=1 pid=8540)[0;0m Keyword argument `images_kwargs.size.shortest_edge` is not a valid argument for this processor and will be ignored.
[1;36m(VllmWorker rank=1 pid=8540)[0;0m Keyword argument `images_kwargs.size.longest_edge` is not a valid argument for this processor and will be ignored.
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:44:15 [backends.py:415] Using cache directory: /nfshomes/sriramb/.cache/vllm/torch_compile_cache/c4f006bf5b/rank_0_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:44:15 [backends.py:415] Using cache directory: /nfshomes/sriramb/.cache/vllm/torch_compile_cache/c4f006bf5b/rank_1_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:44:15 [backends.py:425] Dynamo bytecode transform time: 28.64 s
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:44:15 [backends.py:425] Dynamo bytecode transform time: 28.64 s
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:44:27 [backends.py:132] Cache the graph of shape None for later use
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:44:27 [backends.py:132] Cache the graph of shape None for later use
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:45:43 [backends.py:144] Compiling a graph for general shape takes 86.44 s
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:45:44 [backends.py:144] Compiling a graph for general shape takes 87.20 s
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:46:37 [monitor.py:33] torch.compile takes 115.08 s in total
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:46:37 [monitor.py:33] torch.compile takes 115.84 s in total
INFO 03-29 14:46:38 [kv_cache_utils.py:566] GPU KV cache size: 118,448 tokens
INFO 03-29 14:46:38 [kv_cache_utils.py:569] Maximum concurrency for 16,384 tokens per request: 7.23x
INFO 03-29 14:46:38 [kv_cache_utils.py:566] GPU KV cache size: 118,448 tokens
INFO 03-29 14:46:38 [kv_cache_utils.py:569] Maximum concurrency for 16,384 tokens per request: 7.23x
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:47:36 [custom_all_reduce.py:229] Registering 10560 cuda graph addresses
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:47:37 [custom_all_reduce.py:229] Registering 10560 cuda graph addresses
[1;36m(VllmWorker rank=1 pid=8540)[0;0m INFO 03-29 14:47:37 [gpu_model_runner.py:1534] Graph capturing finished in 59 secs, took 1.45 GiB
[1;36m(VllmWorker rank=0 pid=8519)[0;0m INFO 03-29 14:47:37 [gpu_model_runner.py:1534] Graph capturing finished in 59 secs, took 1.45 GiB
INFO 03-29 14:47:38 [core.py:151] init engine (profile, create kv cache, warmup model) took 245.42 seconds
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
WARNING 03-29 14:47:39 [config.py:1028] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
INFO 03-29 14:47:39 [serving_chat.py:115] Using default chat sampling params from model: {'repetition_penalty': 1.05, 'top_k': 1, 'top_p': 0.001}
INFO 03-29 14:47:39 [serving_completion.py:61] Using default completion sampling params from model: {'repetition_penalty': 1.05, 'top_k': 1, 'top_p': 0.001}
INFO 03-29 14:47:39 [api_server.py:1028] Starting vLLM API server on http://0.0.0.0:27182
INFO 03-29 14:47:39 [launcher.py:26] Available routes are:
INFO 03-29 14:47:39 [launcher.py:34] Route: /openapi.json, Methods: HEAD, GET
INFO 03-29 14:47:39 [launcher.py:34] Route: /docs, Methods: HEAD, GET
INFO 03-29 14:47:39 [launcher.py:34] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 03-29 14:47:39 [launcher.py:34] Route: /redoc, Methods: HEAD, GET
INFO 03-29 14:47:39 [launcher.py:34] Route: /health, Methods: GET
INFO 03-29 14:47:39 [launcher.py:34] Route: /load, Methods: GET
INFO 03-29 14:47:39 [launcher.py:34] Route: /ping, Methods: POST, GET
INFO 03-29 14:47:39 [launcher.py:34] Route: /tokenize, Methods: POST
INFO 03-29 14:47:39 [launcher.py:34] Route: /detokenize, Methods: POST
INFO 03-29 14:47:39 [launcher.py:34] Route: /v1/models, Methods: GET
INFO 03-29 14:47:39 [launcher.py:34] Route: /version, Methods: GET
INFO 03-29 14:47:39 [launcher.py:34] Route: /v1/chat/completions, Methods: POST
INFO 03-29 14:47:39 [launcher.py:34] Route: /v1/completions, Methods: POST
INFO 03-29 14:47:39 [launcher.py:34] Route: /v1/embeddings, Methods: POST
INFO 03-29 14:47:39 [launcher.py:34] Route: /pooling, Methods: POST
INFO 03-29 14:47:39 [launcher.py:34] Route: /score, Methods: POST
INFO 03-29 14:47:39 [launcher.py:34] Route: /v1/score, Methods: POST
INFO 03-29 14:47:39 [launcher.py:34] Route: /v1/audio/transcriptions, Methods: POST
INFO 03-29 14:47:39 [launcher.py:34] Route: /rerank, Methods: POST
INFO 03-29 14:47:39 [launcher.py:34] Route: /v1/rerank, Methods: POST
INFO 03-29 14:47:39 [launcher.py:34] Route: /v2/rerank, Methods: POST
INFO 03-29 14:47:39 [launcher.py:34] Route: /invocations, Methods: POST
INFO:     Started server process [8454]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO 03-29 14:47:50 [loggers.py:80] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:33992 - "GET /health HTTP/1.1" 200 OK
INFO 03-29 14:48:00 [loggers.py:80] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-29 14:48:10 [loggers.py:80] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-29 14:48:20 [loggers.py:80] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
INFO 03-29 14:48:29 [chat_utils.py:379] Detected the chat template content format to be 'openai'. You can set `--chat-template-content-format` to override this.
INFO 03-29 14:48:29 [logger.py:39] Received request chatcmpl-7c3e6655b0874eabad999f5ec9c33b90: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) desk\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
Keyword argument `images_kwargs.do_resize` is not a valid argument for this processor and will be ignored.
Keyword argument `images_kwargs.size.shortest_edge` is not a valid argument for this processor and will be ignored.
Keyword argument `images_kwargs.size.longest_edge` is not a valid argument for this processor and will be ignored.
INFO 03-29 14:48:30 [async_llm.py:221] Added request chatcmpl-7c3e6655b0874eabad999f5ec9c33b90.
INFO 03-29 14:48:30 [loggers.py:80] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 03-29 14:48:30 [logger.py:39] Received request chatcmpl-d2ad906ee14d43eaaf8727e386fd0678: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:48:31 [async_llm.py:221] Added request chatcmpl-d2ad906ee14d43eaaf8727e386fd0678.
INFO 03-29 14:48:31 [logger.py:39] Received request chatcmpl-d2c1a681b287416c8570fd4479acb696: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:48:31 [async_llm.py:221] Added request chatcmpl-d2c1a681b287416c8570fd4479acb696.
INFO 03-29 14:48:31 [logger.py:39] Received request chatcmpl-9b16cdc6134745bba86ba22695e7a705: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:48:31 [async_llm.py:221] Added request chatcmpl-9b16cdc6134745bba86ba22695e7a705.
INFO 03-29 14:48:31 [logger.py:39] Received request chatcmpl-fc4ab604981c4619bb896e04966449c4: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:48:31 [async_llm.py:221] Added request chatcmpl-fc4ab604981c4619bb896e04966449c4.
INFO 03-29 14:48:31 [logger.py:39] Received request chatcmpl-9ff19dad677846399b2ad1d892143913: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:48:31 [async_llm.py:221] Added request chatcmpl-9ff19dad677846399b2ad1d892143913.
INFO 03-29 14:48:31 [logger.py:39] Received request chatcmpl-959c8c9f10e146d5ade87b39950117b8: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:48:31 [async_llm.py:221] Added request chatcmpl-959c8c9f10e146d5ade87b39950117b8.
INFO 03-29 14:48:31 [logger.py:39] Received request chatcmpl-d824e07c7f5045ffb5de194fac766350: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:48:31 [async_llm.py:221] Added request chatcmpl-d824e07c7f5045ffb5de194fac766350.
INFO 03-29 14:48:31 [logger.py:39] Received request chatcmpl-e0ab34181e2f41bfa997201fa9eb6b1c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:48:31 [async_llm.py:221] Added request chatcmpl-e0ab34181e2f41bfa997201fa9eb6b1c.
INFO 03-29 14:48:31 [logger.py:39] Received request chatcmpl-cd7a68a1284a4b65a2e8d971a4e86126: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:48:31 [async_llm.py:221] Added request chatcmpl-cd7a68a1284a4b65a2e8d971a4e86126.
INFO 03-29 14:48:31 [logger.py:39] Received request chatcmpl-e27e98b9989244ea95271a303404e53b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:48:32 [async_llm.py:221] Added request chatcmpl-e27e98b9989244ea95271a303404e53b.
INFO 03-29 14:48:32 [logger.py:39] Received request chatcmpl-40145ea2800543ca8f8045c93f5bd909: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:48:32 [async_llm.py:221] Added request chatcmpl-40145ea2800543ca8f8045c93f5bd909.
INFO 03-29 14:48:32 [logger.py:39] Received request chatcmpl-89e75cd8fca34fdcb4af3b4b02638c64: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sink (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) sink\n(B) pillow\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:48:32 [async_llm.py:221] Added request chatcmpl-89e75cd8fca34fdcb4af3b4b02638c64.
INFO 03-29 14:48:32 [logger.py:39] Received request chatcmpl-3426197ee1a94b74a7cacd82c0deadce: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:48:32 [async_llm.py:221] Added request chatcmpl-3426197ee1a94b74a7cacd82c0deadce.
INFO 03-29 14:48:32 [logger.py:39] Received request chatcmpl-e347f84e0b0c4a2a921568e9b1a9e516: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:48:32 [async_llm.py:221] Added request chatcmpl-e347f84e0b0c4a2a921568e9b1a9e516.
INFO 03-29 14:48:32 [logger.py:39] Received request chatcmpl-9d5d01bc45024feca4b745d6ca6a5350: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) door\n(B) pillow\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:48:32 [async_llm.py:221] Added request chatcmpl-9d5d01bc45024feca4b745d6ca6a5350.
INFO 03-29 14:48:40 [loggers.py:80] Avg prompt throughput: 440.8 tokens/s, Avg generation throughput: 0.7 tokens/s, Running: 5 reqs, Waiting: 11 reqs, GPU KV cache usage: 4.7%, Prefix cache hit rate: 0.0%
INFO 03-29 14:48:50 [loggers.py:80] Avg prompt throughput: 882.0 tokens/s, Avg generation throughput: 3.6 tokens/s, Running: 13 reqs, Waiting: 3 reqs, GPU KV cache usage: 12.0%, Prefix cache hit rate: 0.0%
INFO 03-29 14:49:00 [loggers.py:80] Avg prompt throughput: 440.8 tokens/s, Avg generation throughput: 188.4 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 16.9%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:02 [logger.py:39] Received request chatcmpl-1a18359b01fe4be9874f9b6f4e7a56e2: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) books\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:03 [async_llm.py:221] Added request chatcmpl-1a18359b01fe4be9874f9b6f4e7a56e2.
INFO 03-29 14:49:03 [logger.py:39] Received request chatcmpl-80bc6d263cb34185b252022fc52c5f7a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:03 [async_llm.py:221] Added request chatcmpl-80bc6d263cb34185b252022fc52c5f7a.
INFO:     127.0.0.1:39254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:06 [logger.py:39] Received request chatcmpl-f1247cdf2fbf475091b5a7a92d8ed631: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:06 [async_llm.py:221] Added request chatcmpl-f1247cdf2fbf475091b5a7a92d8ed631.
INFO:     127.0.0.1:39226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:07 [logger.py:39] Received request chatcmpl-c52064af99d84759a3ce1cc33ec4e851: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:07 [async_llm.py:221] Added request chatcmpl-c52064af99d84759a3ce1cc33ec4e851.
INFO:     127.0.0.1:39276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:10 [logger.py:39] Received request chatcmpl-7fa19ee5536b4c6fa4e12ed4ccd56a94: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) shelves\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:10 [async_llm.py:221] Added request chatcmpl-7fa19ee5536b4c6fa4e12ed4ccd56a94.
INFO:     127.0.0.1:39236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:10 [logger.py:39] Received request chatcmpl-0f0b2554ff884e80ae70b4ee8c91f712: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:11 [async_llm.py:221] Added request chatcmpl-0f0b2554ff884e80ae70b4ee8c91f712.
INFO 03-29 14:49:11 [loggers.py:80] Avg prompt throughput: 435.8 tokens/s, Avg generation throughput: 121.3 tokens/s, Running: 10 reqs, Waiting: 0 reqs, GPU KV cache usage: 10.7%, Prefix cache hit rate: 0.0%
INFO 03-29 14:49:11 [logger.py:39] Received request chatcmpl-9e1e28bd43824915baf2f0f465045090: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:11 [async_llm.py:221] Added request chatcmpl-9e1e28bd43824915baf2f0f465045090.
INFO 03-29 14:49:11 [logger.py:39] Received request chatcmpl-74bd5b69c2cc4aa3a0208d117ebd7dec: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:11 [async_llm.py:221] Added request chatcmpl-74bd5b69c2cc4aa3a0208d117ebd7dec.
INFO 03-29 14:49:11 [logger.py:39] Received request chatcmpl-6939cc1f778f42c0acef061608c91a26: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:11 [async_llm.py:221] Added request chatcmpl-6939cc1f778f42c0acef061608c91a26.
INFO 03-29 14:49:11 [logger.py:39] Received request chatcmpl-3c0c1cd2140d4de491a2a648f9f44580: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:11 [async_llm.py:221] Added request chatcmpl-3c0c1cd2140d4de491a2a648f9f44580.
INFO:     127.0.0.1:39242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:12 [logger.py:39] Received request chatcmpl-9b88c576da4646d286befb6921c7c3cf: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:12 [async_llm.py:221] Added request chatcmpl-9b88c576da4646d286befb6921c7c3cf.
INFO:     127.0.0.1:39222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:17 [logger.py:39] Received request chatcmpl-8b4a64a821a24524979dfad14789848c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:17 [async_llm.py:221] Added request chatcmpl-8b4a64a821a24524979dfad14789848c.
INFO:     127.0.0.1:39294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:20 [logger.py:39] Received request chatcmpl-21f0ed07084a495f826976654ab906ed: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:20 [async_llm.py:221] Added request chatcmpl-21f0ed07084a495f826976654ab906ed.
INFO 03-29 14:49:20 [logger.py:39] Received request chatcmpl-ee546749f201424585546f440a49d98e: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:20 [async_llm.py:221] Added request chatcmpl-ee546749f201424585546f440a49d98e.
INFO 03-29 14:49:21 [loggers.py:80] Avg prompt throughput: 661.9 tokens/s, Avg generation throughput: 4.9 tokens/s, Running: 13 reqs, Waiting: 0 reqs, GPU KV cache usage: 12.7%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:25 [logger.py:39] Received request chatcmpl-61eac3c5b1e54e2c8f1b32edcf2fb225: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:25 [async_llm.py:221] Added request chatcmpl-61eac3c5b1e54e2c8f1b32edcf2fb225.
INFO:     127.0.0.1:39238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:29 [logger.py:39] Received request chatcmpl-8c864e72271841efab040043c35cc9d9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:29 [async_llm.py:221] Added request chatcmpl-8c864e72271841efab040043c35cc9d9.
INFO 03-29 14:49:31 [loggers.py:80] Avg prompt throughput: 551.6 tokens/s, Avg generation throughput: 115.0 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.7%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:34 [logger.py:39] Received request chatcmpl-7334252d6e884c51a91262b323b95013: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) sofa\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:34 [async_llm.py:221] Added request chatcmpl-7334252d6e884c51a91262b323b95013.
INFO:     127.0.0.1:39254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:36 [logger.py:39] Received request chatcmpl-53463205652945d49ce85947086b0537: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) chair\n(B) shelves\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:36 [async_llm.py:221] Added request chatcmpl-53463205652945d49ce85947086b0537.
INFO:     127.0.0.1:39310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:38 [logger.py:39] Received request chatcmpl-1ad7ff4684b643b0b49ad5776affa808: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:38 [async_llm.py:221] Added request chatcmpl-1ad7ff4684b643b0b49ad5776affa808.
INFO 03-29 14:49:38 [logger.py:39] Received request chatcmpl-3e1a16186c154594801257a77f032f48: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) shelves\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:38 [async_llm.py:221] Added request chatcmpl-3e1a16186c154594801257a77f032f48.
INFO 03-29 14:49:41 [loggers.py:80] Avg prompt throughput: 440.8 tokens/s, Avg generation throughput: 160.8 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 16.3%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:42 [logger.py:39] Received request chatcmpl-c52887c215e34a95bafe1a8369cc8235: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:42 [async_llm.py:221] Added request chatcmpl-c52887c215e34a95bafe1a8369cc8235.
INFO:     127.0.0.1:39194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:42 [logger.py:39] Received request chatcmpl-66644a04d2744b8a96baa0491198723e: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the floor mat (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) floor mat\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:42 [async_llm.py:221] Added request chatcmpl-66644a04d2744b8a96baa0491198723e.
INFO 03-29 14:49:42 [logger.py:39] Received request chatcmpl-8345ea5cafdc4950af12ae3e32e19b02: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:42 [async_llm.py:221] Added request chatcmpl-8345ea5cafdc4950af12ae3e32e19b02.
INFO:     127.0.0.1:39210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:43 [logger.py:39] Received request chatcmpl-fc5348cc88f1493fb1fd0be36d41880d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:44 [async_llm.py:221] Added request chatcmpl-fc5348cc88f1493fb1fd0be36d41880d.
INFO:     127.0.0.1:39186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:48 [logger.py:39] Received request chatcmpl-f3355266864b42a99e41e2c5ae0b8b90: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the counter (highlighted by a blue box)?\n(A) lamp\n(B) counter\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:48 [async_llm.py:221] Added request chatcmpl-f3355266864b42a99e41e2c5ae0b8b90.
INFO 03-29 14:49:48 [logger.py:39] Received request chatcmpl-b7a0ca7fb51843dda789601e6395f1e9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:48 [async_llm.py:221] Added request chatcmpl-b7a0ca7fb51843dda789601e6395f1e9.
INFO 03-29 14:49:48 [logger.py:39] Received request chatcmpl-4c9a3cfe2d6649378c00d3b2aa30ecdb: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:48 [async_llm.py:221] Added request chatcmpl-4c9a3cfe2d6649378c00d3b2aa30ecdb.
INFO:     127.0.0.1:39300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:50 [logger.py:39] Received request chatcmpl-8a590260c6f84d7c9849574be674427b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:50 [async_llm.py:221] Added request chatcmpl-8a590260c6f84d7c9849574be674427b.
INFO 03-29 14:49:51 [loggers.py:80] Avg prompt throughput: 661.4 tokens/s, Avg generation throughput: 34.7 tokens/s, Running: 13 reqs, Waiting: 0 reqs, GPU KV cache usage: 13.3%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:54 [logger.py:39] Received request chatcmpl-f0192a63406d4433b05f96afca4e1aff: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:54 [async_llm.py:221] Added request chatcmpl-f0192a63406d4433b05f96afca4e1aff.
INFO:     127.0.0.1:39286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:56 [logger.py:39] Received request chatcmpl-7aa4992d31f444148cd36f455fbcd501: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) sofa\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:56 [async_llm.py:221] Added request chatcmpl-7aa4992d31f444148cd36f455fbcd501.
INFO:     127.0.0.1:39256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:49:57 [logger.py:39] Received request chatcmpl-8ae6fa7dd8be40f2a8a549599f0e087c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:49:57 [async_llm.py:221] Added request chatcmpl-8ae6fa7dd8be40f2a8a549599f0e087c.
INFO 03-29 14:50:01 [loggers.py:80] Avg prompt throughput: 661.4 tokens/s, Avg generation throughput: 84.5 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 16.3%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:03 [logger.py:39] Received request chatcmpl-1d1a9b0f97364104b8afed6fc443be94: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) shelves\n(B) mirror\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:03 [async_llm.py:221] Added request chatcmpl-1d1a9b0f97364104b8afed6fc443be94.
INFO:     127.0.0.1:39294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:05 [logger.py:39] Received request chatcmpl-cc97e2bdb31f4a7b86499b9edec2095a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:05 [async_llm.py:221] Added request chatcmpl-cc97e2bdb31f4a7b86499b9edec2095a.
INFO:     127.0.0.1:39272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:07 [logger.py:39] Received request chatcmpl-3d1f3422e12d401689d9742d1bf53030: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:08 [async_llm.py:221] Added request chatcmpl-3d1f3422e12d401689d9742d1bf53030.
INFO:     127.0.0.1:39226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:10 [logger.py:39] Received request chatcmpl-72659f0113e84bbeb3ca754c5b21c9c2: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:10 [async_llm.py:221] Added request chatcmpl-72659f0113e84bbeb3ca754c5b21c9c2.
INFO 03-29 14:50:11 [loggers.py:80] Avg prompt throughput: 330.6 tokens/s, Avg generation throughput: 177.8 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 16.3%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:12 [logger.py:39] Received request chatcmpl-869fe8a2992149848318beeb02ab923b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:12 [async_llm.py:221] Added request chatcmpl-869fe8a2992149848318beeb02ab923b.
INFO:     127.0.0.1:39236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:13 [logger.py:39] Received request chatcmpl-3685f8c55ae24b29a371600f289372be: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:13 [async_llm.py:221] Added request chatcmpl-3685f8c55ae24b29a371600f289372be.
INFO 03-29 14:50:13 [logger.py:39] Received request chatcmpl-2c2f5f36f8974d95a71dfe73edeffc73: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:13 [async_llm.py:221] Added request chatcmpl-2c2f5f36f8974d95a71dfe73edeffc73.
INFO 03-29 14:50:13 [logger.py:39] Received request chatcmpl-7fb50d6625154397a6955ae003d5f8a2: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:13 [async_llm.py:221] Added request chatcmpl-7fb50d6625154397a6955ae003d5f8a2.
INFO:     127.0.0.1:39276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:19 [logger.py:39] Received request chatcmpl-85e9a7f420d34ca081e8bc8e272f996d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) bookcase\n(B) pillow\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:19 [async_llm.py:221] Added request chatcmpl-85e9a7f420d34ca081e8bc8e272f996d.
INFO:     127.0.0.1:39286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:19 [logger.py:39] Received request chatcmpl-8d84c32ceb16452ebe06608b5fc02943: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) shelves\n(B) pillow\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:19 [async_llm.py:221] Added request chatcmpl-8d84c32ceb16452ebe06608b5fc02943.
INFO 03-29 14:50:21 [loggers.py:80] Avg prompt throughput: 661.8 tokens/s, Avg generation throughput: 53.1 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.9%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:22 [logger.py:39] Received request chatcmpl-06e4ba19c14549c4b01f2f2724cd9e8b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:22 [async_llm.py:221] Added request chatcmpl-06e4ba19c14549c4b01f2f2724cd9e8b.
INFO 03-29 14:50:22 [logger.py:39] Received request chatcmpl-ff0acaff069f43be815163e14128237a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:22 [async_llm.py:221] Added request chatcmpl-ff0acaff069f43be815163e14128237a.
INFO 03-29 14:50:22 [logger.py:39] Received request chatcmpl-7718f5efe69e443c8fb0abe1672d1d13: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:22 [async_llm.py:221] Added request chatcmpl-7718f5efe69e443c8fb0abe1672d1d13.
INFO:     127.0.0.1:39186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:27 [logger.py:39] Received request chatcmpl-d4c2e3bbe18a496cbc7ff699ddae80f1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:27 [async_llm.py:221] Added request chatcmpl-d4c2e3bbe18a496cbc7ff699ddae80f1.
INFO 03-29 14:50:27 [logger.py:39] Received request chatcmpl-0b06d3626fc84887b9d3330963856f6c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:27 [async_llm.py:221] Added request chatcmpl-0b06d3626fc84887b9d3330963856f6c.
INFO 03-29 14:50:27 [logger.py:39] Received request chatcmpl-c8d6d46ecae84ba2a1156453f398cc00: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:27 [async_llm.py:221] Added request chatcmpl-c8d6d46ecae84ba2a1156453f398cc00.
INFO 03-29 14:50:31 [loggers.py:80] Avg prompt throughput: 551.2 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 14 reqs, Waiting: 0 reqs, GPU KV cache usage: 14.0%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:33 [logger.py:39] Received request chatcmpl-debf2092dc2d48b5b4a1bdc440252839: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:33 [async_llm.py:221] Added request chatcmpl-debf2092dc2d48b5b4a1bdc440252839.
INFO:     127.0.0.1:39294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:37 [logger.py:39] Received request chatcmpl-d66a9ee534ea404ca5a45957582237f5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) table\n(B) blinds\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:37 [async_llm.py:221] Added request chatcmpl-d66a9ee534ea404ca5a45957582237f5.
INFO:     127.0.0.1:39272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:40 [logger.py:39] Received request chatcmpl-efe8c8e726904622a7d919c7a886d2d7: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:40 [async_llm.py:221] Added request chatcmpl-efe8c8e726904622a7d919c7a886d2d7.
INFO 03-29 14:50:40 [logger.py:39] Received request chatcmpl-811d79827efc4e1e8f974c99a9a0b8c3: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:40 [async_llm.py:221] Added request chatcmpl-811d79827efc4e1e8f974c99a9a0b8c3.
INFO 03-29 14:50:41 [loggers.py:80] Avg prompt throughput: 440.8 tokens/s, Avg generation throughput: 218.7 tokens/s, Running: 14 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.3%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:44 [logger.py:39] Received request chatcmpl-ba4bd356bcfe41839a089bcccad4fe4f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:44 [async_llm.py:221] Added request chatcmpl-ba4bd356bcfe41839a089bcccad4fe4f.
INFO:     127.0.0.1:39194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:44 [logger.py:39] Received request chatcmpl-669fd6e391484563958c4730de2e0869: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:44 [async_llm.py:221] Added request chatcmpl-669fd6e391484563958c4730de2e0869.
INFO 03-29 14:50:44 [logger.py:39] Received request chatcmpl-a022bbfdf020406494326a69d1a6b73f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:44 [async_llm.py:221] Added request chatcmpl-a022bbfdf020406494326a69d1a6b73f.
INFO:     127.0.0.1:39300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:49 [logger.py:39] Received request chatcmpl-d27457f918bd498380e754810b549344: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:49 [async_llm.py:221] Added request chatcmpl-d27457f918bd498380e754810b549344.
INFO 03-29 14:50:51 [loggers.py:80] Avg prompt throughput: 661.7 tokens/s, Avg generation throughput: 43.6 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 17.1%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:51 [logger.py:39] Received request chatcmpl-7da3fb13e8b649e5b8cff8145e21d217: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:51 [async_llm.py:221] Added request chatcmpl-7da3fb13e8b649e5b8cff8145e21d217.
INFO:     127.0.0.1:39254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:51 [logger.py:39] Received request chatcmpl-44dce92b7d4b4dd0b310181996135e05: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:51 [async_llm.py:221] Added request chatcmpl-44dce92b7d4b4dd0b310181996135e05.
INFO:     127.0.0.1:39310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:54 [logger.py:39] Received request chatcmpl-58ec9cf89dd544a7a656f117b4bd4e98: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:54 [async_llm.py:221] Added request chatcmpl-58ec9cf89dd544a7a656f117b4bd4e98.
INFO:     127.0.0.1:39276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:54 [logger.py:39] Received request chatcmpl-265dccb7892e4c12986649476a7ddcfd: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:54 [async_llm.py:221] Added request chatcmpl-265dccb7892e4c12986649476a7ddcfd.
INFO 03-29 14:50:54 [logger.py:39] Received request chatcmpl-f19b456e649446dc8b5d3f2dd2a197ab: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:55 [async_llm.py:221] Added request chatcmpl-f19b456e649446dc8b5d3f2dd2a197ab.
INFO:     127.0.0.1:39256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:59 [logger.py:39] Received request chatcmpl-842f180d27be469bbd5d0d79e142b075: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) box\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:59 [async_llm.py:221] Added request chatcmpl-842f180d27be469bbd5d0d79e142b075.
INFO:     127.0.0.1:39186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:50:59 [logger.py:39] Received request chatcmpl-fc79a423ebb745d39fafa8d0400ce8b9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:50:59 [async_llm.py:221] Added request chatcmpl-fc79a423ebb745d39fafa8d0400ce8b9.
INFO 03-29 14:51:00 [logger.py:39] Received request chatcmpl-e7ff7f8a10fd4d2abc1f9dbd6d7089d5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:00 [async_llm.py:221] Added request chatcmpl-e7ff7f8a10fd4d2abc1f9dbd6d7089d5.
INFO 03-29 14:51:01 [loggers.py:80] Avg prompt throughput: 551.2 tokens/s, Avg generation throughput: 54.9 tokens/s, Running: 13 reqs, Waiting: 0 reqs, GPU KV cache usage: 13.0%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:06 [logger.py:39] Received request chatcmpl-c2062ed1f892436cb2ba4a1bb2cd46b3: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:06 [async_llm.py:221] Added request chatcmpl-c2062ed1f892436cb2ba4a1bb2cd46b3.
INFO:     127.0.0.1:39294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:09 [logger.py:39] Received request chatcmpl-58879ae1cd2840368414f7a52782116b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) table\n(B) shelves\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:09 [async_llm.py:221] Added request chatcmpl-58879ae1cd2840368414f7a52782116b.
INFO 03-29 14:51:11 [loggers.py:80] Avg prompt throughput: 551.2 tokens/s, Avg generation throughput: 137.4 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 16.9%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:12 [logger.py:39] Received request chatcmpl-6e401f23b97346f083dd43ab2cb16acf: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:13 [async_llm.py:221] Added request chatcmpl-6e401f23b97346f083dd43ab2cb16acf.
INFO:     127.0.0.1:39286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:14 [logger.py:39] Received request chatcmpl-1e16b9eb29274a14af1cddce4846bc95: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) lamp\n(B) door\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:15 [async_llm.py:221] Added request chatcmpl-1e16b9eb29274a14af1cddce4846bc95.
INFO:     127.0.0.1:39236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:15 [logger.py:39] Received request chatcmpl-80ce793ded584c81b80fe3278d488059: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:15 [async_llm.py:221] Added request chatcmpl-80ce793ded584c81b80fe3278d488059.
INFO:     127.0.0.1:39272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:18 [logger.py:39] Received request chatcmpl-c08df5f3d4074a2cb068785b760d15e3: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) lamp\n(B) shelves\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:18 [async_llm.py:221] Added request chatcmpl-c08df5f3d4074a2cb068785b760d15e3.
INFO:     127.0.0.1:39194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:20 [logger.py:39] Received request chatcmpl-8022c99e95864d5fbf54b1676ba6f3be: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:20 [async_llm.py:221] Added request chatcmpl-8022c99e95864d5fbf54b1676ba6f3be.
INFO:     127.0.0.1:39210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:20 [logger.py:39] Received request chatcmpl-55c54bffd74b4418a24d13e83a88e880: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) books\n(B) mirror\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:20 [async_llm.py:221] Added request chatcmpl-55c54bffd74b4418a24d13e83a88e880.
INFO 03-29 14:51:20 [logger.py:39] Received request chatcmpl-de182824282b4c9898e094f2ae00bb75: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:20 [async_llm.py:221] Added request chatcmpl-de182824282b4c9898e094f2ae00bb75.
INFO 03-29 14:51:21 [loggers.py:80] Avg prompt throughput: 440.8 tokens/s, Avg generation throughput: 121.3 tokens/s, Running: 13 reqs, Waiting: 0 reqs, GPU KV cache usage: 13.9%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:24 [logger.py:39] Received request chatcmpl-6596e2655e634aeb89ab01055743f4c6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) pillow\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:25 [async_llm.py:221] Added request chatcmpl-6596e2655e634aeb89ab01055743f4c6.
INFO 03-29 14:51:25 [logger.py:39] Received request chatcmpl-b0782d8ada5a456fb560f0ecfeb0e006: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:25 [async_llm.py:221] Added request chatcmpl-b0782d8ada5a456fb560f0ecfeb0e006.
INFO:     127.0.0.1:39254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:26 [logger.py:39] Received request chatcmpl-36672ff5d26144948a120b8f8346c10f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:26 [async_llm.py:221] Added request chatcmpl-36672ff5d26144948a120b8f8346c10f.
INFO:     127.0.0.1:39256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:29 [logger.py:39] Received request chatcmpl-10672ecea28f4bd3b5a67d17720a99ff: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:29 [async_llm.py:221] Added request chatcmpl-10672ecea28f4bd3b5a67d17720a99ff.
INFO:     127.0.0.1:39300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:30 [logger.py:39] Received request chatcmpl-7f5854c8af824a8a8995a7abd5f47212: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:30 [async_llm.py:221] Added request chatcmpl-7f5854c8af824a8a8995a7abd5f47212.
INFO 03-29 14:51:31 [loggers.py:80] Avg prompt throughput: 661.2 tokens/s, Avg generation throughput: 34.3 tokens/s, Running: 14 reqs, Waiting: 0 reqs, GPU KV cache usage: 14.2%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:33 [logger.py:39] Received request chatcmpl-f45db350bdb843b2a58a0488d629e6b8: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:33 [async_llm.py:221] Added request chatcmpl-f45db350bdb843b2a58a0488d629e6b8.
INFO:     127.0.0.1:39186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:34 [logger.py:39] Received request chatcmpl-12b1f077f60b43d1aec611a5859623b2: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) door\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:35 [async_llm.py:221] Added request chatcmpl-12b1f077f60b43d1aec611a5859623b2.
INFO:     127.0.0.1:39238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:37 [logger.py:39] Received request chatcmpl-6d3e1fb24d6b4fd9b4c6c2d541ea6beb: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:37 [async_llm.py:221] Added request chatcmpl-6d3e1fb24d6b4fd9b4c6c2d541ea6beb.
INFO:     127.0.0.1:39294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:41 [loggers.py:80] Avg prompt throughput: 551.4 tokens/s, Avg generation throughput: 133.6 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.7%, Prefix cache hit rate: 0.0%
INFO 03-29 14:51:41 [logger.py:39] Received request chatcmpl-1b3404c102804d92baa2480dbd837b5b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:41 [async_llm.py:221] Added request chatcmpl-1b3404c102804d92baa2480dbd837b5b.
INFO:     127.0.0.1:39194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:45 [logger.py:39] Received request chatcmpl-74504c40f1ea4793889208ab41c37474: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:45 [async_llm.py:221] Added request chatcmpl-74504c40f1ea4793889208ab41c37474.
INFO:     127.0.0.1:39286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:47 [logger.py:39] Received request chatcmpl-d0abeb086ec94ec281f77d09b023991c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:47 [async_llm.py:221] Added request chatcmpl-d0abeb086ec94ec281f77d09b023991c.
INFO:     127.0.0.1:39242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:47 [logger.py:39] Received request chatcmpl-47ff6c9563d24a35bf8f91e4f7245812: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:47 [async_llm.py:221] Added request chatcmpl-47ff6c9563d24a35bf8f91e4f7245812.
INFO 03-29 14:51:47 [logger.py:39] Received request chatcmpl-e7eb2d2f64894871a92f80cf43dd113c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:47 [async_llm.py:221] Added request chatcmpl-e7eb2d2f64894871a92f80cf43dd113c.
INFO 03-29 14:51:51 [loggers.py:80] Avg prompt throughput: 330.6 tokens/s, Avg generation throughput: 117.7 tokens/s, Running: 14 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.2%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:52 [logger.py:39] Received request chatcmpl-e0b8e43929a3444d8df65f50d928c8c8: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) desk\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:52 [async_llm.py:221] Added request chatcmpl-e0b8e43929a3444d8df65f50d928c8c8.
INFO 03-29 14:51:52 [logger.py:39] Received request chatcmpl-c5683878d9254571ac85d022603c7aec: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:52 [async_llm.py:221] Added request chatcmpl-c5683878d9254571ac85d022603c7aec.
INFO:     127.0.0.1:39310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:55 [logger.py:39] Received request chatcmpl-be2b0e5a8292443d8c64093e00c9a44d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:55 [async_llm.py:221] Added request chatcmpl-be2b0e5a8292443d8c64093e00c9a44d.
INFO:     127.0.0.1:39210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:55 [logger.py:39] Received request chatcmpl-b2cd93ec246e4ba59684826ff7f1700b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:55 [async_llm.py:221] Added request chatcmpl-b2cd93ec246e4ba59684826ff7f1700b.
INFO:     127.0.0.1:39272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:51:57 [logger.py:39] Received request chatcmpl-6050b7bcba1840919bde02b191f9dbc8: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:57 [async_llm.py:221] Added request chatcmpl-6050b7bcba1840919bde02b191f9dbc8.
INFO 03-29 14:51:57 [logger.py:39] Received request chatcmpl-9ff243bbc04d4024a87a13939479cabb: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:57 [async_llm.py:221] Added request chatcmpl-9ff243bbc04d4024a87a13939479cabb.
INFO 03-29 14:51:57 [logger.py:39] Received request chatcmpl-7b14331259ef40c4b70c280ca2a01c2a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:51:57 [async_llm.py:221] Added request chatcmpl-7b14331259ef40c4b70c280ca2a01c2a.
INFO 03-29 14:52:01 [loggers.py:80] Avg prompt throughput: 771.8 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 14 reqs, Waiting: 0 reqs, GPU KV cache usage: 14.3%, Prefix cache hit rate: 0.9%
INFO:     127.0.0.1:39254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:02 [logger.py:39] Received request chatcmpl-7076a59de2dc45598421bbdaea7da131: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:02 [async_llm.py:221] Added request chatcmpl-7076a59de2dc45598421bbdaea7da131.
INFO:     127.0.0.1:39222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:04 [logger.py:39] Received request chatcmpl-a6c106712aba49038428ee29b5e104c4: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sink (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) sink\n(B) pillow\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:04 [async_llm.py:221] Added request chatcmpl-a6c106712aba49038428ee29b5e104c4.
INFO:     127.0.0.1:39238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:06 [logger.py:39] Received request chatcmpl-a7e352937790429792cb57aac62fe811: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:06 [async_llm.py:221] Added request chatcmpl-a7e352937790429792cb57aac62fe811.
INFO:     127.0.0.1:39256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:09 [logger.py:39] Received request chatcmpl-45c541c6d8d549da86c6a3f7f9e4ced4: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) door\n(B) pillow\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:09 [async_llm.py:221] Added request chatcmpl-45c541c6d8d549da86c6a3f7f9e4ced4.
INFO 03-29 14:52:11 [loggers.py:80] Avg prompt throughput: 661.4 tokens/s, Avg generation throughput: 125.4 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 16.7%, Prefix cache hit rate: 0.9%
INFO:     127.0.0.1:39294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:12 [logger.py:39] Received request chatcmpl-afac2ac465774ebc933a9b4f999aff25: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:12 [async_llm.py:221] Added request chatcmpl-afac2ac465774ebc933a9b4f999aff25.
INFO:     127.0.0.1:39236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:15 [logger.py:39] Received request chatcmpl-70397db461834e9e8d711835f3995b27: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:15 [async_llm.py:221] Added request chatcmpl-70397db461834e9e8d711835f3995b27.
INFO:     127.0.0.1:39194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:17 [logger.py:39] Received request chatcmpl-9da420fbe8f44b01aa2a29f2515c4de7: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:17 [async_llm.py:221] Added request chatcmpl-9da420fbe8f44b01aa2a29f2515c4de7.
INFO:     127.0.0.1:39242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:19 [logger.py:39] Received request chatcmpl-1534f5ca5c6a4f4095f9e019d195daee: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:19 [async_llm.py:221] Added request chatcmpl-1534f5ca5c6a4f4095f9e019d195daee.
INFO:     127.0.0.1:39226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:19 [logger.py:39] Received request chatcmpl-34d2bf4700d74f328ce244bec62e98ea: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) books\n(B) lamp\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:19 [async_llm.py:221] Added request chatcmpl-34d2bf4700d74f328ce244bec62e98ea.
INFO 03-29 14:52:21 [loggers.py:80] Avg prompt throughput: 440.7 tokens/s, Avg generation throughput: 146.3 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 16.1%, Prefix cache hit rate: 0.8%
INFO:     127.0.0.1:39310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:22 [logger.py:39] Received request chatcmpl-d2ef244e3b7142a3950de42493fb73e5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:22 [async_llm.py:221] Added request chatcmpl-d2ef244e3b7142a3950de42493fb73e5.
INFO:     127.0.0.1:39286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:23 [logger.py:39] Received request chatcmpl-df5f9c51b71349c19e5e34af6441b9e7: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:23 [async_llm.py:221] Added request chatcmpl-df5f9c51b71349c19e5e34af6441b9e7.
INFO:     127.0.0.1:39272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:26 [logger.py:39] Received request chatcmpl-13c280de9cfa4fd48d605ebede0e310f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:26 [async_llm.py:221] Added request chatcmpl-13c280de9cfa4fd48d605ebede0e310f.
INFO:     127.0.0.1:39210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:27 [logger.py:39] Received request chatcmpl-d1457136333c4de58366ce4c5bb6b838: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) shelves\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:27 [async_llm.py:221] Added request chatcmpl-d1457136333c4de58366ce4c5bb6b838.
INFO:     127.0.0.1:39276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:28 [logger.py:39] Received request chatcmpl-dcf36c6676284ecd936562f74a96706d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:28 [async_llm.py:221] Added request chatcmpl-dcf36c6676284ecd936562f74a96706d.
INFO:     127.0.0.1:39186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:31 [logger.py:39] Received request chatcmpl-04b9c0ba55664474a4fac6468bacf654: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:31 [async_llm.py:221] Added request chatcmpl-04b9c0ba55664474a4fac6468bacf654.
INFO 03-29 14:52:31 [loggers.py:80] Avg prompt throughput: 657.3 tokens/s, Avg generation throughput: 43.9 tokens/s, Running: 13 reqs, Waiting: 0 reqs, GPU KV cache usage: 13.2%, Prefix cache hit rate: 0.8%
INFO 03-29 14:52:31 [logger.py:39] Received request chatcmpl-3d96821f2fcd458ab266570ee1e36ded: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:31 [async_llm.py:221] Added request chatcmpl-3d96821f2fcd458ab266570ee1e36ded.
INFO 03-29 14:52:31 [logger.py:39] Received request chatcmpl-b9f4918f6d6c49d4893de920ee62a357: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:31 [async_llm.py:221] Added request chatcmpl-b9f4918f6d6c49d4893de920ee62a357.
INFO:     127.0.0.1:39238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:35 [logger.py:39] Received request chatcmpl-52c385d797db4c8d8ae2466ad22b0a9c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:35 [async_llm.py:221] Added request chatcmpl-52c385d797db4c8d8ae2466ad22b0a9c.
INFO:     127.0.0.1:39254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:37 [logger.py:39] Received request chatcmpl-8a4b406d0297492bbe152b77a026860b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:37 [async_llm.py:221] Added request chatcmpl-8a4b406d0297492bbe152b77a026860b.
INFO:     127.0.0.1:39256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:40 [logger.py:39] Received request chatcmpl-c929f9fd77fb45699ca514371e4c2ea9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:40 [async_llm.py:221] Added request chatcmpl-c929f9fd77fb45699ca514371e4c2ea9.
INFO 03-29 14:52:41 [loggers.py:80] Avg prompt throughput: 551.6 tokens/s, Avg generation throughput: 96.4 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.5%, Prefix cache hit rate: 0.8%
INFO:     127.0.0.1:39294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:44 [logger.py:39] Received request chatcmpl-ce0e53cdbeea46f785e02b1c26bdc03d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:44 [async_llm.py:221] Added request chatcmpl-ce0e53cdbeea46f785e02b1c26bdc03d.
INFO:     127.0.0.1:39236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:47 [logger.py:39] Received request chatcmpl-9668c569aaeb4f17ab1a9976a50cd3eb: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:47 [async_llm.py:221] Added request chatcmpl-9668c569aaeb4f17ab1a9976a50cd3eb.
INFO 03-29 14:52:48 [logger.py:39] Received request chatcmpl-9b322dd3cc7a45e284105016a4038071: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:48 [async_llm.py:221] Added request chatcmpl-9b322dd3cc7a45e284105016a4038071.
INFO 03-29 14:52:51 [loggers.py:80] Avg prompt throughput: 441.4 tokens/s, Avg generation throughput: 149.9 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 17.3%, Prefix cache hit rate: 0.7%
INFO:     127.0.0.1:39286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:51 [logger.py:39] Received request chatcmpl-1a3b8ea248fc4594ac8e21829ea67bf2: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:51 [async_llm.py:221] Added request chatcmpl-1a3b8ea248fc4594ac8e21829ea67bf2.
INFO:     127.0.0.1:39194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:51 [logger.py:39] Received request chatcmpl-a9c50e4b428c4e82a9cf2d23b29e5962: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) sofa\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:51 [async_llm.py:221] Added request chatcmpl-a9c50e4b428c4e82a9cf2d23b29e5962.
INFO 03-29 14:52:52 [logger.py:39] Received request chatcmpl-9f3e29463cd842dbbf6218743b9155c3: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) chair\n(B) shelves\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:52 [async_llm.py:221] Added request chatcmpl-9f3e29463cd842dbbf6218743b9155c3.
INFO 03-29 14:52:52 [logger.py:39] Received request chatcmpl-d16b501339d24918b3f34b55b7f423ff: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:52 [async_llm.py:221] Added request chatcmpl-d16b501339d24918b3f34b55b7f423ff.
INFO:     127.0.0.1:39272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:55 [logger.py:39] Received request chatcmpl-9e4c5c57f86f4f12af8adfee7b7db7e7: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) shelves\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:55 [async_llm.py:221] Added request chatcmpl-9e4c5c57f86f4f12af8adfee7b7db7e7.
INFO:     127.0.0.1:39222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:52:57 [logger.py:39] Received request chatcmpl-8c58838203ac43debe085c7b7582087d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:57 [async_llm.py:221] Added request chatcmpl-8c58838203ac43debe085c7b7582087d.
INFO 03-29 14:52:57 [logger.py:39] Received request chatcmpl-ef6a27ed4f034f518d02539e4b5f4c09: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the floor mat (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) floor mat\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:52:57 [async_llm.py:221] Added request chatcmpl-ef6a27ed4f034f518d02539e4b5f4c09.
INFO:     127.0.0.1:39276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:00 [logger.py:39] Received request chatcmpl-a15f1d0f6b604066b3aa8fda04a0267e: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:00 [async_llm.py:221] Added request chatcmpl-a15f1d0f6b604066b3aa8fda04a0267e.
INFO:     127.0.0.1:39242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:00 [logger.py:39] Received request chatcmpl-d5655de1d43f4ddc8ff39c298fbbdd4f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:00 [async_llm.py:221] Added request chatcmpl-d5655de1d43f4ddc8ff39c298fbbdd4f.
INFO 03-29 14:53:01 [loggers.py:80] Avg prompt throughput: 771.6 tokens/s, Avg generation throughput: 58.5 tokens/s, Running: 14 reqs, Waiting: 0 reqs, GPU KV cache usage: 14.3%, Prefix cache hit rate: 2.0%
INFO:     127.0.0.1:39210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:03 [logger.py:39] Received request chatcmpl-8fdd578c3eed40a5afe0c05d55ca3b44: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the counter (highlighted by a blue box)?\n(A) lamp\n(B) counter\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:03 [async_llm.py:221] Added request chatcmpl-8fdd578c3eed40a5afe0c05d55ca3b44.
INFO:     127.0.0.1:39238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:05 [logger.py:39] Received request chatcmpl-da3e8cec7a8f4cbda3f8639cf8c6b349: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:05 [async_llm.py:221] Added request chatcmpl-da3e8cec7a8f4cbda3f8639cf8c6b349.
INFO:     127.0.0.1:39254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:08 [logger.py:39] Received request chatcmpl-fd76472b989745d2b09503ae72b87758: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:08 [async_llm.py:221] Added request chatcmpl-fd76472b989745d2b09503ae72b87758.
INFO:     127.0.0.1:39256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:10 [logger.py:39] Received request chatcmpl-f102d4d1b7b049d080cad646b465db03: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:10 [async_llm.py:221] Added request chatcmpl-f102d4d1b7b049d080cad646b465db03.
INFO 03-29 14:53:11 [loggers.py:80] Avg prompt throughput: 551.0 tokens/s, Avg generation throughput: 101.6 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.5%, Prefix cache hit rate: 2.0%
INFO:     127.0.0.1:39236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:13 [logger.py:39] Received request chatcmpl-ec75ccdcf61a4753ba3cb81d9aed27d4: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:13 [async_llm.py:221] Added request chatcmpl-ec75ccdcf61a4753ba3cb81d9aed27d4.
INFO 03-29 14:53:14 [logger.py:39] Received request chatcmpl-5d843299fc8341d19f1da850e842b98a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) sofa\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:14 [async_llm.py:221] Added request chatcmpl-5d843299fc8341d19f1da850e842b98a.
INFO:     127.0.0.1:39226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:19 [logger.py:39] Received request chatcmpl-d2c736109617497792e7f5c5fba68b71: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:19 [async_llm.py:221] Added request chatcmpl-d2c736109617497792e7f5c5fba68b71.
INFO 03-29 14:53:21 [loggers.py:80] Avg prompt throughput: 330.8 tokens/s, Avg generation throughput: 174.1 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 16.5%, Prefix cache hit rate: 1.9%
INFO:     127.0.0.1:39222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:21 [logger.py:39] Received request chatcmpl-6a58f7f0a10a4413acd3ec732ff2ceed: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) shelves\n(B) mirror\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:21 [async_llm.py:221] Added request chatcmpl-6a58f7f0a10a4413acd3ec732ff2ceed.
INFO 03-29 14:53:21 [logger.py:39] Received request chatcmpl-bf37f095d5d34cceb1989ee647da5998: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:21 [async_llm.py:221] Added request chatcmpl-bf37f095d5d34cceb1989ee647da5998.
INFO 03-29 14:53:22 [logger.py:39] Received request chatcmpl-ada2642685b545bfa346718d2ab3b89f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:22 [async_llm.py:221] Added request chatcmpl-ada2642685b545bfa346718d2ab3b89f.
INFO:     127.0.0.1:39276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:26 [logger.py:39] Received request chatcmpl-512496fb0018425da454dff21aca1c68: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:26 [async_llm.py:221] Added request chatcmpl-512496fb0018425da454dff21aca1c68.
INFO:     127.0.0.1:39310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:26 [logger.py:39] Received request chatcmpl-21a9d6aa8345457280e01143a8078f0b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:27 [async_llm.py:221] Added request chatcmpl-21a9d6aa8345457280e01143a8078f0b.
INFO 03-29 14:53:27 [logger.py:39] Received request chatcmpl-26c5a9b2b93447478908ad78a3e05d15: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:27 [async_llm.py:221] Added request chatcmpl-26c5a9b2b93447478908ad78a3e05d15.
INFO 03-29 14:53:31 [loggers.py:80] Avg prompt throughput: 661.4 tokens/s, Avg generation throughput: 39.2 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 16.9%, Prefix cache hit rate: 1.8%
INFO:     127.0.0.1:39300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:31 [logger.py:39] Received request chatcmpl-26ba31040a7c493b824c91fd8c29d5cf: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:31 [async_llm.py:221] Added request chatcmpl-26ba31040a7c493b824c91fd8c29d5cf.
INFO:     127.0.0.1:39210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:31 [logger.py:39] Received request chatcmpl-2fe1ec17e9ed4d8593bae4b2f9200253: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:31 [async_llm.py:221] Added request chatcmpl-2fe1ec17e9ed4d8593bae4b2f9200253.
INFO:     127.0.0.1:39186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:34 [logger.py:39] Received request chatcmpl-75c3aee633554d2ba3db10f937a34aa8: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) bookcase\n(B) pillow\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:35 [async_llm.py:221] Added request chatcmpl-75c3aee633554d2ba3db10f937a34aa8.
INFO:     127.0.0.1:39194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:37 [logger.py:39] Received request chatcmpl-6e735ec4f6a945249533fef1a6d65010: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) shelves\n(B) pillow\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:37 [async_llm.py:221] Added request chatcmpl-6e735ec4f6a945249533fef1a6d65010.
INFO 03-29 14:53:37 [logger.py:39] Received request chatcmpl-5755505295a443359cbbe4a96afd4a87: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:37 [async_llm.py:221] Added request chatcmpl-5755505295a443359cbbe4a96afd4a87.
INFO:     127.0.0.1:39254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:40 [logger.py:39] Received request chatcmpl-0c797d192fee4f8e9eab6e5cf2d07685: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:40 [async_llm.py:221] Added request chatcmpl-0c797d192fee4f8e9eab6e5cf2d07685.
INFO 03-29 14:53:41 [loggers.py:80] Avg prompt throughput: 661.6 tokens/s, Avg generation throughput: 69.6 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.1%, Prefix cache hit rate: 1.8%
INFO:     127.0.0.1:39256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:42 [logger.py:39] Received request chatcmpl-1912d30ef0f14e6b8a8f11555eae0a6a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:42 [async_llm.py:221] Added request chatcmpl-1912d30ef0f14e6b8a8f11555eae0a6a.
INFO:     127.0.0.1:39236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:45 [logger.py:39] Received request chatcmpl-aa7b7aeb51fe4c21971307c2ce453e26: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:45 [async_llm.py:221] Added request chatcmpl-aa7b7aeb51fe4c21971307c2ce453e26.
INFO 03-29 14:53:45 [logger.py:39] Received request chatcmpl-2ce0cc5eb77a45138d6136de1c0b2184: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:45 [async_llm.py:221] Added request chatcmpl-2ce0cc5eb77a45138d6136de1c0b2184.
INFO 03-29 14:53:51 [loggers.py:80] Avg prompt throughput: 441.0 tokens/s, Avg generation throughput: 167.6 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 17.2%, Prefix cache hit rate: 1.7%
INFO:     127.0.0.1:39226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:51 [logger.py:39] Received request chatcmpl-1a679ba96f86415ab2f365857cbf9bc0: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:51 [async_llm.py:221] Added request chatcmpl-1a679ba96f86415ab2f365857cbf9bc0.
INFO:     127.0.0.1:39222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:53 [logger.py:39] Received request chatcmpl-69d90ce1350c4730be0b6c949bb45b0f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:53 [async_llm.py:221] Added request chatcmpl-69d90ce1350c4730be0b6c949bb45b0f.
INFO:     127.0.0.1:39310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:55 [logger.py:39] Received request chatcmpl-48e43754e53c4d6eb99d8c561467179c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) table\n(B) blinds\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:55 [async_llm.py:221] Added request chatcmpl-48e43754e53c4d6eb99d8c561467179c.
INFO 03-29 14:53:55 [logger.py:39] Received request chatcmpl-2965d682877741cda7a4dae83d4864fb: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:55 [async_llm.py:221] Added request chatcmpl-2965d682877741cda7a4dae83d4864fb.
INFO:     127.0.0.1:39286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:53:59 [logger.py:39] Received request chatcmpl-ea22142723f54fccb7766dc3ae131d56: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:59 [async_llm.py:221] Added request chatcmpl-ea22142723f54fccb7766dc3ae131d56.
INFO 03-29 14:53:59 [logger.py:39] Received request chatcmpl-14cf12932b3148fba77ad5343fd3a704: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:59 [async_llm.py:221] Added request chatcmpl-14cf12932b3148fba77ad5343fd3a704.
INFO 03-29 14:53:59 [logger.py:39] Received request chatcmpl-240eefe107bc4a07a3f482469b31ef34: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:53:59 [async_llm.py:221] Added request chatcmpl-240eefe107bc4a07a3f482469b31ef34.
INFO 03-29 14:54:01 [loggers.py:80] Avg prompt throughput: 551.1 tokens/s, Avg generation throughput: 90.7 tokens/s, Running: 14 reqs, Waiting: 0 reqs, GPU KV cache usage: 14.9%, Prefix cache hit rate: 1.7%
INFO:     127.0.0.1:39300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:04 [logger.py:39] Received request chatcmpl-bd24e19b688547f18492ead80d347a26: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:04 [async_llm.py:221] Added request chatcmpl-bd24e19b688547f18492ead80d347a26.
INFO:     127.0.0.1:39256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:06 [logger.py:39] Received request chatcmpl-cbfea3b2047e4d749302f404d12be1b0: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:06 [async_llm.py:221] Added request chatcmpl-cbfea3b2047e4d749302f404d12be1b0.
INFO 03-29 14:54:06 [logger.py:39] Received request chatcmpl-0028e0b05763468f8485275d276160f6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:06 [async_llm.py:221] Added request chatcmpl-0028e0b05763468f8485275d276160f6.
INFO 03-29 14:54:06 [logger.py:39] Received request chatcmpl-497d72fbe3ff4b93b5a0eaa063e4622f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:06 [async_llm.py:221] Added request chatcmpl-497d72fbe3ff4b93b5a0eaa063e4622f.
INFO 03-29 14:54:06 [logger.py:39] Received request chatcmpl-cadfb7de96b34c85bee63c3e5784276f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:06 [async_llm.py:221] Added request chatcmpl-cadfb7de96b34c85bee63c3e5784276f.
INFO 03-29 14:54:11 [loggers.py:80] Avg prompt throughput: 551.6 tokens/s, Avg generation throughput: 29.9 tokens/s, Running: 15 reqs, Waiting: 1 reqs, GPU KV cache usage: 15.1%, Prefix cache hit rate: 1.6%
INFO:     127.0.0.1:39210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:12 [logger.py:39] Received request chatcmpl-0814507d7d124cc0ae01373fe2363b87: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:13 [async_llm.py:221] Added request chatcmpl-0814507d7d124cc0ae01373fe2363b87.
INFO:     127.0.0.1:39238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:14 [logger.py:39] Received request chatcmpl-c21eeef1c65547538cc359604b9f7f1c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:14 [async_llm.py:221] Added request chatcmpl-c21eeef1c65547538cc359604b9f7f1c.
INFO:     127.0.0.1:39294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:18 [logger.py:39] Received request chatcmpl-58e0d6266fef4137a30bfad13f4a8671: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) box\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:18 [async_llm.py:221] Added request chatcmpl-58e0d6266fef4137a30bfad13f4a8671.
INFO:     127.0.0.1:39236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:19 [logger.py:39] Received request chatcmpl-bacf52eeb9f14d028f6eae60919a86c4: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:19 [async_llm.py:221] Added request chatcmpl-bacf52eeb9f14d028f6eae60919a86c4.
INFO 03-29 14:54:21 [loggers.py:80] Avg prompt throughput: 550.7 tokens/s, Avg generation throughput: 120.5 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.6%, Prefix cache hit rate: 1.6%
INFO:     127.0.0.1:39226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:23 [logger.py:39] Received request chatcmpl-bf3a578ff9834fb2b377c8708d5bd443: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:23 [async_llm.py:221] Added request chatcmpl-bf3a578ff9834fb2b377c8708d5bd443.
INFO:     127.0.0.1:39310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:25 [logger.py:39] Received request chatcmpl-70bcbdf200804cb4b4bfa38c316c73ca: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:25 [async_llm.py:221] Added request chatcmpl-70bcbdf200804cb4b4bfa38c316c73ca.
INFO:     127.0.0.1:39222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:27 [logger.py:39] Received request chatcmpl-3ed122347de54b67bf0e2f27ec108175: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) table\n(B) shelves\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:27 [async_llm.py:221] Added request chatcmpl-3ed122347de54b67bf0e2f27ec108175.
INFO:     127.0.0.1:39186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:29 [logger.py:39] Received request chatcmpl-555389f663c94e92a9108f2f7101be80: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:29 [async_llm.py:221] Added request chatcmpl-555389f663c94e92a9108f2f7101be80.
INFO:     127.0.0.1:39286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:30 [logger.py:39] Received request chatcmpl-86b8cc1dd5294551b8b73f9afc120196: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) lamp\n(B) door\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:30 [async_llm.py:221] Added request chatcmpl-86b8cc1dd5294551b8b73f9afc120196.
INFO 03-29 14:54:30 [logger.py:39] Received request chatcmpl-e444144e9ff34afe8014a18221112105: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:30 [async_llm.py:221] Added request chatcmpl-e444144e9ff34afe8014a18221112105.
INFO 03-29 14:54:30 [logger.py:39] Received request chatcmpl-2af16150a19149709410a8fadb1c0fe7: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) lamp\n(B) shelves\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:30 [async_llm.py:221] Added request chatcmpl-2af16150a19149709410a8fadb1c0fe7.
INFO 03-29 14:54:31 [loggers.py:80] Avg prompt throughput: 441.0 tokens/s, Avg generation throughput: 148.6 tokens/s, Running: 12 reqs, Waiting: 0 reqs, GPU KV cache usage: 12.8%, Prefix cache hit rate: 1.6%
INFO:     127.0.0.1:39272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:36 [logger.py:39] Received request chatcmpl-8925714483d14b49aa9a1b12c45262c1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:36 [async_llm.py:221] Added request chatcmpl-8925714483d14b49aa9a1b12c45262c1.
INFO:     127.0.0.1:39210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:38 [logger.py:39] Received request chatcmpl-2992759fdde64f3fb49760ff82348b67: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) books\n(B) mirror\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:38 [async_llm.py:221] Added request chatcmpl-2992759fdde64f3fb49760ff82348b67.
INFO:     127.0.0.1:39276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:38 [logger.py:39] Received request chatcmpl-d329ab1a7f5b44679420ab19da724eb0: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:38 [async_llm.py:221] Added request chatcmpl-d329ab1a7f5b44679420ab19da724eb0.
INFO 03-29 14:54:41 [loggers.py:80] Avg prompt throughput: 661.1 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.5%, Prefix cache hit rate: 1.5%
INFO:     127.0.0.1:39254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:41 [logger.py:39] Received request chatcmpl-57e5986e7ba34c2484b534741a42d157: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) pillow\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:41 [async_llm.py:221] Added request chatcmpl-57e5986e7ba34c2484b534741a42d157.
INFO:     127.0.0.1:39256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:43 [logger.py:39] Received request chatcmpl-4969ae2348714ffc926689a032203305: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:43 [async_llm.py:221] Added request chatcmpl-4969ae2348714ffc926689a032203305.
INFO:     127.0.0.1:39238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:44 [logger.py:39] Received request chatcmpl-db517446385a4b22ae3ebf241d9e7e2a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:44 [async_llm.py:221] Added request chatcmpl-db517446385a4b22ae3ebf241d9e7e2a.
INFO:     127.0.0.1:39300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:45 [logger.py:39] Received request chatcmpl-c644cecc4e6b45b2a6929dc89d88b5f5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:45 [async_llm.py:221] Added request chatcmpl-c644cecc4e6b45b2a6929dc89d88b5f5.
INFO:     127.0.0.1:39294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:49 [logger.py:39] Received request chatcmpl-14a4e99104fd4a02abaf7cd392a740d1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:49 [async_llm.py:221] Added request chatcmpl-14a4e99104fd4a02abaf7cd392a740d1.
INFO 03-29 14:54:51 [loggers.py:80] Avg prompt throughput: 551.2 tokens/s, Avg generation throughput: 92.3 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.5%, Prefix cache hit rate: 1.5%
INFO:     127.0.0.1:39236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:51 [logger.py:39] Received request chatcmpl-87402426472d47988d9265665440a145: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:51 [async_llm.py:221] Added request chatcmpl-87402426472d47988d9265665440a145.
INFO:     127.0.0.1:39310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:55 [logger.py:39] Received request chatcmpl-0468c5e363744bdd8af7eb3b84323ef1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) door\n(B) table\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:55 [async_llm.py:221] Added request chatcmpl-0468c5e363744bdd8af7eb3b84323ef1.
INFO:     127.0.0.1:39222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:58 [logger.py:39] Received request chatcmpl-5622882417bd41979ab94a3bb5c530ff: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:58 [async_llm.py:221] Added request chatcmpl-5622882417bd41979ab94a3bb5c530ff.
INFO:     127.0.0.1:39272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:54:58 [logger.py:39] Received request chatcmpl-38b16dc5ba55493984debca194c1bd38: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:58 [async_llm.py:221] Added request chatcmpl-38b16dc5ba55493984debca194c1bd38.
INFO 03-29 14:54:58 [logger.py:39] Received request chatcmpl-539d8ee50eaf4bf8bae3660734a773c4: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:54:58 [async_llm.py:221] Added request chatcmpl-539d8ee50eaf4bf8bae3660734a773c4.
INFO 03-29 14:55:01 [loggers.py:80] Avg prompt throughput: 441.2 tokens/s, Avg generation throughput: 144.7 tokens/s, Running: 14 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.2%, Prefix cache hit rate: 1.4%
INFO:     127.0.0.1:39226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:55:03 [logger.py:39] Received request chatcmpl-3c740327e3994b7fa71e3823c0eba3af: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n Hint: According to me, the answer is (B)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:55:03 [async_llm.py:221] Added request chatcmpl-3c740327e3994b7fa71e3823c0eba3af.
INFO:     127.0.0.1:39194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:55:03 [logger.py:39] Received request chatcmpl-c180f87d27904325b70cf24fae08b8be: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n Hint: According to me, the answer is (A)\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.05, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-29 14:55:03 [async_llm.py:221] Added request chatcmpl-c180f87d27904325b70cf24fae08b8be.
INFO:     127.0.0.1:39186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-29 14:55:11 [loggers.py:80] Avg prompt throughput: 441.0 tokens/s, Avg generation throughput: 144.1 tokens/s, Running: 7 reqs, Waiting: 0 reqs, GPU KV cache usage: 7.6%, Prefix cache hit rate: 1.4%
INFO:     127.0.0.1:39300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39310 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:39194 - "POST /v1/chat/completions HTTP/1.1" 200 OK
