INFO 03-21 14:17:34 __init__.py:207] Automatically detected platform cuda.
INFO 03-21 14:17:34 api_server.py:912] vLLM API server version 0.7.3
INFO 03-21 14:17:34 api_server.py:913] args: Namespace(subparser='serve', model_tag='Qwen/Qwen2.5-VL-72B-Instruct-AWQ', config='', host=None, port=27182, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, chat_template_content_format='openai', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, enable_reasoning=False, reasoning_parser=None, tool_call_parser=None, tool_parser_plugin='', model='Qwen/Qwen2.5-VL-72B-Instruct-AWQ', task='auto', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, allowed_local_media_path=None, download_dir=None, load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', max_model_len=32768, guided_decoding_backend='xgrammar', logits_processor_pattern=None, model_impl='auto', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=2, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=None, enable_prefix_caching=None, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_partial_prefills=1, max_long_partial_prefills=1, long_prefill_token_threshold=0, max_num_seqs=None, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_overrides=None, enforce_eager=False, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt={'image': 9}, mm_processor_kwargs={'images_kwargs.do_resize': True, 'images_kwargs.size.shortest_edge': 3136, 'images_kwargs.size.longest_edge': 250880}, disable_mm_preprocessor_cache=False, enable_lora=False, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, scheduling_policy='fcfs', scheduler_cls='vllm.core.scheduler.Scheduler', override_neuron_config=None, override_pooler_config=None, compilation_config=None, kv_transfer_config=None, worker_cls='auto', generation_config=None, override_generation_config=None, enable_sleep_mode=False, calculate_kv_scales=False, additional_config=None, disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False, dispatch_function=<function ServeSubcommand.cmd at 0x7fc1fa092160>)
INFO 03-21 14:17:34 api_server.py:209] Started engine process with PID 88943
INFO 03-21 14:17:43 __init__.py:207] Automatically detected platform cuda.
INFO 03-21 14:17:48 config.py:549] This model supports multiple tasks: {'generate', 'embed', 'classify', 'reward', 'score'}. Defaulting to 'generate'.
INFO 03-21 14:17:49 awq_marlin.py:114] The model is convertible to awq_marlin during runtime. Using awq_marlin kernel.
INFO 03-21 14:17:49 config.py:1382] Defaulting to use mp for distributed inference
INFO 03-21 14:17:53 config.py:549] This model supports multiple tasks: {'classify', 'generate', 'reward', 'embed', 'score'}. Defaulting to 'generate'.
INFO 03-21 14:17:54 awq_marlin.py:114] The model is convertible to awq_marlin during runtime. Using awq_marlin kernel.
INFO 03-21 14:17:54 config.py:1382] Defaulting to use mp for distributed inference
INFO 03-21 14:17:54 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='Qwen/Qwen2.5-VL-72B-Instruct-AWQ', speculative_config=None, tokenizer='Qwen/Qwen2.5-VL-72B-Instruct-AWQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq_marlin, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-VL-72B-Instruct-AWQ, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs={'images_kwargs.do_resize': True, 'images_kwargs.size.shortest_edge': 3136, 'images_kwargs.size.longest_edge': 250880}, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=True, 
WARNING 03-21 14:17:54 multiproc_worker_utils.py:300] Reducing Torch parallelism from 4 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 03-21 14:17:54 custom_cache_manager.py:19] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
INFO 03-21 14:17:55 cuda.py:229] Using Flash Attention backend.
INFO 03-21 14:18:03 __init__.py:207] Automatically detected platform cuda.
[1;36m(VllmWorkerProcess pid=89038)[0;0m INFO 03-21 14:18:04 multiproc_worker_utils.py:229] Worker ready; awaiting tasks
[1;36m(VllmWorkerProcess pid=89038)[0;0m INFO 03-21 14:18:05 cuda.py:229] Using Flash Attention backend.
INFO 03-21 14:18:05 utils.py:916] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=89038)[0;0m INFO 03-21 14:18:05 utils.py:916] Found nccl from library libnccl.so.2
INFO 03-21 14:18:05 pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorkerProcess pid=89038)[0;0m INFO 03-21 14:18:05 pynccl.py:69] vLLM is using nccl==2.21.5
INFO 03-21 14:18:06 custom_all_reduce_utils.py:244] reading GPU P2P access cache from /nfshomes/sriramb/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
[1;36m(VllmWorkerProcess pid=89038)[0;0m INFO 03-21 14:18:06 custom_all_reduce_utils.py:244] reading GPU P2P access cache from /nfshomes/sriramb/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
INFO 03-21 14:18:06 shm_broadcast.py:258] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_4e76a180'), local_subscribe_port=42033, remote_subscribe_port=None)
INFO 03-21 14:18:06 model_runner.py:1110] Starting to load model Qwen/Qwen2.5-VL-72B-Instruct-AWQ...
[1;36m(VllmWorkerProcess pid=89038)[0;0m INFO 03-21 14:18:06 model_runner.py:1110] Starting to load model Qwen/Qwen2.5-VL-72B-Instruct-AWQ...
[1;36m(VllmWorkerProcess pid=89038)[0;0m INFO 03-21 14:18:07 config.py:3054] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
INFO 03-21 14:18:07 config.py:3054] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
[1;36m(VllmWorkerProcess pid=89038)[0;0m INFO 03-21 14:18:07 weight_utils.py:254] Using model weights format ['*.safetensors']
INFO 03-21 14:18:07 weight_utils.py:254] Using model weights format ['*.safetensors']
Loading safetensors checkpoint shards:   0% Completed | 0/11 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   9% Completed | 1/11 [00:04<00:43,  4.39s/it]
Loading safetensors checkpoint shards:  18% Completed | 2/11 [00:11<00:55,  6.12s/it]
Loading safetensors checkpoint shards:  27% Completed | 3/11 [00:19<00:53,  6.72s/it]
Loading safetensors checkpoint shards:  36% Completed | 4/11 [00:26<00:48,  6.97s/it]
Loading safetensors checkpoint shards:  45% Completed | 5/11 [00:33<00:42,  7.06s/it]
Loading safetensors checkpoint shards:  55% Completed | 6/11 [00:41<00:35,  7.15s/it]
Loading safetensors checkpoint shards:  64% Completed | 7/11 [00:48<00:28,  7.11s/it]
Loading safetensors checkpoint shards:  73% Completed | 8/11 [00:55<00:21,  7.16s/it]
Loading safetensors checkpoint shards:  82% Completed | 9/11 [00:59<00:12,  6.12s/it]
Loading safetensors checkpoint shards:  91% Completed | 10/11 [01:06<00:06,  6.56s/it]
Loading safetensors checkpoint shards: 100% Completed | 11/11 [01:14<00:00,  6.90s/it]
Loading safetensors checkpoint shards: 100% Completed | 11/11 [01:14<00:00,  6.76s/it]

[1;36m(VllmWorkerProcess pid=89038)[0;0m INFO 03-21 14:19:24 model_runner.py:1115] Loading model weights took 20.1697 GB
INFO 03-21 14:19:24 model_runner.py:1115] Loading model weights took 20.1697 GB
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
WARNING 03-21 14:19:25 model_runner.py:1288] Computed max_num_seqs (min(256, 32768 // 163840)) to be less than 1. Setting it to the minimum value of 1.
Keyword argument `images_kwargs.do_resize` is not a valid argument for this processor and will be ignored.
Keyword argument `images_kwargs.size.shortest_edge` is not a valid argument for this processor and will be ignored.
Keyword argument `images_kwargs.size.longest_edge` is not a valid argument for this processor and will be ignored.
[1;36m(VllmWorkerProcess pid=89038)[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
[1;36m(VllmWorkerProcess pid=89038)[0;0m WARNING 03-21 14:19:27 model_runner.py:1288] Computed max_num_seqs (min(256, 32768 // 163840)) to be less than 1. Setting it to the minimum value of 1.
[1;36m(VllmWorkerProcess pid=89038)[0;0m Keyword argument `images_kwargs.do_resize` is not a valid argument for this processor and will be ignored.
[1;36m(VllmWorkerProcess pid=89038)[0;0m Keyword argument `images_kwargs.size.shortest_edge` is not a valid argument for this processor and will be ignored.
[1;36m(VllmWorkerProcess pid=89038)[0;0m Keyword argument `images_kwargs.size.longest_edge` is not a valid argument for this processor and will be ignored.
It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.
Token indices sequence length is longer than the specified maximum sequence length for this model (163840 > 131072). Running this sequence through the model will result in indexing errors
[1;36m(VllmWorkerProcess pid=89038)[0;0m It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.
[1;36m(VllmWorkerProcess pid=89038)[0;0m Token indices sequence length is longer than the specified maximum sequence length for this model (163840 > 131072). Running this sequence through the model will result in indexing errors
WARNING 03-21 14:19:38 profiling.py:192] The context length (32768) of the model is too short to hold the multi-modal embeddings in the worst case (163840 tokens in total, out of which {'image': 147456, 'video': 16384} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
[1;36m(VllmWorkerProcess pid=89038)[0;0m WARNING 03-21 14:19:39 profiling.py:192] The context length (32768) of the model is too short to hold the multi-modal embeddings in the worst case (163840 tokens in total, out of which {'image': 147456, 'video': 16384} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
[1;36m(VllmWorkerProcess pid=89038)[0;0m INFO 03-21 14:20:36 worker.py:267] Memory profiling takes 71.43 seconds
[1;36m(VllmWorkerProcess pid=89038)[0;0m INFO 03-21 14:20:36 worker.py:267] the current vLLM instance can use total_gpu_memory (47.41GiB) x gpu_memory_utilization (0.90) = 42.67GiB
[1;36m(VllmWorkerProcess pid=89038)[0;0m INFO 03-21 14:20:36 worker.py:267] model weights take 20.17GiB; non_torch_memory takes 0.38GiB; PyTorch activation peak memory takes 5.66GiB; the rest of the memory reserved for KV Cache is 16.47GiB.
INFO 03-21 14:20:36 worker.py:267] Memory profiling takes 71.64 seconds
INFO 03-21 14:20:36 worker.py:267] the current vLLM instance can use total_gpu_memory (47.41GiB) x gpu_memory_utilization (0.90) = 42.67GiB
INFO 03-21 14:20:36 worker.py:267] model weights take 20.17GiB; non_torch_memory takes 0.41GiB; PyTorch activation peak memory takes 5.66GiB; the rest of the memory reserved for KV Cache is 16.44GiB.
INFO 03-21 14:20:36 executor_base.py:111] # cuda blocks: 6733, # CPU blocks: 1638
INFO 03-21 14:20:36 executor_base.py:116] Maximum concurrency for 32768 tokens per request: 3.29x
[1;36m(VllmWorkerProcess pid=89038)[0;0m INFO 03-21 14:20:40 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 03-21 14:20:40 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:33,  1.00it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:31,  1.06it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:02<00:29,  1.09it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:03<00:28,  1.10it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:04<00:26,  1.11it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:05<00:25,  1.12it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:06<00:24,  1.12it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:07<00:23,  1.13it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:08<00:22,  1.17it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:08<00:20,  1.19it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:09<00:19,  1.21it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:10<00:18,  1.23it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:11<00:17,  1.24it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:11<00:16,  1.26it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:12<00:15,  1.28it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:13<00:14,  1.28it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:14<00:13,  1.32it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:14<00:12,  1.35it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:15<00:11,  1.37it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:16<00:10,  1.38it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:16<00:09,  1.41it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:17<00:09,  1.43it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:18<00:08,  1.44it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:18<00:07,  1.46it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:19<00:06,  1.51it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:20<00:05,  1.55it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:20<00:05,  1.57it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:21<00:04,  1.59it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:22<00:03,  1.60it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:22<00:03,  1.61it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:23<00:02,  1.61it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:23<00:01,  1.62it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:24<00:01,  1.62it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:25<00:00,  1.62it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:26<00:00,  1.31it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:26<00:00,  1.33it/s]
[1;36m(VllmWorkerProcess pid=89038)[0;0m INFO 03-21 14:21:06 custom_all_reduce.py:226] Registering 5635 cuda graph addresses
INFO 03-21 14:21:06 custom_all_reduce.py:226] Registering 5635 cuda graph addresses
[1;36m(VllmWorkerProcess pid=89038)[0;0m INFO 03-21 14:21:06 model_runner.py:1562] Graph capturing finished in 26 secs, took 0.94 GiB
INFO 03-21 14:21:06 model_runner.py:1562] Graph capturing finished in 26 secs, took 0.94 GiB
INFO 03-21 14:21:06 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 102.31 seconds
INFO 03-21 14:21:07 api_server.py:958] Starting vLLM API server on http://0.0.0.0:27182
INFO 03-21 14:21:07 launcher.py:23] Available routes are:
INFO 03-21 14:21:07 launcher.py:31] Route: /openapi.json, Methods: GET, HEAD
INFO 03-21 14:21:07 launcher.py:31] Route: /docs, Methods: GET, HEAD
INFO 03-21 14:21:07 launcher.py:31] Route: /docs/oauth2-redirect, Methods: GET, HEAD
INFO 03-21 14:21:07 launcher.py:31] Route: /redoc, Methods: GET, HEAD
INFO 03-21 14:21:07 launcher.py:31] Route: /health, Methods: GET
INFO 03-21 14:21:07 launcher.py:31] Route: /ping, Methods: POST, GET
INFO 03-21 14:21:07 launcher.py:31] Route: /tokenize, Methods: POST
INFO 03-21 14:21:07 launcher.py:31] Route: /detokenize, Methods: POST
INFO 03-21 14:21:07 launcher.py:31] Route: /v1/models, Methods: GET
INFO 03-21 14:21:07 launcher.py:31] Route: /version, Methods: GET
INFO 03-21 14:21:07 launcher.py:31] Route: /v1/chat/completions, Methods: POST
INFO 03-21 14:21:07 launcher.py:31] Route: /v1/completions, Methods: POST
INFO 03-21 14:21:07 launcher.py:31] Route: /v1/embeddings, Methods: POST
INFO 03-21 14:21:07 launcher.py:31] Route: /pooling, Methods: POST
INFO 03-21 14:21:07 launcher.py:31] Route: /score, Methods: POST
INFO 03-21 14:21:07 launcher.py:31] Route: /v1/score, Methods: POST
INFO 03-21 14:21:07 launcher.py:31] Route: /v1/audio/transcriptions, Methods: POST
INFO 03-21 14:21:07 launcher.py:31] Route: /rerank, Methods: POST
INFO 03-21 14:21:07 launcher.py:31] Route: /v1/rerank, Methods: POST
INFO 03-21 14:21:07 launcher.py:31] Route: /v2/rerank, Methods: POST
INFO 03-21 14:21:07 launcher.py:31] Route: /invocations, Methods: POST
INFO:     Started server process [88909]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     127.0.0.1:35796 - "GET /health HTTP/1.1" 200 OK
INFO 03-21 14:22:37 chat_utils.py:332] Detected the chat template content format to be 'openai'. You can set `--chat-template-content-format` to override this.
INFO 03-21 14:22:37 logger.py:39] Received request chatcmpl-e840a2276364482d83bcc76e58173b4b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the printer (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) printer\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the keyboard (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) keyboard\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the vase (highlighted by a red box) or the potted plant (highlighted by a blue box)?\n(A) vase\n(B) potted plant\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) barrier\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the painting (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) painting\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the vase (highlighted by a blue box)?\n(A) sofa\n(B) vase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) desk\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:22:38 logger.py:39] Received request chatcmpl-d73bdac028714a6da7ffa4ee00ce47d1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) chair\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) truck\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the picture (highlighted by a blue box)?\n(A) sofa\n(B) picture\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the dresser (highlighted by a red box) or the potted plant (highlighted by a blue box)?\n(A) dresser\n(B) potted plant\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:22:38 logger.py:39] Received request chatcmpl-8dfa195b1018433baa16fa9fda7b8589: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bag (highlighted by a red box) or the remote (highlighted by a blue box)?\n(A) bag\n(B) remote\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the towel (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) towel\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) pillow\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) bin\n(B) box\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) car\n(B) bicycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) pedestrian\n(B) bicycle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:22:38 logger.py:39] Received request chatcmpl-297f3180d894444f8fcda3aaefdcf406: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) lamp\n(B) bin\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the night stand (highlighted by a blue box)?\n(A) chair\n(B) night stand\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the dresser (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) dresser\n(B) box\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:22:42 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:22:42 engine.py:280] Added request chatcmpl-e840a2276364482d83bcc76e58173b4b.
WARNING 03-21 14:22:43 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:22:43 engine.py:280] Added request chatcmpl-d73bdac028714a6da7ffa4ee00ce47d1.
WARNING 03-21 14:22:43 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:22:43 engine.py:280] Added request chatcmpl-8dfa195b1018433baa16fa9fda7b8589.
WARNING 03-21 14:22:43 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:22:43 engine.py:280] Added request chatcmpl-297f3180d894444f8fcda3aaefdcf406.
INFO 03-21 14:23:01 metrics.py:455] Avg prompt throughput: 520.9 tokens/s, Avg generation throughput: 0.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:23:07 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 101.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:59426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:23:09 logger.py:39] Received request chatcmpl-e361187fcb734a27a7f862f7826543fc: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) pillow\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) chair\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) chair\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the curtain (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) curtain\n(B) box\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) barrier\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) bus\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the vase (highlighted by a red box) or the potted plant (highlighted by a blue box)?\n(A) vase\n(B) potted plant\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:23:10 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:23:10 engine.py:280] Added request chatcmpl-e361187fcb734a27a7f862f7826543fc.
INFO 03-21 14:23:14 metrics.py:455] Avg prompt throughput: 457.7 tokens/s, Avg generation throughput: 23.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:23:14 logger.py:39] Received request chatcmpl-725ebccc0a884e1e843d6b7aebc86ca2: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) bicycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the night stand (highlighted by a blue box)?\n(A) lamp\n(B) night stand\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) truck\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:23:14 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:23:14 engine.py:280] Added request chatcmpl-725ebccc0a884e1e843d6b7aebc86ca2.
INFO 03-21 14:23:15 logger.py:39] Received request chatcmpl-fd1baa7c01464cf0b0cf87ac1846ce84: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) pillow\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the tissues (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) tissues\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) chair\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bookcase\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) bus\n(B) barrier\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) books\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:23:15 logger.py:39] Received request chatcmpl-0e02e687706d4805b26af6bbf4cc9ebf: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) barrier\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) shelves\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:23:19 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:23:19 engine.py:280] Added request chatcmpl-fd1baa7c01464cf0b0cf87ac1846ce84.
WARNING 03-21 14:23:19 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:23:19 engine.py:280] Added request chatcmpl-0e02e687706d4805b26af6bbf4cc9ebf.
INFO 03-21 14:23:26 metrics.py:455] Avg prompt throughput: 268.2 tokens/s, Avg generation throughput: 1.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:23:31 metrics.py:455] Avg prompt throughput: 1278.7 tokens/s, Avg generation throughput: 70.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:58768 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59426 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:23:34 logger.py:39] Received request chatcmpl-b161141425bf4c9c9ec6600c24040a2f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the microwave (highlighted by a blue box)?\n(A) bin\n(B) microwave\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) chair\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the person (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) person\n(B) mirror\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:23:34 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:23:34 engine.py:280] Added request chatcmpl-b161141425bf4c9c9ec6600c24040a2f.
INFO 03-21 14:23:37 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:59442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:23:38 logger.py:39] Received request chatcmpl-7f66eab1e0be41789c280b91de8814f2: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) lamp\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) truck\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the microwave (highlighted by a blue box)?\n(A) bin\n(B) microwave\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) chair\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:23:39 logger.py:39] Received request chatcmpl-4ea5eac33b744f4eaf055d3850e106ce: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) table\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) bus\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) bus\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) truck\n(B) barrier\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the rack (highlighted by a blue box)?\n(A) books\n(B) rack\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) refrigerator\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sink (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) sink\n(B) pillow\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:23:39 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:23:39 engine.py:280] Added request chatcmpl-7f66eab1e0be41789c280b91de8814f2.
INFO 03-21 14:23:41 logger.py:39] Received request chatcmpl-381f448c864b433196e196b49955ec0b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the sink (highlighted by a red box) or the bottle (highlighted by a blue box)?\n(A) sink\n(B) bottle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bottle (highlighted by a red box) or the remote (highlighted by a blue box)?\n(A) bottle\n(B) remote\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) pedestrian\n(B) bicycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bus\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) door\n(B) pillow\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:23:43 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:23:43 engine.py:280] Added request chatcmpl-4ea5eac33b744f4eaf055d3850e106ce.
WARNING 03-21 14:23:43 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:23:43 engine.py:280] Added request chatcmpl-381f448c864b433196e196b49955ec0b.
INFO 03-21 14:23:49 metrics.py:455] Avg prompt throughput: 529.5 tokens/s, Avg generation throughput: 0.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:23:54 metrics.py:455] Avg prompt throughput: 1283.7 tokens/s, Avg generation throughput: 70.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:58768 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32858 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59442 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58782 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:23:58 logger.py:39] Received request chatcmpl-a49b65340e414441b7a983951d6cefff: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the picture (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) picture\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) motorcycle\n(B) bicycle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) desk\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:23:59 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:23:59 engine.py:280] Added request chatcmpl-a49b65340e414441b7a983951d6cefff.
INFO 03-21 14:24:03 metrics.py:455] Avg prompt throughput: 397.1 tokens/s, Avg generation throughput: 26.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:24:04 logger.py:39] Received request chatcmpl-5201d359e3f648f3869b0a36b56b299f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) traffic cone\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bottle (highlighted by a blue box)?\n(A) chair\n(B) bottle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:24:04 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:24:04 engine.py:280] Added request chatcmpl-5201d359e3f648f3869b0a36b56b299f.
INFO 03-21 14:24:04 logger.py:39] Received request chatcmpl-addc370cf77d45bb83fccff40dd29a85: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) barrier\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) motorcycle\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) motorcycle\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) pillow\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) bus\n(B) barrier\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:24:05 logger.py:39] Received request chatcmpl-6a9045aaeea64e49859cb05445d5f8d9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) traffic cone\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) chair\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) door\n(B) television\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:24:08 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:24:08 engine.py:280] Added request chatcmpl-addc370cf77d45bb83fccff40dd29a85.
WARNING 03-21 14:24:09 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:24:09 engine.py:280] Added request chatcmpl-6a9045aaeea64e49859cb05445d5f8d9.
INFO 03-21 14:24:15 metrics.py:455] Avg prompt throughput: 249.2 tokens/s, Avg generation throughput: 3.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:24:20 metrics.py:455] Avg prompt throughput: 1282.6 tokens/s, Avg generation throughput: 69.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58768 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:24:25 logger.py:39] Received request chatcmpl-ab2dc466131a47ee91ffe63a2be82527: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) pedestrian\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) motorcycle\n(B) bicycle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) table\n(B) blinds\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) chair\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the rack (highlighted by a blue box)?\n(A) books\n(B) rack\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) books\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:24:25 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:24:25 engine.py:280] Added request chatcmpl-ab2dc466131a47ee91ffe63a2be82527.
INFO 03-21 14:24:29 metrics.py:455] Avg prompt throughput: 374.9 tokens/s, Avg generation throughput: 32.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:24:30 logger.py:39] Received request chatcmpl-9b0eb1a529644a4d8b7302046fd2a5d5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the mouse (highlighted by a blue box)?\n(A) chair\n(B) mouse\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) table\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) traffic cone\n(B) bicycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) sofa\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:24:30 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:24:30 engine.py:280] Added request chatcmpl-9b0eb1a529644a4d8b7302046fd2a5d5.
INFO 03-21 14:24:30 logger.py:39] Received request chatcmpl-204ea9dfba654770b5e4494c3cdcf34b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the shoes (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) shoes\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the towel (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) towel\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bookcase\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) pillow\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the sink (highlighted by a red box) or the bottle (highlighted by a blue box)?\n(A) sink\n(B) bottle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:24:30 logger.py:39] Received request chatcmpl-e5e9d22c4623445e858cb341dcc43b4d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the laptop (highlighted by a red box) or the machine (highlighted by a blue box)?\n(A) laptop\n(B) machine\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) bus\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) refrigerator\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) traffic cone\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:24:34 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:24:34 engine.py:280] Added request chatcmpl-204ea9dfba654770b5e4494c3cdcf34b.
WARNING 03-21 14:24:34 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:24:34 engine.py:280] Added request chatcmpl-e5e9d22c4623445e858cb341dcc43b4d.
INFO 03-21 14:24:41 metrics.py:455] Avg prompt throughput: 277.8 tokens/s, Avg generation throughput: 1.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:24:46 metrics.py:455] Avg prompt throughput: 1282.3 tokens/s, Avg generation throughput: 69.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:24:48 logger.py:39] Received request chatcmpl-fa0afd3ba3e246e1a9d22f19c153a9f5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) books\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bicycle\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the electronics (highlighted by a blue box)?\n(A) monitor\n(B) electronics\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) pillow\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the vase (highlighted by a blue box)?\n(A) sofa\n(B) vase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) door\n(B) television\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) shelves\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:24:48 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:24:48 engine.py:280] Added request chatcmpl-fa0afd3ba3e246e1a9d22f19c153a9f5.
INFO 03-21 14:24:50 logger.py:39] Received request chatcmpl-bf5f7d89c2e2403dad51de33243d4992: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) sofa\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) bicycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the clothes (highlighted by a blue box)?\n(A) desk\n(B) clothes\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:24:51 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 35.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:24:53 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:24:53 engine.py:280] Added request chatcmpl-bf5f7d89c2e2403dad51de33243d4992.
INFO 03-21 14:24:56 metrics.py:455] Avg prompt throughput: 1245.3 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43044 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43054 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:24:59 logger.py:39] Received request chatcmpl-002bd028c39c4de385d4a26d77556dec: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the printer (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) printer\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) motorcycle\n(B) bicycle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) barrier\n(B) motorcycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the picture (highlighted by a red box) or the mouse (highlighted by a blue box)?\n(A) picture\n(B) mouse\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:25:00 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:25:00 engine.py:280] Added request chatcmpl-002bd028c39c4de385d4a26d77556dec.
INFO 03-21 14:25:01 logger.py:39] Received request chatcmpl-8cd42a981b9d495fabc8173e31cb0b87: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the keyboard (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) keyboard\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bottle (highlighted by a red box) or the remote (highlighted by a blue box)?\n(A) bottle\n(B) remote\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) bicycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) bookcase\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) shelves\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the mouse (highlighted by a blue box)?\n(A) television\n(B) mouse\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:25:03 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 35.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:25:04 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:25:04 engine.py:280] Added request chatcmpl-8cd42a981b9d495fabc8173e31cb0b87.
INFO 03-21 14:25:08 metrics.py:455] Avg prompt throughput: 1246.7 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:25:10 logger.py:39] Received request chatcmpl-c914a176813e41c6a789fa6cf312cb34: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the board (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) board\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the plates (highlighted by a red box) or the drawers (highlighted by a blue box)?\n(A) plates\n(B) drawers\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) shelves\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) truck\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:25:10 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:25:10 engine.py:280] Added request chatcmpl-c914a176813e41c6a789fa6cf312cb34.
INFO 03-21 14:25:12 logger.py:39] Received request chatcmpl-c869b32b9fc34c94a0b365688f33c78f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the toys (highlighted by a red box) or the closet (highlighted by a blue box)?\n(A) toys\n(B) closet\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the night stand (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) night stand\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) barrier\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the tissues (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) tissues\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) sofa\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:25:13 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 33.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:25:15 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:25:15 engine.py:280] Added request chatcmpl-c869b32b9fc34c94a0b365688f33c78f.
INFO 03-21 14:25:19 metrics.py:455] Avg prompt throughput: 1218.0 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43044 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:25:24 logger.py:39] Received request chatcmpl-b1b2e679d30e4bfb8b201ada9bf71f13: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) table\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) trailer\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) car\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) bicycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) door\n(B) television\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:25:24 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:25:24 engine.py:280] Added request chatcmpl-b1b2e679d30e4bfb8b201ada9bf71f13.
INFO 03-21 14:25:26 logger.py:39] Received request chatcmpl-dce731b76516456ba0583d1272950cb6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the painting (highlighted by a blue box)?\n(A) chair\n(B) painting\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) car\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bottle (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) bottle\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) door\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) pillow\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:25:27 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 53.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:25:28 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:25:28 engine.py:280] Added request chatcmpl-dce731b76516456ba0583d1272950cb6.
INFO 03-21 14:25:32 metrics.py:455] Avg prompt throughput: 1237.4 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43054 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:25:34 logger.py:39] Received request chatcmpl-14c23ec9f4074373bdc0f1af6afd7df4: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) trailer\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the picture (highlighted by a blue box)?\n(A) table\n(B) picture\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) motorcycle\n(B) bicycle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) car\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bag (highlighted by a red box) or the remote (highlighted by a blue box)?\n(A) bag\n(B) remote\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:25:35 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:25:35 engine.py:280] Added request chatcmpl-14c23ec9f4074373bdc0f1af6afd7df4.
INFO 03-21 14:25:36 logger.py:39] Received request chatcmpl-018407bf3c1e4ad388da51a015904e1f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) pillow\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bottle (highlighted by a red box) or the remote (highlighted by a blue box)?\n(A) bottle\n(B) remote\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the painting (highlighted by a blue box)?\n(A) table\n(B) painting\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the keyboard (highlighted by a blue box)?\n(A) desk\n(B) keyboard\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) pedestrian\n(B) motorcycle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:25:37 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:25:39 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:25:39 engine.py:280] Added request chatcmpl-018407bf3c1e4ad388da51a015904e1f.
INFO 03-21 14:25:43 metrics.py:455] Avg prompt throughput: 1178.5 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43044 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:25:48 logger.py:39] Received request chatcmpl-3ced13b9ba4f4700abd08f38951f02f5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the bag (highlighted by a red box) or the bottle (highlighted by a blue box)?\n(A) bag\n(B) bottle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) chair\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) motorcycle\n(B) bicycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the keyboard (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) keyboard\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) door\n(B) television\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:25:48 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:25:48 engine.py:280] Added request chatcmpl-3ced13b9ba4f4700abd08f38951f02f5.
INFO 03-21 14:25:49 logger.py:39] Received request chatcmpl-3b15f2f5fe6a4fb5b21a40e0690e472e: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) books\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) door\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) bus\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the picture (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) picture\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the tissues (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) tissues\n(B) bin\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the person (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) person\n(B) mirror\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:25:51 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 50.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:25:52 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:25:52 engine.py:280] Added request chatcmpl-3b15f2f5fe6a4fb5b21a40e0690e472e.
INFO 03-21 14:25:56 metrics.py:455] Avg prompt throughput: 1206.7 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43054 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:25:59 logger.py:39] Received request chatcmpl-eef71a78ac4c472f8260b1b2f4c09b20: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) motorcycle\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the towel (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) towel\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) chair\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the counter (highlighted by a blue box)?\n(A) sofa\n(B) counter\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) television\n(B) stationery\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) door\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) sofa\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:25:59 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:25:59 engine.py:280] Added request chatcmpl-eef71a78ac4c472f8260b1b2f4c09b20.
INFO 03-21 14:26:02 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43044 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:26:07 metrics.py:455] Avg prompt throughput: 639.0 tokens/s, Avg generation throughput: 51.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43054 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:26:11 logger.py:39] Received request chatcmpl-2aeea5f4d3fe4a6298a9af6e6f74e59a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) books\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) pedestrian\n(B) bicycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) car\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) chair\n(B) shelves\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:26:11 logger.py:39] Received request chatcmpl-1044ffc352a047d6a5a9154d4d7d879b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) shelves\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) bicycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) door\n(B) refrigerator\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:26:11 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:26:11 engine.py:280] Added request chatcmpl-2aeea5f4d3fe4a6298a9af6e6f74e59a.
INFO 03-21 14:26:12 logger.py:39] Received request chatcmpl-427268fcba8949cba9620ca92cec2588: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the plates (highlighted by a red box) or the drawers (highlighted by a blue box)?\n(A) plates\n(B) drawers\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) table\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the dresser (highlighted by a red box) or the clothes (highlighted by a blue box)?\n(A) dresser\n(B) clothes\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bottle (highlighted by a red box) or the remote (highlighted by a blue box)?\n(A) bottle\n(B) remote\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the towel (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) towel\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the keyboard (highlighted by a blue box)?\n(A) desk\n(B) keyboard\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) shelves\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:26:12 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:26:12 engine.py:280] Added request chatcmpl-1044ffc352a047d6a5a9154d4d7d879b.
INFO 03-21 14:26:12 logger.py:39] Received request chatcmpl-2fea983710c84eb3b3bb3a95e15e4b7b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the bathtub (highlighted by a blue box)?\n(A) lamp\n(B) bathtub\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the picture (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) picture\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the microwave (highlighted by a blue box)?\n(A) bin\n(B) microwave\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the picture (highlighted by a red box) or the potted plant (highlighted by a blue box)?\n(A) picture\n(B) potted plant\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) bicycle\n(B) motorcycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) pillow\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:26:12 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:26:12 engine.py:280] Added request chatcmpl-427268fcba8949cba9620ca92cec2588.
WARNING 03-21 14:26:12 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:26:12 engine.py:280] Added request chatcmpl-2fea983710c84eb3b3bb3a95e15e4b7b.
INFO 03-21 14:26:29 metrics.py:455] Avg prompt throughput: 590.3 tokens/s, Avg generation throughput: 0.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:26:34 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 100.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:26:35 logger.py:39] Received request chatcmpl-eccc3601e63a4028b0a6850959495355: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) books\n(B) blinds\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bin\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) chair\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) bin\n(B) monitor\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bookcase\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the floor mat (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) floor mat\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:26:36 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:26:36 engine.py:280] Added request chatcmpl-eccc3601e63a4028b0a6850959495355.
INFO 03-21 14:26:37 logger.py:39] Received request chatcmpl-dab2867ee85747c6a892b605150ce76d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the machine (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) machine\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) truck\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) chair\n(B) bin\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:26:40 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:26:40 engine.py:280] Added request chatcmpl-dab2867ee85747c6a892b605150ce76d.
INFO 03-21 14:26:43 metrics.py:455] Avg prompt throughput: 354.5 tokens/s, Avg generation throughput: 15.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43054 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:26:47 logger.py:39] Received request chatcmpl-f19abf15de6b47708e2b8956da07ade5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) books\n(B) monitor\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) pillow\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) pedestrian\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:26:47 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:26:47 engine.py:280] Added request chatcmpl-f19abf15de6b47708e2b8956da07ade5.
INFO 03-21 14:26:48 logger.py:39] Received request chatcmpl-6e10f771aa3e41d2b9a0e78e4e54c298: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the floor mat (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) floor mat\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the shoes (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) shoes\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) traffic cone\n(B) bicycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the tray (highlighted by a blue box)?\n(A) refrigerator\n(B) tray\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the counter (highlighted by a blue box)?\n(A) lamp\n(B) counter\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:26:50 metrics.py:455] Avg prompt throughput: 469.6 tokens/s, Avg generation throughput: 28.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:26:51 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:26:51 engine.py:280] Added request chatcmpl-6e10f771aa3e41d2b9a0e78e4e54c298.
INFO 03-21 14:26:55 metrics.py:455] Avg prompt throughput: 1251.9 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:26:58 logger.py:39] Received request chatcmpl-8b951eadb9cd4c03b896ddd65da90b74: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) pillow\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) books\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the mouse (highlighted by a blue box)?\n(A) television\n(B) mouse\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) chair\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) chair\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bottle (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) bottle\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:26:58 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:26:58 engine.py:280] Added request chatcmpl-8b951eadb9cd4c03b896ddd65da90b74.
INFO 03-21 14:26:59 logger.py:39] Received request chatcmpl-e0e1125ba37a4418838195b7640ea869: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the bathtub (highlighted by a blue box)?\n(A) lamp\n(B) bathtub\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) chair\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) desk\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the laptop (highlighted by a blue box)?\n(A) chair\n(B) laptop\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the machine (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) machine\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) truck\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:27:01 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:27:02 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:27:02 engine.py:280] Added request chatcmpl-e0e1125ba37a4418838195b7640ea869.
INFO 03-21 14:27:06 metrics.py:455] Avg prompt throughput: 1253.6 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43054 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:27:11 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 95.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:27:12 logger.py:39] Received request chatcmpl-27f90b1391424a3f89db32f2487261dd: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) chair\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the bottle (highlighted by a blue box)?\n(A) monitor\n(B) bottle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:27:12 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:27:12 engine.py:280] Added request chatcmpl-27f90b1391424a3f89db32f2487261dd.
INFO 03-21 14:27:16 logger.py:39] Received request chatcmpl-0a68d47033fc420aa0fe4fc2b86e9f36: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bin\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) bicycle\n(B) motorcycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) car\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) books\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the stationery (highlighted by a red box) or the printer (highlighted by a blue box)?\n(A) stationery\n(B) printer\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:27:16 logger.py:39] Received request chatcmpl-3de6baedaf8a4abf9d6fa76a7b705d39: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) table\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) traffic cone\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) pedestrian\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) table\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) bookcase\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) sofa\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:27:17 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:27:17 engine.py:280] Added request chatcmpl-0a68d47033fc420aa0fe4fc2b86e9f36.
WARNING 03-21 14:27:17 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:27:17 engine.py:280] Added request chatcmpl-3de6baedaf8a4abf9d6fa76a7b705d39.
INFO 03-21 14:27:23 metrics.py:455] Avg prompt throughput: 267.6 tokens/s, Avg generation throughput: 4.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:27:26 logger.py:39] Received request chatcmpl-f29d2504a8f1467a8f430f64ca88cd13: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) table\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) lamp\n(B) box\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the keyboard (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) keyboard\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) car\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:27:27 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:27:27 engine.py:280] Added request chatcmpl-f29d2504a8f1467a8f430f64ca88cd13.
INFO 03-21 14:27:30 metrics.py:455] Avg prompt throughput: 962.1 tokens/s, Avg generation throughput: 23.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:27:35 metrics.py:455] Avg prompt throughput: 642.1 tokens/s, Avg generation throughput: 63.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.
INFO 03-21 14:27:35 logger.py:39] Received request chatcmpl-3cba992a97f34f39b40ac5cb3de2efc6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bag (highlighted by a red box) or the remote (highlighted by a blue box)?\n(A) bag\n(B) remote\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) motorcycle\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the picture (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) picture\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) monitor\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) bus\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) door\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) shelves\n(B) mirror\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:27:35 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:27:35 engine.py:280] Added request chatcmpl-3cba992a97f34f39b40ac5cb3de2efc6.
INFO 03-21 14:27:39 logger.py:39] Received request chatcmpl-58cd2bc3aab5445eabee961fb024c705: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the blanket (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) blanket\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) books\n(B) mirror\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bus\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) table\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) motorcycle\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) lamp\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the bottle (highlighted by a blue box)?\n(A) monitor\n(B) bottle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:27:39 logger.py:39] Received request chatcmpl-4ee4aedc89b2437bbbaf1b2121672697: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the clothes (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) clothes\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the keyboard (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) keyboard\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) pedestrian\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) bin\n(B) box\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:27:39 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:27:39 engine.py:280] Added request chatcmpl-58cd2bc3aab5445eabee961fb024c705.
WARNING 03-21 14:27:40 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:27:40 engine.py:280] Added request chatcmpl-4ee4aedc89b2437bbbaf1b2121672697.
INFO 03-21 14:27:46 metrics.py:455] Avg prompt throughput: 290.1 tokens/s, Avg generation throughput: 0.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:27:51 metrics.py:455] Avg prompt throughput: 1280.9 tokens/s, Avg generation throughput: 68.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
INFO 03-21 14:27:52 logger.py:39] Received request chatcmpl-24a8bd76ce6f41318f45968d60fcdef1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) bin\n(B) monitor\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) chair\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) shelves\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) trailer\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) bus\n(B) barrier\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) lamp\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:27:53 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:27:53 engine.py:280] Added request chatcmpl-24a8bd76ce6f41318f45968d60fcdef1.
INFO 03-21 14:27:57 metrics.py:455] Avg prompt throughput: 540.6 tokens/s, Avg generation throughput: 23.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:28:00 logger.py:39] Received request chatcmpl-3691dff30eea4441afbd75b349a62752: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the plates (highlighted by a red box) or the drawers (highlighted by a blue box)?\n(A) plates\n(B) drawers\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) desk\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) door\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the towel (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) towel\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the dresser (highlighted by a red box) or the clothes (highlighted by a blue box)?\n(A) dresser\n(B) clothes\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:28:00 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:28:00 engine.py:280] Added request chatcmpl-3691dff30eea4441afbd75b349a62752.
INFO 03-21 14:28:02 logger.py:39] Received request chatcmpl-347073203b75432e957aa666300e8cac: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the tray (highlighted by a red box) or the painting (highlighted by a blue box)?\n(A) tray\n(B) painting\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) barrier\n(B) motorcycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) shelves\n(B) stationery\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:28:03 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:28:04 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:28:04 engine.py:280] Added request chatcmpl-347073203b75432e957aa666300e8cac.
INFO 03-21 14:28:08 metrics.py:455] Avg prompt throughput: 1248.7 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:32844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:28:10 logger.py:39] Received request chatcmpl-5bc86dc0699a4c8d831d2798ecbca5c0: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) chair\n(B) shelves\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the towel (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) towel\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) table\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:28:11 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:28:11 engine.py:280] Added request chatcmpl-5bc86dc0699a4c8d831d2798ecbca5c0.
INFO 03-21 14:28:13 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:28:17 logger.py:39] Received request chatcmpl-45d356796a70495b98b7be6073fcda73: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) pedestrian\n(B) traffic cone\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bin\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the tissues (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) tissues\n(B) bin\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) pillow\n(B) mirror\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) door\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) books\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:28:18 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:28:18 engine.py:280] Added request chatcmpl-45d356796a70495b98b7be6073fcda73.
INFO 03-21 14:28:21 metrics.py:455] Avg prompt throughput: 449.5 tokens/s, Avg generation throughput: 35.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:28:25 logger.py:39] Received request chatcmpl-a8e3ab5bb5614ff8acf5ad8434ebe978: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) sofa\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the sink (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) sink\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) television\n(B) stationery\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bus\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) bookcase\n(B) pillow\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:28:25 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:28:25 engine.py:280] Added request chatcmpl-a8e3ab5bb5614ff8acf5ad8434ebe978.
INFO 03-21 14:28:26 logger.py:39] Received request chatcmpl-6a7349ff3f9d4d7ead760cfa1c17515f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) lamp\n(B) towel\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the curtain (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) curtain\n(B) box\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) books\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the fireplace (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) fireplace\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) shelves\n(B) pillow\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:28:28 metrics.py:455] Avg prompt throughput: 421.8 tokens/s, Avg generation throughput: 32.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:28:29 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:28:29 engine.py:280] Added request chatcmpl-6a7349ff3f9d4d7ead760cfa1c17515f.
INFO 03-21 14:28:33 metrics.py:455] Avg prompt throughput: 1256.3 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:32844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:28:36 logger.py:39] Received request chatcmpl-5394b53401f247d2b5a1e30ff8ef875a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) bicycle\n(B) towel\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bag (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) bag\n(B) stationery\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) door\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:28:36 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:28:36 engine.py:280] Added request chatcmpl-5394b53401f247d2b5a1e30ff8ef875a.
INFO 03-21 14:28:39 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 36.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:28:43 logger.py:39] Received request chatcmpl-cc402e5a2f3144bb926b120c352b2110: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) books\n(B) blinds\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the night stand (highlighted by a blue box)?\n(A) chair\n(B) night stand\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the picture (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) picture\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the picture (highlighted by a blue box)?\n(A) lamp\n(B) picture\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) barrier\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) door\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:28:43 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:28:43 engine.py:280] Added request chatcmpl-cc402e5a2f3144bb926b120c352b2110.
INFO 03-21 14:28:46 metrics.py:455] Avg prompt throughput: 491.2 tokens/s, Avg generation throughput: 30.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:28:49 logger.py:39] Received request chatcmpl-b49a8e0222b041e3aaac2df4c0c413bd: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the plates (highlighted by a red box) or the drawers (highlighted by a blue box)?\n(A) plates\n(B) drawers\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) door\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:28:49 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:28:49 engine.py:280] Added request chatcmpl-b49a8e0222b041e3aaac2df4c0c413bd.
INFO 03-21 14:28:50 logger.py:39] Received request chatcmpl-9a90f0866de5481a8f8f4b584f7fde06: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the tray (highlighted by a red box) or the painting (highlighted by a blue box)?\n(A) tray\n(B) painting\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) refrigerator\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) shelves\n(B) pillow\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the board (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) board\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:28:52 metrics.py:455] Avg prompt throughput: 495.7 tokens/s, Avg generation throughput: 26.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:28:53 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:28:53 engine.py:280] Added request chatcmpl-9a90f0866de5481a8f8f4b584f7fde06.
INFO 03-21 14:28:57 metrics.py:455] Avg prompt throughput: 1256.8 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:32844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:29:01 logger.py:39] Received request chatcmpl-05d773a743bd4d3cb40f28598677cafb: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the picture (highlighted by a blue box)?\n(A) chair\n(B) picture\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) traffic cone\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) chair\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the potted plant (highlighted by a red box) or the night stand (highlighted by a blue box)?\n(A) potted plant\n(B) night stand\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the laptop (highlighted by a blue box)?\n(A) chair\n(B) laptop\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:29:01 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:29:01 engine.py:280] Added request chatcmpl-05d773a743bd4d3cb40f28598677cafb.
INFO 03-21 14:29:03 logger.py:39] Received request chatcmpl-6b3bb74c3f9642c8a4ceab9404b52d34: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the printer (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) printer\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) pillow\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bus\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) table\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) refrigerator\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:29:04 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 48.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:29:06 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:29:06 engine.py:280] Added request chatcmpl-6b3bb74c3f9642c8a4ceab9404b52d34.
INFO 03-21 14:29:09 metrics.py:455] Avg prompt throughput: 1253.9 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:29:14 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 86.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.
INFO 03-21 14:29:15 logger.py:39] Received request chatcmpl-9fea36c07e89469586f470e567a4e29c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the mouse (highlighted by a blue box)?\n(A) chair\n(B) mouse\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) chair\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) table\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) bus\n(B) traffic cone\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) chair\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:29:15 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:29:15 engine.py:280] Added request chatcmpl-9fea36c07e89469586f470e567a4e29c.
INFO 03-21 14:29:16 logger.py:39] Received request chatcmpl-44bc97f5233a4e239b0c6ac98cf32a0d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) chair\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) table\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) chair\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) table\n(B) blinds\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
WARNING 03-21 14:29:18 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:29:18 engine.py:280] Added request chatcmpl-44bc97f5233a4e239b0c6ac98cf32a0d.
INFO 03-21 14:29:20 logger.py:39] Received request chatcmpl-3cdb5778aaf64abca2de91844d557a03: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the machine (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) machine\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bicycle\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) barrier\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) lamp\n(B) towel\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) bus\n(B) traffic cone\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bus\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:29:22 metrics.py:455] Avg prompt throughput: 439.7 tokens/s, Avg generation throughput: 2.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:29:23 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:29:23 engine.py:280] Added request chatcmpl-3cdb5778aaf64abca2de91844d557a03.
INFO 03-21 14:29:27 metrics.py:455] Avg prompt throughput: 1244.9 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:32844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:29:31 logger.py:39] Received request chatcmpl-df680c07025d495484951799b2ae1d04: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) chair\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) chair\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) table\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) trailer\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) motorcycle\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:29:31 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:29:31 engine.py:280] Added request chatcmpl-df680c07025d495484951799b2ae1d04.
INFO 03-21 14:29:34 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 49.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:29:36 logger.py:39] Received request chatcmpl-1485c088ee5844098c2ed1eead6c1712: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) truck\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) chair\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the keyboard (highlighted by a blue box)?\n(A) desk\n(B) keyboard\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:29:36 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:29:36 engine.py:280] Added request chatcmpl-1485c088ee5844098c2ed1eead6c1712.
INFO 03-21 14:29:39 metrics.py:455] Avg prompt throughput: 640.2 tokens/s, Avg generation throughput: 13.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:29:43 logger.py:39] Received request chatcmpl-7c49b35cfa3c41e39d0ffc3b1b8215f4: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) sofa\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bin\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the potted plant (highlighted by a blue box)?\n(A) lamp\n(B) potted plant\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the mouse (highlighted by a blue box)?\n(A) television\n(B) mouse\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:29:43 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:29:43 engine.py:280] Added request chatcmpl-7c49b35cfa3c41e39d0ffc3b1b8215f4.
INFO 03-21 14:29:45 logger.py:39] Received request chatcmpl-d9ed06334bbc4b648bc3307093d7ac70: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) bus\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) table\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) refrigerator\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:29:46 metrics.py:455] Avg prompt throughput: 485.5 tokens/s, Avg generation throughput: 30.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:29:47 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:29:47 engine.py:280] Added request chatcmpl-d9ed06334bbc4b648bc3307093d7ac70.
INFO 03-21 14:29:51 metrics.py:455] Avg prompt throughput: 1241.8 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:29:56 logger.py:39] Received request chatcmpl-bebe0229bef34dada15a53d54d898192: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) traffic cone\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the stationery (highlighted by a red box) or the bag (highlighted by a blue box)?\n(A) stationery\n(B) bag\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) chair\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:29:56 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:29:56 engine.py:280] Added request chatcmpl-bebe0229bef34dada15a53d54d898192.
INFO 03-21 14:29:58 logger.py:39] Received request chatcmpl-1b14fc497f7c4b05ba06df29bd555089: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the mouse (highlighted by a blue box)?\n(A) television\n(B) mouse\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bookcase\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) car\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:29:59 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 53.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:30:00 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:30:00 engine.py:280] Added request chatcmpl-1b14fc497f7c4b05ba06df29bd555089.
INFO 03-21 14:30:04 metrics.py:455] Avg prompt throughput: 1246.2 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:30:08 logger.py:39] Received request chatcmpl-753a6602c6aa49feadd02d40d989dd0c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) table\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the sink (highlighted by a red box) or the fire extinguisher (highlighted by a blue box)?\n(A) sink\n(B) fire extinguisher\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) bus\n(B) barrier\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:30:08 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:30:08 engine.py:280] Added request chatcmpl-753a6602c6aa49feadd02d40d989dd0c.
INFO 03-21 14:30:10 logger.py:39] Received request chatcmpl-550a3440781c485094a4eff437a40b73: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the toys (highlighted by a red box) or the closet (highlighted by a blue box)?\n(A) toys\n(B) closet\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bottle (highlighted by a red box) or the remote (highlighted by a blue box)?\n(A) bottle\n(B) remote\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) door\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:30:11 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 44.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.
INFO 03-21 14:30:11 logger.py:39] Received request chatcmpl-928fb6333bbe4b0eb2826ba3282e984e: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) box\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bus\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:30:13 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:30:13 engine.py:280] Added request chatcmpl-550a3440781c485094a4eff437a40b73.
WARNING 03-21 14:30:13 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:30:13 engine.py:280] Added request chatcmpl-928fb6333bbe4b0eb2826ba3282e984e.
INFO 03-21 14:30:19 metrics.py:455] Avg prompt throughput: 420.3 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:30:24 metrics.py:455] Avg prompt throughput: 1284.3 tokens/s, Avg generation throughput: 61.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
INFO 03-21 14:30:24 logger.py:39] Received request chatcmpl-ac82a94df48d480fa37d51807813e8f9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) sofa\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) truck\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the night stand (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) night stand\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) television\n(B) stationery\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) motorcycle\n(B) bicycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the dresser (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) dresser\n(B) box\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:30:25 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:30:25 engine.py:280] Added request chatcmpl-ac82a94df48d480fa37d51807813e8f9.
INFO 03-21 14:30:29 metrics.py:455] Avg prompt throughput: 643.6 tokens/s, Avg generation throughput: 14.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:32844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:42492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:30:33 logger.py:39] Received request chatcmpl-083cb01dacbf4c96a175be01f443e468: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the remote (highlighted by a blue box)?\n(A) table\n(B) remote\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) lamp\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bicycle\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) chair\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the printer (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) printer\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) box\n(B) desk\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:30:34 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:30:34 engine.py:280] Added request chatcmpl-083cb01dacbf4c96a175be01f443e468.
INFO 03-21 14:30:37 logger.py:39] Received request chatcmpl-899f0702bd6f401280899e8dea63ca0b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) bicycle\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) chair\n(B) shelves\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) door\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the drawers (highlighted by a blue box)?\n(A) pillow\n(B) drawers\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the counter (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) counter\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) monitor\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:30:38 logger.py:39] Received request chatcmpl-86d611ea176c4ae6b5896beca413d42f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bicycle\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) traffic cone\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the remote (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) remote\n(B) bin\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the air conditioner (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) air conditioner\n(B) desk\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:30:38 logger.py:39] Received request chatcmpl-8fccf2d4f8bb4f6bbeaeced06eac33bf: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the rack (highlighted by a blue box)?\n(A) books\n(B) rack\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the board (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) board\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) pedestrian\n(B) traffic cone\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:30:38 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:30:38 engine.py:280] Added request chatcmpl-899f0702bd6f401280899e8dea63ca0b.
WARNING 03-21 14:30:38 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:30:38 engine.py:280] Added request chatcmpl-86d611ea176c4ae6b5896beca413d42f.
WARNING 03-21 14:30:38 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:30:38 engine.py:280] Added request chatcmpl-8fccf2d4f8bb4f6bbeaeced06eac33bf.
INFO 03-21 14:30:48 metrics.py:455] Avg prompt throughput: 169.6 tokens/s, Avg generation throughput: 13.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:30:53 metrics.py:455] Avg prompt throughput: 1919.1 tokens/s, Avg generation throughput: 61.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:47680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:30:56 logger.py:39] Received request chatcmpl-f3bc455f3e7948e2891c859095948658: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the painting (highlighted by a blue box)?\n(A) chair\n(B) painting\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) chair\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the phone (highlighted by a blue box)?\n(A) table\n(B) phone\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) chair\n(B) bin\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the laptop (highlighted by a red box) or the machine (highlighted by a blue box)?\n(A) laptop\n(B) machine\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) car\n(B) bicycle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) table\n(B) shelves\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:30:57 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:30:57 engine.py:280] Added request chatcmpl-f3bc455f3e7948e2891c859095948658.
INFO 03-21 14:30:58 logger.py:39] Received request chatcmpl-32a1d79689cc4abc9902daacd919ecbd: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) books\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) car\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) table\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) pillow\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:31:00 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.
INFO 03-21 14:31:00 logger.py:39] Received request chatcmpl-7f9850f1b5354389a02d081a59c4cfde: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) traffic cone\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) lamp\n(B) door\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:31:01 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:31:01 engine.py:280] Added request chatcmpl-32a1d79689cc4abc9902daacd919ecbd.
WARNING 03-21 14:31:01 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:31:01 engine.py:280] Added request chatcmpl-7f9850f1b5354389a02d081a59c4cfde.
INFO 03-21 14:31:07 metrics.py:455] Avg prompt throughput: 419.8 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:31:11 logger.py:39] Received request chatcmpl-965f317ec35c44e6bef961b81472fb3e: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bowl (highlighted by a blue box)?\n(A) chair\n(B) bowl\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bin\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) table\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the clothes (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) clothes\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:31:12 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:31:12 engine.py:280] Added request chatcmpl-965f317ec35c44e6bef961b81472fb3e.
INFO 03-21 14:31:15 metrics.py:455] Avg prompt throughput: 871.1 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:32844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:31:20 metrics.py:455] Avg prompt throughput: 638.7 tokens/s, Avg generation throughput: 76.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:47680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:31:21 logger.py:39] Received request chatcmpl-ff1622740bca43018ce9691255dcb062: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the dresser (highlighted by a red box) or the potted plant (highlighted by a blue box)?\n(A) dresser\n(B) potted plant\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) truck\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) shelves\n(B) pillow\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the fireplace (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) fireplace\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) sofa\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) chair\n(B) bin\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) lamp\n(B) shelves\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:31:21 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:31:21 engine.py:280] Added request chatcmpl-ff1622740bca43018ce9691255dcb062.
INFO 03-21 14:31:24 logger.py:39] Received request chatcmpl-495d4c727e6542d0ab5df37238e10c8c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) bicycle\n(B) motorcycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) shelves\n(B) stationery\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) bin\n(B) stationery\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:31:24 logger.py:39] Received request chatcmpl-0c4951bebd964f818c69fdc3e6a6fedf: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the air conditioner (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) air conditioner\n(B) desk\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) desk\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) chair\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) books\n(B) mirror\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:31:25 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:31:25 engine.py:280] Added request chatcmpl-495d4c727e6542d0ab5df37238e10c8c.
WARNING 03-21 14:31:25 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:31:25 engine.py:280] Added request chatcmpl-0c4951bebd964f818c69fdc3e6a6fedf.
INFO 03-21 14:31:31 metrics.py:455] Avg prompt throughput: 270.3 tokens/s, Avg generation throughput: 4.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:31:36 logger.py:39] Received request chatcmpl-2ba7ddf049be4d1b8d49fe63239f8628: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) television\n(B) stationery\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the toys (highlighted by a red box) or the closet (highlighted by a blue box)?\n(A) toys\n(B) closet\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bottle (highlighted by a red box) or the remote (highlighted by a blue box)?\n(A) bottle\n(B) remote\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the drawers (highlighted by a blue box)?\n(A) pillow\n(B) drawers\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) chair\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:31:36 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:31:36 engine.py:280] Added request chatcmpl-2ba7ddf049be4d1b8d49fe63239f8628.
INFO 03-21 14:31:39 metrics.py:455] Avg prompt throughput: 820.2 tokens/s, Avg generation throughput: 35.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:32844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:47680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:31:44 metrics.py:455] Avg prompt throughput: 641.6 tokens/s, Avg generation throughput: 72.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.
INFO 03-21 14:31:46 logger.py:39] Received request chatcmpl-70055662351941579f5894ec44c9e5e6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the towel (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) towel\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) bus\n(B) traffic cone\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) truck\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the sink (highlighted by a red box) or the fire extinguisher (highlighted by a blue box)?\n(A) sink\n(B) fire extinguisher\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) pillow\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:31:46 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:31:46 engine.py:280] Added request chatcmpl-70055662351941579f5894ec44c9e5e6.
INFO 03-21 14:31:49 logger.py:39] Received request chatcmpl-b356aa003749471bbc6d9de841a82ad2: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) books\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) lamp\n(B) bin\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) trailer\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bicycle\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:31:49 logger.py:39] Received request chatcmpl-33d937993af34ca587832b151cc31b0b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) barrier\n(B) motorcycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the fireplace (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) fireplace\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the curtain (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) curtain\n(B) box\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the counter (highlighted by a blue box)?\n(A) lamp\n(B) counter\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) chair\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:31:50 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:31:50 engine.py:280] Added request chatcmpl-b356aa003749471bbc6d9de841a82ad2.
WARNING 03-21 14:31:50 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:31:50 engine.py:280] Added request chatcmpl-33d937993af34ca587832b151cc31b0b.
INFO 03-21 14:31:56 metrics.py:455] Avg prompt throughput: 265.8 tokens/s, Avg generation throughput: 2.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:32:01 metrics.py:455] Avg prompt throughput: 1283.9 tokens/s, Avg generation throughput: 64.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
INFO 03-21 14:32:03 logger.py:39] Received request chatcmpl-ceaed54549eb43f2b8778095cf7f449e: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bottle (highlighted by a blue box)?\n(A) chair\n(B) bottle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bin\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bicycle\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) bus\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) shelves\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bookcase\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) chair\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) barrier\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:32:03 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:32:03 engine.py:280] Added request chatcmpl-ceaed54549eb43f2b8778095cf7f449e.
INFO 03-21 14:32:07 metrics.py:455] Avg prompt throughput: 599.7 tokens/s, Avg generation throughput: 17.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:47680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:32:09 logger.py:39] Received request chatcmpl-639c7cc328b94120afebd0e1bdc1d61b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) chair\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) truck\n(B) barrier\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) lamp\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) pillow\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:32:10 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:32:10 engine.py:280] Added request chatcmpl-639c7cc328b94120afebd0e1bdc1d61b.
INFO 03-21 14:32:13 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 26.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.
INFO 03-21 14:32:13 logger.py:39] Received request chatcmpl-f55bceae4a3c44d388594de65db73878: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) motorcycle\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bottle (highlighted by a red box) or the board (highlighted by a blue box)?\n(A) bottle\n(B) board\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) table\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) pedestrian\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:32:13 logger.py:39] Received request chatcmpl-b3e76cf2f68946e7bdd931ef87357f73: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bicycle\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the dresser (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) dresser\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the night stand (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) night stand\n(B) pillow\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) lamp\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) table\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the clock (highlighted by a red box) or the bottle (highlighted by a blue box)?\n(A) clock\n(B) bottle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the keyboard (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) keyboard\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) bookcase\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) door\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:32:14 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:32:14 engine.py:280] Added request chatcmpl-f55bceae4a3c44d388594de65db73878.
WARNING 03-21 14:32:14 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:32:14 engine.py:280] Added request chatcmpl-b3e76cf2f68946e7bdd931ef87357f73.
INFO 03-21 14:32:20 metrics.py:455] Avg prompt throughput: 421.8 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:32:25 metrics.py:455] Avg prompt throughput: 1280.1 tokens/s, Avg generation throughput: 69.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:32:28 logger.py:39] Received request chatcmpl-b5c404c711fa49f0bd7091f64d85b59a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) chair\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bicycle\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) bicycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) barrier\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:32:28 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:32:28 engine.py:280] Added request chatcmpl-b5c404c711fa49f0bd7091f64d85b59a.
INFO 03-21 14:32:31 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:47680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:32:31 logger.py:39] Received request chatcmpl-5d1d90b3690641deac5538ef4c900335: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) books\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) motorcycle\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the clothes (highlighted by a blue box)?\n(A) monitor\n(B) clothes\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) bicycle\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) table\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the drawers (highlighted by a blue box)?\n(A) pillow\n(B) drawers\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) lamp\n(B) box\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:32:31 logger.py:39] Received request chatcmpl-c83aff6699254a388bae5c70c18668fa: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the dresser (highlighted by a red box) or the potted plant (highlighted by a blue box)?\n(A) dresser\n(B) potted plant\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) sofa\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) lamp\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bag (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bag\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the night stand (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) night stand\n(B) pillow\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:32:32 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:32:32 engine.py:280] Added request chatcmpl-5d1d90b3690641deac5538ef4c900335.
WARNING 03-21 14:32:33 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:32:33 engine.py:280] Added request chatcmpl-c83aff6699254a388bae5c70c18668fa.
INFO 03-21 14:32:33 logger.py:39] Received request chatcmpl-577364394f484ba59db276bd7615b481: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the counter (highlighted by a blue box)?\n(A) lamp\n(B) counter\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the board (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) board\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) monitor\n(B) bin\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the night stand (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) night stand\n(B) pillow\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) lamp\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:32:39 metrics.py:455] Avg prompt throughput: 421.5 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:32:41 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:32:41 engine.py:280] Added request chatcmpl-577364394f484ba59db276bd7615b481.
INFO 03-21 14:32:44 metrics.py:455] Avg prompt throughput: 1689.8 tokens/s, Avg generation throughput: 0.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:32844 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:56478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:32:49 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 94.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:47680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:32:51 logger.py:39] Received request chatcmpl-bc73103a8d174d92a688850bb7b1bcf2: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the mouse (highlighted by a blue box)?\n(A) television\n(B) mouse\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bottle (highlighted by a red box) or the board (highlighted by a blue box)?\n(A) bottle\n(B) board\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) motorcycle\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:32:51 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:32:51 engine.py:280] Added request chatcmpl-bc73103a8d174d92a688850bb7b1bcf2.
INFO 03-21 14:32:55 metrics.py:455] Avg prompt throughput: 608.9 tokens/s, Avg generation throughput: 3.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:32:56 logger.py:39] Received request chatcmpl-1b29fa08ed1a4cfc906d6dd9cbd8f67b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) trailer\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the air conditioner (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) air conditioner\n(B) desk\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the tray (highlighted by a blue box)?\n(A) refrigerator\n(B) tray\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) pedestrian\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) car\n(B) motorcycle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) motorcycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:32:56 logger.py:39] Received request chatcmpl-bc842cc44e98454cac6b52c312dd0a93: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) box\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) sofa\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the potted plant (highlighted by a blue box)?\n(A) lamp\n(B) potted plant\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) bus\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) monitor\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the dresser (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) dresser\n(B) box\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:32:56 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:32:56 engine.py:280] Added request chatcmpl-1b29fa08ed1a4cfc906d6dd9cbd8f67b.
INFO 03-21 14:32:56 logger.py:39] Received request chatcmpl-2f3edb919396483b952c9d9265263124: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) chair\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the printer (highlighted by a blue box)?\n(A) bin\n(B) printer\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) box\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the keyboard (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) keyboard\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the clothes (highlighted by a blue box)?\n(A) monitor\n(B) clothes\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) desk\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:32:56 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:32:56 engine.py:280] Added request chatcmpl-bc842cc44e98454cac6b52c312dd0a93.
WARNING 03-21 14:32:56 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:32:56 engine.py:280] Added request chatcmpl-2f3edb919396483b952c9d9265263124.
INFO 03-21 14:33:06 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:33:11 metrics.py:455] Avg prompt throughput: 1917.3 tokens/s, Avg generation throughput: 61.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:33:15 logger.py:39] Received request chatcmpl-2b03170ae0ef435ea6c0414042a3f998: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the clock (highlighted by a red box) or the bottle (highlighted by a blue box)?\n(A) clock\n(B) bottle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) traffic cone\n(B) bicycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the toys (highlighted by a red box) or the closet (highlighted by a blue box)?\n(A) toys\n(B) closet\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) trailer\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) table\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:33:15 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:33:15 engine.py:280] Added request chatcmpl-2b03170ae0ef435ea6c0414042a3f998.
INFO 03-21 14:33:17 logger.py:39] Received request chatcmpl-b6546d2371a348ba9ab9f83e44cefca1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) books\n(B) monitor\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) trailer\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) books\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the fireplace (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) fireplace\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:54898 - "POST /v1/chat/completions HTTP/1.1" 200 OK
WARNING 03-21 14:33:19 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:33:19 engine.py:280] Added request chatcmpl-b6546d2371a348ba9ab9f83e44cefca1.
INFO 03-21 14:33:19 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 48.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 1 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.
INFO 03-21 14:33:21 logger.py:39] Received request chatcmpl-c0da1ba6464e4dd887a48f151e99b1a5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) car\n(B) bicycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) motorcycle\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the picture (highlighted by a blue box)?\n(A) table\n(B) picture\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the clothes (highlighted by a blue box)?\n(A) monitor\n(B) clothes\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:33:23 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:33:23 engine.py:280] Added request chatcmpl-c0da1ba6464e4dd887a48f151e99b1a5.
INFO 03-21 14:33:26 metrics.py:455] Avg prompt throughput: 823.5 tokens/s, Avg generation throughput: 0.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:33:30 logger.py:39] Received request chatcmpl-e852e1c461064188ad868a115657583e: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the towel (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) towel\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) bus\n(B) barrier\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) bus\n(B) barrier\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) table\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) door\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:33:31 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:33:31 engine.py:280] Added request chatcmpl-e852e1c461064188ad868a115657583e.
INFO 03-21 14:33:33 metrics.py:455] Avg prompt throughput: 451.9 tokens/s, Avg generation throughput: 34.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:33:39 metrics.py:455] Avg prompt throughput: 638.2 tokens/s, Avg generation throughput: 77.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54898 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:33:40 logger.py:39] Received request chatcmpl-a5983e4efbab49cb83195477ab672ff1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the machine (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) machine\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the stationery (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) stationery\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) box\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) traffic cone\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the board (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) board\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:33:40 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:33:40 engine.py:280] Added request chatcmpl-a5983e4efbab49cb83195477ab672ff1.
INFO 03-21 14:33:43 logger.py:39] Received request chatcmpl-f9fe20ee49e94d8c8458613cb447b32f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) door\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) pedestrian\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) books\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the tissues (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) tissues\n(B) bin\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) bus\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:33:43 logger.py:39] Received request chatcmpl-2fb4b1833b544d649b25856fb4e926d6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) chair\n(B) bin\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) table\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the stationery (highlighted by a red box) or the bag (highlighted by a blue box)?\n(A) stationery\n(B) bag\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) bus\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sink (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) sink\n(B) pillow\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:33:44 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:33:44 engine.py:280] Added request chatcmpl-f9fe20ee49e94d8c8458613cb447b32f.
WARNING 03-21 14:33:44 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:33:44 engine.py:280] Added request chatcmpl-2fb4b1833b544d649b25856fb4e926d6.
INFO 03-21 14:33:50 metrics.py:455] Avg prompt throughput: 271.5 tokens/s, Avg generation throughput: 3.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:33:55 logger.py:39] Received request chatcmpl-4b135a3e2b314b3ca9abe655d368eae1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) bin\n(B) monitor\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bag (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bag\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) lamp\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) motorcycle\n(B) bicycle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:33:55 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:33:55 engine.py:280] Added request chatcmpl-4b135a3e2b314b3ca9abe655d368eae1.
INFO 03-21 14:33:58 metrics.py:455] Avg prompt throughput: 811.0 tokens/s, Avg generation throughput: 34.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:34:03 metrics.py:455] Avg prompt throughput: 640.9 tokens/s, Avg generation throughput: 72.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54898 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:34:04 logger.py:39] Received request chatcmpl-5a58ba1ae0be4304baecccd4ede55621: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the tissues (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) tissues\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bicycle\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) bicycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) lamp\n(B) towel\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) books\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) table\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) door\n(B) pillow\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:34:04 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:34:04 engine.py:280] Added request chatcmpl-5a58ba1ae0be4304baecccd4ede55621.
INFO 03-21 14:34:05 logger.py:39] Received request chatcmpl-fea4a4c32d024fa78c9264eb7853d3f1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the picture (highlighted by a blue box)?\n(A) chair\n(B) picture\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) box\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) chair\n(B) bin\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) car\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) bicycle\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) motorcycle\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the towel (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) towel\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) traffic cone\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:34:06 logger.py:39] Received request chatcmpl-c973c87326294cd6974306ac079617fe: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) chair\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the towel (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) towel\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the board (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) board\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) monitor\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the machine (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) machine\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the phone (highlighted by a blue box)?\n(A) table\n(B) phone\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the dresser (highlighted by a red box) or the clothes (highlighted by a blue box)?\n(A) dresser\n(B) clothes\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:34:08 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:34:08 engine.py:280] Added request chatcmpl-fea4a4c32d024fa78c9264eb7853d3f1.
WARNING 03-21 14:34:08 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:34:08 engine.py:280] Added request chatcmpl-c973c87326294cd6974306ac079617fe.
INFO 03-21 14:34:14 metrics.py:455] Avg prompt throughput: 292.6 tokens/s, Avg generation throughput: 0.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:34:19 metrics.py:455] Avg prompt throughput: 1279.1 tokens/s, Avg generation throughput: 69.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
INFO 03-21 14:34:21 logger.py:39] Received request chatcmpl-884d98b66783484d97b825c413b66ba0: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) bin\n(B) box\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) bicycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) bus\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) sofa\n(B) door\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:34:21 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:34:21 engine.py:280] Added request chatcmpl-884d98b66783484d97b825c413b66ba0.
INFO 03-21 14:34:24 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54898 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:34:27 logger.py:39] Received request chatcmpl-87cd3d8994ee4d079a02677a634df71b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the stationery (highlighted by a red box) or the bag (highlighted by a blue box)?\n(A) stationery\n(B) bag\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the electronics (highlighted by a blue box)?\n(A) monitor\n(B) electronics\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) bin\n(B) box\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the potted plant (highlighted by a blue box)?\n(A) lamp\n(B) potted plant\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the mouse (highlighted by a blue box)?\n(A) television\n(B) mouse\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:34:28 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:34:28 engine.py:280] Added request chatcmpl-87cd3d8994ee4d079a02677a634df71b.
INFO 03-21 14:34:31 metrics.py:455] Avg prompt throughput: 518.3 tokens/s, Avg generation throughput: 28.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:34:33 logger.py:39] Received request chatcmpl-f21457b64a014fbcbd130f8ef2a01fb4: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the stationery (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) stationery\n(B) bin\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bin\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bicycle\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the tray (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) tray\n(B) box\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the printer (highlighted by a blue box)?\n(A) bin\n(B) printer\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) books\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:34:34 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:34:34 engine.py:280] Added request chatcmpl-f21457b64a014fbcbd130f8ef2a01fb4.
INFO 03-21 14:34:35 logger.py:39] Received request chatcmpl-132aaea0fa764d7b99909f78b6751dd0: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) trailer\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the stationery (highlighted by a red box) or the bag (highlighted by a blue box)?\n(A) stationery\n(B) bag\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the laptop (highlighted by a blue box)?\n(A) chair\n(B) laptop\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) bicycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) car\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) bus\n(B) barrier\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the phone (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) phone\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:34:37 metrics.py:455] Avg prompt throughput: 533.3 tokens/s, Avg generation throughput: 21.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:34:38 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:34:38 engine.py:280] Added request chatcmpl-132aaea0fa764d7b99909f78b6751dd0.
INFO 03-21 14:34:42 metrics.py:455] Avg prompt throughput: 1248.1 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:34:45 logger.py:39] Received request chatcmpl-1e2e4c39b47a4bc2ba58134abb5d3855: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) books\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) sofa\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) pillow\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) television\n(B) stationery\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the printer (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) printer\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the stationery (highlighted by a red box) or the printer (highlighted by a blue box)?\n(A) stationery\n(B) printer\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:34:46 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:34:46 engine.py:280] Added request chatcmpl-1e2e4c39b47a4bc2ba58134abb5d3855.
INFO 03-21 14:34:48 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 46.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54898 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:34:54 metrics.py:455] Avg prompt throughput: 643.0 tokens/s, Avg generation throughput: 55.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.
INFO 03-21 14:34:54 logger.py:39] Received request chatcmpl-761173cc626744ebafdca5b391f45e72: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) pillow\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the towel (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) towel\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the vase (highlighted by a red box) or the potted plant (highlighted by a blue box)?\n(A) vase\n(B) potted plant\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) barrier\n(B) motorcycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) pedestrian\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:34:54 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:34:54 engine.py:280] Added request chatcmpl-761173cc626744ebafdca5b391f45e72.
INFO 03-21 14:34:57 logger.py:39] Received request chatcmpl-5f1cc664a40f4d1e864b3c2cfb36b9df: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) table\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bowl (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) bowl\n(B) bin\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) motorcycle\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) pedestrian\n(B) barrier\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) lamp\n(B) bin\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) bus\n(B) barrier\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) door\n(B) refrigerator\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:34:58 logger.py:39] Received request chatcmpl-ea3fd40e81c6481fad658aa31272005d: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the picture (highlighted by a red box) or the keyboard (highlighted by a blue box)?\n(A) picture\n(B) keyboard\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) chair\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the person (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) person\n(B) mirror\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) shelves\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:34:58 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:34:58 engine.py:280] Added request chatcmpl-5f1cc664a40f4d1e864b3c2cfb36b9df.
WARNING 03-21 14:34:58 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:34:58 engine.py:280] Added request chatcmpl-ea3fd40e81c6481fad658aa31272005d.
INFO 03-21 14:35:05 metrics.py:455] Avg prompt throughput: 289.2 tokens/s, Avg generation throughput: 0.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO 03-21 14:35:10 metrics.py:455] Avg prompt throughput: 1279.1 tokens/s, Avg generation throughput: 69.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:35:12 logger.py:39] Received request chatcmpl-c91450b6fbe4425f990d13f513f5f873: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the tray (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) tray\n(B) box\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bowl (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) bowl\n(B) bin\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) books\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the machine (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) machine\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:35:12 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:35:12 engine.py:280] Added request chatcmpl-c91450b6fbe4425f990d13f513f5f873.
INFO 03-21 14:35:15 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 32.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37054 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54898 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:35:19 logger.py:39] Received request chatcmpl-c0af0424b79940faad167c158b9622c1: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) chair\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) barrier\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bin\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the night stand (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) night stand\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) car\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the printer (highlighted by a blue box)?\n(A) bin\n(B) printer\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:35:19 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:35:19 engine.py:280] Added request chatcmpl-c0af0424b79940faad167c158b9622c1.
INFO 03-21 14:35:22 metrics.py:455] Avg prompt throughput: 456.2 tokens/s, Avg generation throughput: 29.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.
INFO 03-21 14:35:23 logger.py:39] Received request chatcmpl-6e61f58abeb341629ba5d8b5baf27093: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bottle (highlighted by a blue box)?\n(A) chair\n(B) bottle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) bin\n(B) box\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) motorcycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the keyboard (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) keyboard\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:35:23 logger.py:39] Received request chatcmpl-6d9428bdeeca45cab31affd090cae1c4: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) barrier\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) bicycle\n(B) motorcycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) pedestrian\n(B) bicycle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) car\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the stationery (highlighted by a red box) or the printer (highlighted by a blue box)?\n(A) stationery\n(B) printer\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:35:23 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:35:23 engine.py:280] Added request chatcmpl-6e61f58abeb341629ba5d8b5baf27093.
WARNING 03-21 14:35:24 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:35:24 engine.py:280] Added request chatcmpl-6d9428bdeeca45cab31affd090cae1c4.
INFO 03-21 14:35:30 metrics.py:455] Avg prompt throughput: 419.9 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:35:35 metrics.py:455] Avg prompt throughput: 1279.7 tokens/s, Avg generation throughput: 69.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:35:37 logger.py:39] Received request chatcmpl-3ef8111dc81d40bb9bf02f8524032a05: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) pedestrian\n(B) traffic cone\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) table\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bicycle\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) chair\n(B) desk\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) books\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) traffic cone\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the clothes (highlighted by a blue box)?\n(A) lamp\n(B) clothes\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:35:37 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:35:37 engine.py:280] Added request chatcmpl-3ef8111dc81d40bb9bf02f8524032a05.
INFO 03-21 14:35:40 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 32.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37054 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54898 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:35:43 logger.py:39] Received request chatcmpl-d723d3c2a3c6422cba3a596c46012d90: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) chair\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the person (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) person\n(B) mirror\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) table\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) door\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) table\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:35:43 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:35:43 engine.py:280] Added request chatcmpl-d723d3c2a3c6422cba3a596c46012d90.
INFO 03-21 14:35:46 metrics.py:455] Avg prompt throughput: 545.3 tokens/s, Avg generation throughput: 17.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:35:47 logger.py:39] Received request chatcmpl-e5ef513ce73c4bbcb5c1101784667423: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) barrier\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) motorcycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:35:47 logger.py:39] Received request chatcmpl-ad146c6af25240fc911fd213547ca594: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the stationery (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) stationery\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) chair\n(B) desk\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bag (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bag\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) motorcycle\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) pillow\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:35:47 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:35:47 engine.py:280] Added request chatcmpl-e5ef513ce73c4bbcb5c1101784667423.
WARNING 03-21 14:35:48 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:35:48 engine.py:280] Added request chatcmpl-ad146c6af25240fc911fd213547ca594.
INFO 03-21 14:35:54 metrics.py:455] Avg prompt throughput: 414.8 tokens/s, Avg generation throughput: 0.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:35:59 metrics.py:455] Avg prompt throughput: 1279.2 tokens/s, Avg generation throughput: 69.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:36:03 logger.py:39] Received request chatcmpl-098c1fd3b12a4bc4b83ce68538979287: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) box\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the dresser (highlighted by a red box) or the potted plant (highlighted by a blue box)?\n(A) dresser\n(B) potted plant\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) bus\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) bus\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) chair\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:36:03 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:36:03 engine.py:280] Added request chatcmpl-098c1fd3b12a4bc4b83ce68538979287.
INFO 03-21 14:36:05 logger.py:39] Received request chatcmpl-ce8427d98bcf43e0b2ea14c7b4e95ef7: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bottle (highlighted by a blue box)?\n(A) chair\n(B) bottle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) barrier\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the picture (highlighted by a blue box)?\n(A) table\n(B) picture\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) car\n(B) motorcycle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) motorcycle\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:36:06 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:36:07 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:36:07 engine.py:280] Added request chatcmpl-ce8427d98bcf43e0b2ea14c7b4e95ef7.
INFO 03-21 14:36:11 metrics.py:455] Avg prompt throughput: 1248.3 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48228 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54898 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:36:13 logger.py:39] Received request chatcmpl-9e47d161873646a9a2c11baa009b9795: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) monitor\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the counter (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) counter\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) box\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the phone (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) phone\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) sofa\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:36:13 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:36:13 engine.py:280] Added request chatcmpl-9e47d161873646a9a2c11baa009b9795.
INFO 03-21 14:36:14 logger.py:39] Received request chatcmpl-5c156f8333554301a92d46e6e1f45d97: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) truck\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bottle (highlighted by a red box) or the remote (highlighted by a blue box)?\n(A) bottle\n(B) remote\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) chair\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the electronics (highlighted by a blue box)?\n(A) monitor\n(B) electronics\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the picture (highlighted by a blue box)?\n(A) lamp\n(B) picture\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) table\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) chair\n(B) shelves\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:36:16 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 23.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:36:17 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:36:17 engine.py:280] Added request chatcmpl-5c156f8333554301a92d46e6e1f45d97.
INFO 03-21 14:36:21 metrics.py:455] Avg prompt throughput: 1258.8 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:36:26 logger.py:39] Received request chatcmpl-5cd7c3c36ea8487085eebe16e4286536: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the plates (highlighted by a red box) or the drawers (highlighted by a blue box)?\n(A) plates\n(B) drawers\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the board (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) board\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) chair\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) pillow\n(B) mirror\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:36:27 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:36:27 engine.py:280] Added request chatcmpl-5cd7c3c36ea8487085eebe16e4286536.
INFO 03-21 14:36:28 logger.py:39] Received request chatcmpl-074742e106d64b04aaff0bea65317297: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the vase (highlighted by a blue box)?\n(A) table\n(B) vase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the night stand (highlighted by a blue box)?\n(A) shelves\n(B) night stand\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) books\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bottle (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) bottle\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) bookcase\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) shelves\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:36:30 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 50.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:36:31 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:36:31 engine.py:280] Added request chatcmpl-074742e106d64b04aaff0bea65317297.
INFO 03-21 14:36:35 metrics.py:455] Avg prompt throughput: 1253.6 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54898 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48228 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:36:38 logger.py:39] Received request chatcmpl-541774df0d194c918db90c84ee96b7e0: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) table\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) bus\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) books\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) table\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) lamp\n(B) blinds\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:36:38 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:36:38 engine.py:280] Added request chatcmpl-541774df0d194c918db90c84ee96b7e0.
INFO 03-21 14:36:39 logger.py:39] Received request chatcmpl-c671a77660bb4241a4d7756fda1e4ed5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the night stand (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) night stand\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bowl (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) bowl\n(B) bin\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the clothes (highlighted by a blue box)?\n(A) desk\n(B) clothes\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) books\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) box\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the clothes (highlighted by a blue box)?\n(A) monitor\n(B) clothes\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the floor mat (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) floor mat\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:36:41 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:36:42 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:36:42 engine.py:280] Added request chatcmpl-c671a77660bb4241a4d7756fda1e4ed5.
INFO 03-21 14:36:46 metrics.py:455] Avg prompt throughput: 1254.9 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:36:50 logger.py:39] Received request chatcmpl-97ce2b50628548a185435ef6d4542500: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the clothes (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) clothes\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) shelves\n(B) stationery\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the counter (highlighted by a blue box)?\n(A) sofa\n(B) counter\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bookcase\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:36:51 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:36:51 engine.py:280] Added request chatcmpl-97ce2b50628548a185435ef6d4542500.
INFO 03-21 14:36:52 logger.py:39] Received request chatcmpl-429b928168ae4668aafe219bc82d6862: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) motorcycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) sofa\n(B) door\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) shelves\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) barrier\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the rack (highlighted by a blue box)?\n(A) books\n(B) rack\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the picture (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) picture\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:36:54 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 48.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:36:55 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:36:55 engine.py:280] Added request chatcmpl-429b928168ae4668aafe219bc82d6862.
INFO 03-21 14:36:59 metrics.py:455] Avg prompt throughput: 1249.4 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48228 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54898 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:37:02 logger.py:39] Received request chatcmpl-503efaebe3614972aa50d385239cfe04: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) door\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) barrier\n(B) motorcycle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the counter (highlighted by a blue box)?\n(A) lamp\n(B) counter\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:37:02 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:37:02 engine.py:280] Added request chatcmpl-503efaebe3614972aa50d385239cfe04.
INFO 03-21 14:37:03 logger.py:39] Received request chatcmpl-0b7f771375d44c61988ecbe2fecb0abe: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the remote (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) remote\n(B) bin\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bin\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the tissues (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) tissues\n(B) bin\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) bus\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) lamp\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) car\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:37:05 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 36.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:37:06 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:37:06 engine.py:280] Added request chatcmpl-0b7f771375d44c61988ecbe2fecb0abe.
INFO 03-21 14:37:10 metrics.py:455] Avg prompt throughput: 1251.6 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:37:13 logger.py:39] Received request chatcmpl-5820f8c44c9748d080966bc235acc45a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) books\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) television\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) books\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the painting (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) painting\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the keyboard (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) keyboard\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:37:14 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:37:14 engine.py:280] Added request chatcmpl-5820f8c44c9748d080966bc235acc45a.
INFO 03-21 14:37:15 logger.py:39] Received request chatcmpl-8fa7ecabedd44ac3a19e540a9a2bf368: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the picture (highlighted by a blue box)?\n(A) pillow\n(B) picture\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the drawers (highlighted by a blue box)?\n(A) pillow\n(B) drawers\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) shelves\n(B) pillow\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) desk\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:37:16 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:37:18 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:37:18 engine.py:280] Added request chatcmpl-8fa7ecabedd44ac3a19e540a9a2bf368.
INFO 03-21 14:37:22 metrics.py:455] Avg prompt throughput: 1252.2 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54898 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48228 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:37:27 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 94.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:37:28 logger.py:39] Received request chatcmpl-7a29640c953444a79fd8e85d331df5df: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) pedestrian\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) traffic cone\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the laptop (highlighted by a red box) or the machine (highlighted by a blue box)?\n(A) laptop\n(B) machine\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the board (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) board\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) barrier\n(B) motorcycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) door\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bottle (highlighted by a red box) or the board (highlighted by a blue box)?\n(A) bottle\n(B) board\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:37:28 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:37:28 engine.py:280] Added request chatcmpl-7a29640c953444a79fd8e85d331df5df.
INFO 03-21 14:37:32 metrics.py:455] Avg prompt throughput: 591.1 tokens/s, Avg generation throughput: 2.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:37:32 logger.py:39] Received request chatcmpl-453050a0f95642ab936e0c77ab187734: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) chair\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) chair\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) box\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bottle (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) bottle\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) chair\n(B) desk\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) sofa\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:37:32 logger.py:39] Received request chatcmpl-489bfb9269a545b085d23476f3bda96f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) trailer\n(B) motorcycle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) chair\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the picture (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) picture\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the air conditioner (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) air conditioner\n(B) desk\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) door\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the drawers (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) drawers\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:37:33 logger.py:39] Received request chatcmpl-46257d4e83a94ed99fd3107f146d25ad: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) barrier\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the painting (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) painting\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) books\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) books\n(B) blinds\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) shelves\n(B) mirror\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:37:33 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:37:33 engine.py:280] Added request chatcmpl-453050a0f95642ab936e0c77ab187734.
WARNING 03-21 14:37:33 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:37:33 engine.py:280] Added request chatcmpl-489bfb9269a545b085d23476f3bda96f.
WARNING 03-21 14:37:33 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:37:33 engine.py:280] Added request chatcmpl-46257d4e83a94ed99fd3107f146d25ad.
INFO 03-21 14:37:43 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:37:48 metrics.py:455] Avg prompt throughput: 1918.0 tokens/s, Avg generation throughput: 61.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44606 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:44600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:37:52 logger.py:39] Received request chatcmpl-310b912ded0749debd0eb5f7480d7793: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the microwave (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) microwave\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) bus\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bicycle\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) box\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the clothes (highlighted by a blue box)?\n(A) lamp\n(B) clothes\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:37:53 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:37:53 engine.py:280] Added request chatcmpl-310b912ded0749debd0eb5f7480d7793.
INFO 03-21 14:37:57 metrics.py:455] Avg prompt throughput: 357.0 tokens/s, Avg generation throughput: 39.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:37:58 logger.py:39] Received request chatcmpl-f397d802bc0047e088b698250951667b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) bus\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) books\n(B) monitor\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the picture (highlighted by a red box) or the keyboard (highlighted by a blue box)?\n(A) picture\n(B) keyboard\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:37:58 logger.py:39] Received request chatcmpl-0c458fd67b6840c695e8834f8a892856: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the bathtub (highlighted by a blue box)?\n(A) lamp\n(B) bathtub\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the sink (highlighted by a red box) or the bottle (highlighted by a blue box)?\n(A) sink\n(B) bottle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) chair\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) truck\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the night stand (highlighted by a blue box)?\n(A) lamp\n(B) night stand\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:37:59 logger.py:39] Received request chatcmpl-1318337cb2194856b9d69e6067177c93: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) bus\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) pedestrian\n(B) bicycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) lamp\n(B) box\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:37:59 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:37:59 engine.py:280] Added request chatcmpl-f397d802bc0047e088b698250951667b.
WARNING 03-21 14:37:59 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:37:59 engine.py:280] Added request chatcmpl-0c458fd67b6840c695e8834f8a892856.
WARNING 03-21 14:37:59 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:37:59 engine.py:280] Added request chatcmpl-1318337cb2194856b9d69e6067177c93.
INFO 03-21 14:38:09 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:38:14 metrics.py:455] Avg prompt throughput: 1916.9 tokens/s, Avg generation throughput: 61.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:47762 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:47752 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:38:17 logger.py:39] Received request chatcmpl-50dd463cf2184bdc93038bc232d6c15c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) bus\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) bus\n(B) barrier\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) pedestrian\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) books\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) chair\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) table\n(B) books\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:38:17 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:38:17 engine.py:280] Added request chatcmpl-50dd463cf2184bdc93038bc232d6c15c.
INFO 03-21 14:38:20 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.
INFO 03-21 14:38:22 logger.py:39] Received request chatcmpl-4c5528e31e814048a0cb6cc84135ced9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) trailer\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) bicycle\n(B) motorcycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) table\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:47772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:38:22 logger.py:39] Received request chatcmpl-a94fd701415f4483a5b67dabd2f5931a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the fireplace (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) fireplace\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) car\n(B) trailer\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) chair\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) barrier\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bus\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:38:22 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:38:22 engine.py:280] Added request chatcmpl-4c5528e31e814048a0cb6cc84135ced9.
WARNING 03-21 14:38:22 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:38:22 engine.py:280] Added request chatcmpl-a94fd701415f4483a5b67dabd2f5931a.
INFO 03-21 14:38:23 logger.py:39] Received request chatcmpl-71665b4cebd642f8ae91df122e2e7a17: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the board (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) board\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) truck\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) bin\n(B) monitor\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the tissues (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) tissues\n(B) bin\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) bin\n(B) stationery\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) bookcase\n(B) pillow\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:38:28 metrics.py:455] Avg prompt throughput: 396.0 tokens/s, Avg generation throughput: 2.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.0%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:38:30 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:38:30 engine.py:280] Added request chatcmpl-71665b4cebd642f8ae91df122e2e7a17.
INFO 03-21 14:38:34 metrics.py:455] Avg prompt throughput: 1694.9 tokens/s, Avg generation throughput: 0.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:47752 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:38:39 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 100.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:38:41 logger.py:39] Received request chatcmpl-8a11581d47e44246924a6384c55ca99f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the picture (highlighted by a blue box)?\n(A) sofa\n(B) picture\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) barrier\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the counter (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) counter\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) car\n(B) bicycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the stationery (highlighted by a red box) or the printer (highlighted by a blue box)?\n(A) stationery\n(B) printer\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) shelves\n(B) pillow\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:38:41 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:38:41 engine.py:280] Added request chatcmpl-8a11581d47e44246924a6384c55ca99f.
INFO 03-21 14:38:43 logger.py:39] Received request chatcmpl-bb1df94e15cb46088895c675425fc268: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) desk\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the board (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) board\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the plates (highlighted by a red box) or the drawers (highlighted by a blue box)?\n(A) plates\n(B) drawers\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) bicycle\n(B) motorcycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) pedestrian\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:38:45 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:38:45 engine.py:280] Added request chatcmpl-bb1df94e15cb46088895c675425fc268.
INFO 03-21 14:38:48 metrics.py:455] Avg prompt throughput: 358.8 tokens/s, Avg generation throughput: 11.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:47762 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:47772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:38:53 metrics.py:455] Avg prompt throughput: 641.6 tokens/s, Avg generation throughput: 48.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.
INFO 03-21 14:38:53 logger.py:39] Received request chatcmpl-5702cc7f833843cc8530ecc09cbd7bf7: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) table\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) table\n(B) bin\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bicycle\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:38:54 logger.py:39] Received request chatcmpl-50ae9fc979d64a089b60bf214bb0e325: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) bicycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) barrier\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the vase (highlighted by a blue box)?\n(A) table\n(B) vase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the night stand (highlighted by a blue box)?\n(A) lamp\n(B) night stand\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) books\n(B) mirror\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) bookcase\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:38:54 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:38:54 engine.py:280] Added request chatcmpl-5702cc7f833843cc8530ecc09cbd7bf7.
WARNING 03-21 14:38:54 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:38:54 engine.py:280] Added request chatcmpl-50ae9fc979d64a089b60bf214bb0e325.
INFO 03-21 14:39:00 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:47752 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:39:05 metrics.py:455] Avg prompt throughput: 1278.2 tokens/s, Avg generation throughput: 52.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.
INFO 03-21 14:39:05 logger.py:39] Received request chatcmpl-c3b51c686cae49aa9a1c36f494d2ab83: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) pedestrian\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) shelves\n(B) stationery\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) table\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:47772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
WARNING 03-21 14:39:06 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:39:06 engine.py:280] Added request chatcmpl-c3b51c686cae49aa9a1c36f494d2ab83.
INFO 03-21 14:39:06 logger.py:39] Received request chatcmpl-b6c753574eda44408b6c4130e99ee537: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the towel (highlighted by a red box) or the bathtub (highlighted by a blue box)?\n(A) towel\n(B) bathtub\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the machine (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) machine\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the vase (highlighted by a red box) or the potted plant (highlighted by a blue box)?\n(A) vase\n(B) potted plant\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:39:08 logger.py:39] Received request chatcmpl-2dd35bb5e1dd4a2c99bf18f0fe11d2d4: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the printer (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) printer\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) pillow\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the picture (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) picture\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) shelves\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:39:10 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:39:10 engine.py:280] Added request chatcmpl-b6c753574eda44408b6c4130e99ee537.
WARNING 03-21 14:39:10 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:39:10 engine.py:280] Added request chatcmpl-2dd35bb5e1dd4a2c99bf18f0fe11d2d4.
INFO 03-21 14:39:16 metrics.py:455] Avg prompt throughput: 294.1 tokens/s, Avg generation throughput: 0.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO 03-21 14:39:21 metrics.py:455] Avg prompt throughput: 1280.0 tokens/s, Avg generation throughput: 69.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:47762 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:47752 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:47772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:39:26 logger.py:39] Received request chatcmpl-4be24af97e294048a3e15339276e6bc6: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the tissues (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) tissues\n(B) bin\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) table\n(B) blinds\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) barrier\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) shelves\n(B) stationery\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:39:27 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:39:27 engine.py:280] Added request chatcmpl-4be24af97e294048a3e15339276e6bc6.
INFO 03-21 14:39:28 logger.py:39] Received request chatcmpl-fa84b9d11c574d2a8ff4d40e8070d907: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) pedestrian\n(B) barrier\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) door\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) table\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the tray (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) tray\n(B) box\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bin\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) door\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the counter (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) counter\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) table\n(B) blinds\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:39:29 logger.py:39] Received request chatcmpl-f9635e432f524a1982135a564ef89633: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) table\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the clock (highlighted by a red box) or the bottle (highlighted by a blue box)?\n(A) clock\n(B) bottle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the printer (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) printer\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the stationery (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) stationery\n(B) bin\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the bag (highlighted by a blue box)?\n(A) door\n(B) bag\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) table\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:39:29 logger.py:39] Received request chatcmpl-190dce8f215949c69ef127c26ceae2bb: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) motorcycle\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) table\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:39:31 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:39:31 engine.py:280] Added request chatcmpl-fa84b9d11c574d2a8ff4d40e8070d907.
WARNING 03-21 14:39:31 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:39:31 engine.py:280] Added request chatcmpl-f9635e432f524a1982135a564ef89633.
WARNING 03-21 14:39:31 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:39:31 engine.py:280] Added request chatcmpl-190dce8f215949c69ef127c26ceae2bb.
INFO 03-21 14:39:41 metrics.py:455] Avg prompt throughput: 163.6 tokens/s, Avg generation throughput: 5.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:39:46 metrics.py:455] Avg prompt throughput: 1918.7 tokens/s, Avg generation throughput: 61.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:38690 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:47762 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:39:50 logger.py:39] Received request chatcmpl-b71e596e6c5f4313b919e8ace8823d8b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) sofa\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the keyboard (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) keyboard\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the keyboard (highlighted by a blue box)?\n(A) desk\n(B) keyboard\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:39:50 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:39:50 engine.py:280] Added request chatcmpl-b71e596e6c5f4313b919e8ace8823d8b.
INFO 03-21 14:39:52 logger.py:39] Received request chatcmpl-20215ecf5c044a5fa37d972c5d29e1dc: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the clothes (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) clothes\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the night stand (highlighted by a blue box)?\n(A) lamp\n(B) night stand\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:39:53 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.
INFO 03-21 14:39:53 logger.py:39] Received request chatcmpl-064ea781f9a84cd584933a1e1296e81a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the painting (highlighted by a blue box)?\n(A) chair\n(B) painting\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) bus\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) bus\n(B) barrier\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the blinds (highlighted by a blue box)?\n(A) books\n(B) blinds\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) car\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) books\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:39:54 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:39:54 engine.py:280] Added request chatcmpl-20215ecf5c044a5fa37d972c5d29e1dc.
WARNING 03-21 14:39:54 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:39:54 engine.py:280] Added request chatcmpl-064ea781f9a84cd584933a1e1296e81a.
INFO 03-21 14:40:00 metrics.py:455] Avg prompt throughput: 419.5 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:47772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:40:04 logger.py:39] Received request chatcmpl-5e30eb21390d4d3cb561619786517bfa: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the machine (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) machine\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) chair\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the keyboard (highlighted by a blue box)?\n(A) desk\n(B) keyboard\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the printer (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) printer\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) table\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) bus\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:40:04 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:40:04 engine.py:280] Added request chatcmpl-5e30eb21390d4d3cb561619786517bfa.
INFO 03-21 14:40:07 metrics.py:455] Avg prompt throughput: 936.2 tokens/s, Avg generation throughput: 25.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:47762 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:38690 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:40:12 metrics.py:455] Avg prompt throughput: 640.1 tokens/s, Avg generation throughput: 75.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:47772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:40:18 logger.py:39] Received request chatcmpl-b3ec814f3031418c90ad13dd0a4ebe81: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the tray (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) tray\n(B) box\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) books\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the mouse (highlighted by a blue box)?\n(A) television\n(B) mouse\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the picture (highlighted by a blue box)?\n(A) chair\n(B) picture\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the night stand (highlighted by a blue box)?\n(A) chair\n(B) night stand\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:40:19 logger.py:39] Received request chatcmpl-9d59b87e6dc2495da09f320296fb5cb0: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) car\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the towel (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) towel\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the dresser (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) dresser\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the laptop (highlighted by a red box) or the machine (highlighted by a blue box)?\n(A) laptop\n(B) machine\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) chair\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:40:19 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:40:19 engine.py:280] Added request chatcmpl-b3ec814f3031418c90ad13dd0a4ebe81.
WARNING 03-21 14:40:19 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:40:19 engine.py:280] Added request chatcmpl-9d59b87e6dc2495da09f320296fb5cb0.
INFO 03-21 14:40:19 logger.py:39] Received request chatcmpl-5df2cf396f0044e5b795cef3524a9479: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) bicycle\n(B) towel\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) chair\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) pillow\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) motorcycle\n(B) bicycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:40:19 logger.py:39] Received request chatcmpl-6c0939db63fc4599a7e490041b1cfa22: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) lamp\n(B) towel\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) truck\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) lamp\n(B) refrigerator\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bus\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the painting (highlighted by a blue box)?\n(A) table\n(B) painting\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:40:27 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:40:27 engine.py:280] Added request chatcmpl-5df2cf396f0044e5b795cef3524a9479.
WARNING 03-21 14:40:27 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:40:27 engine.py:280] Added request chatcmpl-6c0939db63fc4599a7e490041b1cfa22.
INFO 03-21 14:40:33 metrics.py:455] Avg prompt throughput: 305.5 tokens/s, Avg generation throughput: 1.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:40:38 metrics.py:455] Avg prompt throughput: 1282.6 tokens/s, Avg generation throughput: 69.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:40:41 logger.py:39] Received request chatcmpl-d73cb596fe194b96b26908494dc90608: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) lamp\n(B) towel\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) traffic cone\n(B) bicycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) bus\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) television\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:40:41 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:40:41 engine.py:280] Added request chatcmpl-d73cb596fe194b96b26908494dc90608.
INFO 03-21 14:40:43 logger.py:39] Received request chatcmpl-ab38d42de5fc4c3f8b3f59ca69f939ed: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) pedestrian\n(B) barrier\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) door\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) truck\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bus\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) box\n(B) desk\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:40:44 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 36.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:40:46 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:40:46 engine.py:280] Added request chatcmpl-ab38d42de5fc4c3f8b3f59ca69f939ed.
INFO 03-21 14:40:49 metrics.py:455] Avg prompt throughput: 1249.0 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48546 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:40:53 logger.py:39] Received request chatcmpl-1d292e6bd3884211b0d03a781c8cef21: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the tray (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) tray\n(B) box\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the stationery (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) stationery\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the toys (highlighted by a red box) or the closet (highlighted by a blue box)?\n(A) toys\n(B) closet\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the toys (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) toys\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) bus\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:40:53 logger.py:39] Received request chatcmpl-ac726f5b77e94319893a1d2c24e46f98: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) books\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the towel (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) towel\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the keyboard (highlighted by a blue box)?\n(A) television\n(B) keyboard\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the monitor (highlighted by a blue box)?\n(A) chair\n(B) monitor\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) traffic cone\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the counter (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) counter\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:40:53 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:40:53 engine.py:280] Added request chatcmpl-1d292e6bd3884211b0d03a781c8cef21.
WARNING 03-21 14:40:53 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:40:53 engine.py:280] Added request chatcmpl-ac726f5b77e94319893a1d2c24e46f98.
INFO 03-21 14:41:00 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 21.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:41:05 metrics.py:455] Avg prompt throughput: 1278.9 tokens/s, Avg generation throughput: 59.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.
INFO 03-21 14:41:06 logger.py:39] Received request chatcmpl-67ddaa13697b4afbb9a96a5bfa2f1ee9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the picture (highlighted by a blue box)?\n(A) chair\n(B) picture\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bicycle (highlighted by a blue box)?\n(A) car\n(B) bicycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the drawers (highlighted by a red box) or the phone (highlighted by a blue box)?\n(A) drawers\n(B) phone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the blanket (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) blanket\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the dresser (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) dresser\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) traffic cone\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) desk\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:41:06 logger.py:39] Received request chatcmpl-23b56c0309b347319922d889d96230ae: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) pedestrian\n(B) barrier\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the sink (highlighted by a red box) or the bottle (highlighted by a blue box)?\n(A) sink\n(B) bottle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the night stand (highlighted by a blue box)?\n(A) chair\n(B) night stand\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the blanket (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) blanket\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the stationery (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) stationery\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) table\n(B) desk\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) table\n(B) shelves\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:41:06 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:41:06 engine.py:280] Added request chatcmpl-67ddaa13697b4afbb9a96a5bfa2f1ee9.
WARNING 03-21 14:41:06 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:41:06 engine.py:280] Added request chatcmpl-23b56c0309b347319922d889d96230ae.
INFO 03-21 14:41:12 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48546 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:41:17 logger.py:39] Received request chatcmpl-8e12f1d20cf2486c907e1e33e76e8ca9: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) pedestrian\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) bus\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bin\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) door\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) television\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:41:18 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:41:18 engine.py:280] Added request chatcmpl-8e12f1d20cf2486c907e1e33e76e8ca9.
INFO 03-21 14:41:19 logger.py:39] Received request chatcmpl-3cdf01b01e17421abf46e2ce33617313: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) door\n(B) sofa\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) pedestrian\n(B) motorcycle\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the tray (highlighted by a red box) or the painting (highlighted by a blue box)?\n(A) tray\n(B) painting\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) traffic cone\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) lamp\n(B) door\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:41:21 metrics.py:455] Avg prompt throughput: 786.9 tokens/s, Avg generation throughput: 28.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:41:22 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:41:22 engine.py:280] Added request chatcmpl-3cdf01b01e17421abf46e2ce33617313.
INFO 03-21 14:41:26 metrics.py:455] Avg prompt throughput: 1249.5 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:41:31 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 79.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.
INFO 03-21 14:41:31 logger.py:39] Received request chatcmpl-c3854539018f4eaca9b71566430e73de: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) traffic cone\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) bus\n(B) barrier\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the board (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) board\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) shelves\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) television\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) car\n(B) trailer\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) desk\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:41:31 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:41:31 engine.py:280] Added request chatcmpl-c3854539018f4eaca9b71566430e73de.
INFO 03-21 14:41:32 logger.py:39] Received request chatcmpl-b901cfc1036347e5b458265c6acb73dd: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the tissues (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) tissues\n(B) bin\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bin\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the bowl (highlighted by a blue box)?\n(A) chair\n(B) bowl\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the dresser (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) dresser\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) bin\n(B) stationery\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) lamp\n(B) shelves\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:41:36 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:41:36 engine.py:280] Added request chatcmpl-b901cfc1036347e5b458265c6acb73dd.
INFO 03-21 14:41:38 metrics.py:455] Avg prompt throughput: 421.0 tokens/s, Avg generation throughput: 2.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48546 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:41:42 logger.py:39] Received request chatcmpl-d8a1c3c9ef0c48c2b1e173d473663e2b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) trailer\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) lamp\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) pedestrian\n(B) traffic cone\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) shelves\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) traffic cone\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the counter (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) counter\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:41:42 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:41:42 engine.py:280] Added request chatcmpl-d8a1c3c9ef0c48c2b1e173d473663e2b.
INFO 03-21 14:41:44 logger.py:39] Received request chatcmpl-00a06d04e1e84af6bbf1c7d8c4fac05b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) traffic cone\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) books\n(B) mirror\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:41:45 metrics.py:455] Avg prompt throughput: 500.1 tokens/s, Avg generation throughput: 19.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:41:46 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:41:46 engine.py:280] Added request chatcmpl-00a06d04e1e84af6bbf1c7d8c4fac05b.
INFO 03-21 14:41:50 metrics.py:455] Avg prompt throughput: 1242.1 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:41:53 logger.py:39] Received request chatcmpl-68db03edeb0849c69bceb90465f4a29a: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) bicycle\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) car\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the picture (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) picture\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) bus\n(B) truck\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) car\n(B) trailer\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) door\n(B) books\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:41:53 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:41:53 engine.py:280] Added request chatcmpl-68db03edeb0849c69bceb90465f4a29a.
INFO 03-21 14:41:56 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 37.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48546 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:42:01 metrics.py:455] Avg prompt throughput: 638.4 tokens/s, Avg generation throughput: 68.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:42:01 logger.py:39] Received request chatcmpl-48adcdb444394fc89535156c655a0b67: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) pedestrian\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the painting (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) painting\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the board (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) board\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the box (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) box\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bin\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) trailer\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) pillow\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:42:02 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:42:02 engine.py:280] Added request chatcmpl-48adcdb444394fc89535156c655a0b67.
INFO 03-21 14:42:05 logger.py:39] Received request chatcmpl-d782d067c1e1494eac2b416a45450e5c: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bin\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) pedestrian\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) chair\n(B) stationery\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) books\n(B) shelves\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) table\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) refrigerator\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the stationery (highlighted by a blue box)?\n(A) shelves\n(B) stationery\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the blinds (highlighted by a red box) or the towel (highlighted by a blue box)?\n(A) blinds\n(B) towel\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:42:05 logger.py:39] Received request chatcmpl-a62da698e31044c2b0b8cb875ba2a7fe: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) chair\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the tray (highlighted by a blue box)?\n(A) refrigerator\n(B) tray\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) bicycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) lamp\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:42:06 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:42:06 engine.py:280] Added request chatcmpl-d782d067c1e1494eac2b416a45450e5c.
WARNING 03-21 14:42:06 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:42:06 engine.py:280] Added request chatcmpl-a62da698e31044c2b0b8cb875ba2a7fe.
INFO 03-21 14:42:12 metrics.py:455] Avg prompt throughput: 288.0 tokens/s, Avg generation throughput: 1.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:42:17 metrics.py:455] Avg prompt throughput: 1279.2 tokens/s, Avg generation throughput: 66.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
INFO 03-21 14:42:18 logger.py:39] Received request chatcmpl-0a205e8a2df243c0b4709ad7f559949f: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) traffic cone\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the box (highlighted by a blue box)?\n(A) bin\n(B) box\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the tissues (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) tissues\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) shelves\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the painting (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) painting\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the motorcycle (highlighted by a blue box)?\n(A) bicycle\n(B) motorcycle\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the refrigerator (highlighted by a blue box)?\n(A) door\n(B) refrigerator\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the picture (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) picture\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:42:19 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:42:19 engine.py:280] Added request chatcmpl-0a205e8a2df243c0b4709ad7f559949f.
INFO 03-21 14:42:23 metrics.py:455] Avg prompt throughput: 600.0 tokens/s, Avg generation throughput: 17.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:43060 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48546 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:42:26 logger.py:39] Received request chatcmpl-d969474e98ca4a7f95d69a14ca02f8df: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) shelves\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the keyboard (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) keyboard\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) truck\n(B) bus\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the sink (highlighted by a blue box)?\n(A) pillow\n(B) sink\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) bus\n(B) barrier\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) books\n(B) bookcase\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:42:26 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:42:26 engine.py:280] Added request chatcmpl-d969474e98ca4a7f95d69a14ca02f8df.
INFO 03-21 14:42:29 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 27.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%.
INFO 03-21 14:42:29 logger.py:39] Received request chatcmpl-2741fecedb9f405689bfd7784b407396: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) table\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the printer (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) printer\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) lamp\n(B) table\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the drawers (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) drawers\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) chair\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the barrier (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) barrier\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the monitor (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) monitor\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) chair\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) door\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:42:29 logger.py:39] Received request chatcmpl-eaaffa3143da4fe1bbb7d08f908d9163: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the motorcycle (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) motorcycle\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) traffic cone\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the pillow (highlighted by a blue box)?\n(A) door\n(B) pillow\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) chair\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the tissues (highlighted by a blue box)?\n(A) desk\n(B) tissues\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) door\n(B) lamp\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:42:30 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:42:30 engine.py:280] Added request chatcmpl-2741fecedb9f405689bfd7784b407396.
WARNING 03-21 14:42:30 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:42:30 engine.py:280] Added request chatcmpl-eaaffa3143da4fe1bbb7d08f908d9163.
INFO 03-21 14:42:36 metrics.py:455] Avg prompt throughput: 420.7 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.0%, CPU KV cache usage: 0.0%.
INFO 03-21 14:42:42 metrics.py:455] Avg prompt throughput: 1278.7 tokens/s, Avg generation throughput: 69.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:42:44 logger.py:39] Received request chatcmpl-e7f60101e19d4475aa10251d1d2fa1d5: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) books\n(B) desk\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the bowl (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) bowl\n(B) bin\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bicycle (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) bicycle\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) trailer\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the picture (highlighted by a blue box)?\n(A) pillow\n(B) picture\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the desk (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) desk\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the person (highlighted by a red box) or the mirror (highlighted by a blue box)?\n(A) person\n(B) mirror\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:42:45 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:42:45 engine.py:280] Added request chatcmpl-e7f60101e19d4475aa10251d1d2fa1d5.
INFO 03-21 14:42:46 logger.py:39] Received request chatcmpl-d3c00d9d8ea2456bb6c0b6e0ed352a87: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bin (highlighted by a blue box)?\n(A) table\n(B) bin\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the refrigerator (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) refrigerator\n(B) lamp\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the sofa (highlighted by a red box) or the door (highlighted by a blue box)?\n(A) sofa\n(B) door\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) bin\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the trailer (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) trailer\n(B) car\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the night stand (highlighted by a blue box)?\n(A) shelves\n(B) night stand\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) pillow\n(B) desk\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:42:48 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 37.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.3%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:42:49 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:42:49 engine.py:280] Added request chatcmpl-d3c00d9d8ea2456bb6c0b6e0ed352a87.
INFO 03-21 14:42:53 metrics.py:455] Avg prompt throughput: 1254.6 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48546 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:42:56 logger.py:39] Received request chatcmpl-081ea7f8a2c14ce185b63c7bc0192178: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the car (highlighted by a blue box)?\n(A) truck\n(B) car\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the bus (highlighted by a red box) or the barrier (highlighted by a blue box)?\n(A) bus\n(B) barrier\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) bookcase\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the blanket (highlighted by a red box) or the lamp (highlighted by a blue box)?\n(A) blanket\n(B) lamp\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the truck (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) truck\n(B) pedestrian\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) lamp\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the television (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) television\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the shelves (highlighted by a blue box)?\n(A) door\n(B) shelves\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:42:57 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:42:57 engine.py:280] Added request chatcmpl-081ea7f8a2c14ce185b63c7bc0192178.
INFO 03-21 14:42:58 logger.py:39] Received request chatcmpl-4c91463d5dc94d0a8359bd19129f0765: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the pillow (highlighted by a red box) or the television (highlighted by a blue box)?\n(A) pillow\n(B) television\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the books (highlighted by a blue box)?\n(A) shelves\n(B) books\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the table (highlighted by a red box) or the bookcase (highlighted by a blue box)?\n(A) table\n(B) bookcase\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) chair\n(B) desk\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the traffic cone (highlighted by a blue box)?\n(A) pedestrian\n(B) traffic cone\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the bus (highlighted by a blue box)?\n(A) car\n(B) bus\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the door (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) door\n(B) table\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the lamp (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) lamp\n(B) chair\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 03-21 14:42:59 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 35.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
WARNING 03-21 14:43:01 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:43:01 engine.py:280] Added request chatcmpl-4c91463d5dc94d0a8359bd19129f0765.
INFO 03-21 14:43:05 metrics.py:455] Avg prompt throughput: 1249.3 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 12.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:43:09 logger.py:39] Received request chatcmpl-cd8117914042435cb2a1a0e764aa263b: prompt: '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>\nExample 0:\nWhich object is closer to the camera taking this photo, the traffic cone (highlighted by a red box) or the trailer (highlighted by a blue box)?\n(A) traffic cone\n(B) trailer\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 1:\nWhich object is closer to the camera taking this photo, the shelves (highlighted by a red box) or the sofa (highlighted by a blue box)?\n(A) shelves\n(B) sofa\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 2:\nWhich object is closer to the camera taking this photo, the pedestrian (highlighted by a red box) or the truck (highlighted by a blue box)?\n(A) pedestrian\n(B) truck\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 3:\nWhich object is closer to the camera taking this photo, the chair (highlighted by a red box) or the desk (highlighted by a blue box)?\n(A) chair\n(B) desk\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 4:\nWhich object is closer to the camera taking this photo, the car (highlighted by a red box) or the pedestrian (highlighted by a blue box)?\n(A) car\n(B) pedestrian\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 5:\nWhich object is closer to the camera taking this photo, the floor mat (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) floor mat\n(B) chair\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 6:\nWhich object is closer to the camera taking this photo, the books (highlighted by a red box) or the chair (highlighted by a blue box)?\n(A) books\n(B) chair\n The answer is (A)\n<|vision_start|><|image_pad|><|vision_end|>\nExample 7:\nWhich object is closer to the camera taking this photo, the bin (highlighted by a red box) or the printer (highlighted by a blue box)?\n(A) bin\n(B) printer\n The answer is (B)\n<|vision_start|><|image_pad|><|vision_end|>\nQuestion:\nWhich object is closer to the camera taking this photo, the bookcase (highlighted by a red box) or the table (highlighted by a blue box)?\n(A) bookcase\n(B) table\nEnd your answer with either (A) or (B).\nThink step by step and carefully reason through the question before giving the answer.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
WARNING 03-21 14:43:10 utils.py:1446] The following intended overrides are not keyword-only args and and will be dropped: {'images_kwargs.size.shortest_edge', 'images_kwargs.do_resize', 'images_kwargs.size.longest_edge'}
INFO 03-21 14:43:10 engine.py:280] Added request chatcmpl-cd8117914042435cb2a1a0e764aa263b.
INFO 03-21 14:43:12 metrics.py:455] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 52.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:58618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:48546 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 03-21 14:43:17 metrics.py:455] Avg prompt throughput: 640.1 tokens/s, Avg generation throughput: 38.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:48562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
